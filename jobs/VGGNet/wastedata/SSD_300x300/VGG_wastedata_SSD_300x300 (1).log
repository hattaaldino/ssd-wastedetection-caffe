I0622 04:06:51.260437 13672 caffe.cpp:217] Using GPUs 0
I0622 04:06:52.089018 13672 caffe.cpp:222] GPU 0: GeForce 930MX
I0622 04:06:52.578483 13672 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0622 04:06:52.578483 13672 solver.cpp:63] Initializing solver from parameters: 
train_net: "models\\VGGNet\\wastedata\\SSD_300x300\\train.prototxt"
test_net: "models\\VGGNet\\wastedata\\SSD_300x300\\test.prototxt"
test_iter: 500
test_interval: 10000
base_lr: 0.001
display: 10
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 40000
snapshot_prefix: "models\\VGGNet\\wastedata\\SSD_300x300\\VGG_wastedata_SSD_300x300"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 80000
stepvalue: 100000
stepvalue: 120000
iter_size: 16
type: "SGD"
eval_type: "detection"
ap_version: "11point"
I0622 04:06:52.585641 13672 solver.cpp:96] Creating training net from train_net file: models\VGGNet\wastedata\SSD_300x300\train.prototxt
I0622 04:06:52.587636 13672 net.cpp:58] Initializing net from parameters: 
name: "VGG_wastedata_SSD_300x300_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "examples\\wastedata\\wastedata_trainval_lmdb"
    batch_size: 2
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data\\wastedata\\labelmap_waste.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv10_1"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv10_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv10_1_relu"
  type: "ReLU"
  bottom: "conv10_1"
  top: "conv10_1"
}
layer {
  name: "conv10_2"
  type: "Convolution"
  bottom: "conv10_1"
  top: "conv10_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv10_2_relu"
  type: "ReLU"
  bottom: "conv10_2"
  top: "conv10_2"
}
layer {
  name: "conv11_1"
  type: "Convolution"
  bottom: "conv10_2"
  top: "conv11_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_1_relu"
  type: "ReLU"
  bottom: "conv11_1"
  top: "conv11_1"
}
layer {
  name: "conv11_2"
  type: "Convolution"
  bottom: "conv11_1"
  top: "conv11_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_2_relu"
  type: "ReLU"
  bottom: "conv11_2"
  top: "conv11_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv10_2_mbox_loc"
  type: "Convolution"
  bottom: "conv10_2"
  top: "conv10_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv10_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv10_2_mbox_loc"
  top: "conv10_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv10_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv10_2_mbox_loc_perm"
  top: "conv10_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv10_2_mbox_conf"
  type: "Convolution"
  bottom: "conv10_2"
  top: "conv10_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv10_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv10_2_mbox_conf"
  top: "conv10_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv10_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv10_2_mbox_conf_perm"
  top: "conv10_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv10_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv10_2"
  bottom: "data"
  top: "conv10_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv11_2_mbox_loc"
  type: "Convolution"
  bottom: "conv11_2"
  top: "conv11_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_2_mbox_loc"
  top: "conv11_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_2_mbox_loc_perm"
  top: "conv11_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_2_mbox_conf"
  type: "Convolution"
  bottom: "conv11_2"
  top: "conv11_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_2_mbox_conf"
  top: "conv11_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_2_mbox_conf_perm"
  top: "conv11_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11_2"
  bottom: "data"
  top: "conv11_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  bottom: "conv10_2_mbox_loc_flat"
  bottom: "conv11_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  bottom: "conv10_2_mbox_conf_flat"
  bottom: "conv11_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  bottom: "conv10_2_mbox_priorbox"
  bottom: "conv11_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 3
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0622 04:06:52.825404 13672 layer_factory.hpp:77] Creating layer data
I0622 04:06:52.825404 13672 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0622 04:06:52.825404 13672 net.cpp:100] Creating Layer data
I0622 04:06:52.825404 13672 net.cpp:408] data -> data
I0622 04:06:52.825404 13672 net.cpp:408] data -> label
I0622 04:06:52.828363  6080 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0622 04:06:52.871114  6080 db_lmdb.cpp:40] Opened lmdb examples\wastedata\wastedata_trainval_lmdb
I0622 04:06:52.886713 13672 annotated_data_layer.cpp:62] output data size: 2,3,300,300
I0622 04:06:52.904903 13672 net.cpp:150] Setting up data
I0622 04:06:52.904903 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:52.904903 13672 net.cpp:157] Top shape: 1 1 1 8 (8)
I0622 04:06:52.904903 13672 net.cpp:165] Memory required for data: 2160032
I0622 04:06:52.904903 13672 layer_factory.hpp:77] Creating layer data_data_0_split
I0622 04:06:52.904903 13672 net.cpp:100] Creating Layer data_data_0_split
I0622 04:06:52.904903 13672 net.cpp:434] data_data_0_split <- data
I0622 04:06:52.904903 13672 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0622 04:06:52.904903 13672 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0622 04:06:52.904903 13672 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0622 04:06:52.904903 13672 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0622 04:06:52.904903 13672 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0622 04:06:52.904903 13672 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0622 04:06:52.904903 13672 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0622 04:06:52.905901 13672 net.cpp:150] Setting up data_data_0_split
I0622 04:06:52.905901 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:52.906939 13720 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0622 04:06:52.914268 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:52.914616 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:52.914616 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:52.914616 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:52.914616 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:52.914616 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:52.914616 13672 net.cpp:165] Memory required for data: 17280032
I0622 04:06:52.914616 13672 layer_factory.hpp:77] Creating layer conv1_1
I0622 04:06:52.914616 13672 net.cpp:100] Creating Layer conv1_1
I0622 04:06:52.914616 13672 net.cpp:434] conv1_1 <- data_data_0_split_0
I0622 04:06:52.914616 13672 net.cpp:408] conv1_1 -> conv1_1
I0622 04:06:53.778146 13672 net.cpp:150] Setting up conv1_1
I0622 04:06:53.778146 13672 net.cpp:157] Top shape: 2 64 300 300 (11520000)
I0622 04:06:53.778146 13672 net.cpp:165] Memory required for data: 63360032
I0622 04:06:53.778146 13672 layer_factory.hpp:77] Creating layer relu1_1
I0622 04:06:53.778146 13672 net.cpp:100] Creating Layer relu1_1
I0622 04:06:53.778146 13672 net.cpp:434] relu1_1 <- conv1_1
I0622 04:06:53.778146 13672 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0622 04:06:53.780138 13672 net.cpp:150] Setting up relu1_1
I0622 04:06:53.780138 13672 net.cpp:157] Top shape: 2 64 300 300 (11520000)
I0622 04:06:53.780138 13672 net.cpp:165] Memory required for data: 109440032
I0622 04:06:53.780138 13672 layer_factory.hpp:77] Creating layer conv1_2
I0622 04:06:53.780138 13672 net.cpp:100] Creating Layer conv1_2
I0622 04:06:53.780138 13672 net.cpp:434] conv1_2 <- conv1_1
I0622 04:06:53.780138 13672 net.cpp:408] conv1_2 -> conv1_2
I0622 04:06:53.788141 13672 net.cpp:150] Setting up conv1_2
I0622 04:06:53.788141 13672 net.cpp:157] Top shape: 2 64 300 300 (11520000)
I0622 04:06:53.788141 13672 net.cpp:165] Memory required for data: 155520032
I0622 04:06:53.788141 13672 layer_factory.hpp:77] Creating layer relu1_2
I0622 04:06:53.788141 13672 net.cpp:100] Creating Layer relu1_2
I0622 04:06:53.788141 13672 net.cpp:434] relu1_2 <- conv1_2
I0622 04:06:53.788141 13672 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0622 04:06:53.789139 13672 net.cpp:150] Setting up relu1_2
I0622 04:06:53.790169 13672 net.cpp:157] Top shape: 2 64 300 300 (11520000)
I0622 04:06:53.790169 13672 net.cpp:165] Memory required for data: 201600032
I0622 04:06:53.790169 13672 layer_factory.hpp:77] Creating layer pool1
I0622 04:06:53.790169 13672 net.cpp:100] Creating Layer pool1
I0622 04:06:53.790169 13672 net.cpp:434] pool1 <- conv1_2
I0622 04:06:53.790169 13672 net.cpp:408] pool1 -> pool1
I0622 04:06:53.790169 13672 net.cpp:150] Setting up pool1
I0622 04:06:53.790169 13672 net.cpp:157] Top shape: 2 64 150 150 (2880000)
I0622 04:06:53.790169 13672 net.cpp:165] Memory required for data: 213120032
I0622 04:06:53.790169 13672 layer_factory.hpp:77] Creating layer conv2_1
I0622 04:06:53.790169 13672 net.cpp:100] Creating Layer conv2_1
I0622 04:06:53.790169 13672 net.cpp:434] conv2_1 <- pool1
I0622 04:06:53.790169 13672 net.cpp:408] conv2_1 -> conv2_1
I0622 04:06:53.798477 13672 net.cpp:150] Setting up conv2_1
I0622 04:06:53.798477 13672 net.cpp:157] Top shape: 2 128 150 150 (5760000)
I0622 04:06:53.798477 13672 net.cpp:165] Memory required for data: 236160032
I0622 04:06:53.798477 13672 layer_factory.hpp:77] Creating layer relu2_1
I0622 04:06:53.798477 13672 net.cpp:100] Creating Layer relu2_1
I0622 04:06:53.798477 13672 net.cpp:434] relu2_1 <- conv2_1
I0622 04:06:53.798477 13672 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0622 04:06:53.800472 13672 net.cpp:150] Setting up relu2_1
I0622 04:06:53.800472 13672 net.cpp:157] Top shape: 2 128 150 150 (5760000)
I0622 04:06:53.800472 13672 net.cpp:165] Memory required for data: 259200032
I0622 04:06:53.800472 13672 layer_factory.hpp:77] Creating layer conv2_2
I0622 04:06:53.800472 13672 net.cpp:100] Creating Layer conv2_2
I0622 04:06:53.800472 13672 net.cpp:434] conv2_2 <- conv2_1
I0622 04:06:53.800472 13672 net.cpp:408] conv2_2 -> conv2_2
I0622 04:06:53.809854 13672 net.cpp:150] Setting up conv2_2
I0622 04:06:53.809854 13672 net.cpp:157] Top shape: 2 128 150 150 (5760000)
I0622 04:06:53.809854 13672 net.cpp:165] Memory required for data: 282240032
I0622 04:06:53.809854 13672 layer_factory.hpp:77] Creating layer relu2_2
I0622 04:06:53.809854 13672 net.cpp:100] Creating Layer relu2_2
I0622 04:06:53.809854 13672 net.cpp:434] relu2_2 <- conv2_2
I0622 04:06:53.809854 13672 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0622 04:06:53.812847 13672 net.cpp:150] Setting up relu2_2
I0622 04:06:53.812847 13672 net.cpp:157] Top shape: 2 128 150 150 (5760000)
I0622 04:06:53.812847 13672 net.cpp:165] Memory required for data: 305280032
I0622 04:06:53.812847 13672 layer_factory.hpp:77] Creating layer pool2
I0622 04:06:53.812847 13672 net.cpp:100] Creating Layer pool2
I0622 04:06:53.812847 13672 net.cpp:434] pool2 <- conv2_2
I0622 04:06:53.812847 13672 net.cpp:408] pool2 -> pool2
I0622 04:06:53.812847 13672 net.cpp:150] Setting up pool2
I0622 04:06:53.812847 13672 net.cpp:157] Top shape: 2 128 75 75 (1440000)
I0622 04:06:53.812847 13672 net.cpp:165] Memory required for data: 311040032
I0622 04:06:53.812847 13672 layer_factory.hpp:77] Creating layer conv3_1
I0622 04:06:53.812847 13672 net.cpp:100] Creating Layer conv3_1
I0622 04:06:53.812847 13672 net.cpp:434] conv3_1 <- pool2
I0622 04:06:53.812847 13672 net.cpp:408] conv3_1 -> conv3_1
I0622 04:06:53.866835 13672 net.cpp:150] Setting up conv3_1
I0622 04:06:53.866835 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:53.866835 13672 net.cpp:165] Memory required for data: 322560032
I0622 04:06:53.867835 13672 layer_factory.hpp:77] Creating layer relu3_1
I0622 04:06:53.867835 13672 net.cpp:100] Creating Layer relu3_1
I0622 04:06:53.867835 13672 net.cpp:434] relu3_1 <- conv3_1
I0622 04:06:53.867835 13672 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0622 04:06:53.868832 13672 net.cpp:150] Setting up relu3_1
I0622 04:06:53.868832 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:53.868832 13672 net.cpp:165] Memory required for data: 334080032
I0622 04:06:53.868832 13672 layer_factory.hpp:77] Creating layer conv3_2
I0622 04:06:53.868832 13672 net.cpp:100] Creating Layer conv3_2
I0622 04:06:53.868832 13672 net.cpp:434] conv3_2 <- conv3_1
I0622 04:06:53.868832 13672 net.cpp:408] conv3_2 -> conv3_2
I0622 04:06:53.885260 13672 net.cpp:150] Setting up conv3_2
I0622 04:06:53.885260 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:53.885260 13672 net.cpp:165] Memory required for data: 345600032
I0622 04:06:53.885260 13672 layer_factory.hpp:77] Creating layer relu3_2
I0622 04:06:53.885260 13672 net.cpp:100] Creating Layer relu3_2
I0622 04:06:53.885260 13672 net.cpp:434] relu3_2 <- conv3_2
I0622 04:06:53.885260 13672 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0622 04:06:53.886258 13672 net.cpp:150] Setting up relu3_2
I0622 04:06:53.886258 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:53.886258 13672 net.cpp:165] Memory required for data: 357120032
I0622 04:06:53.886258 13672 layer_factory.hpp:77] Creating layer conv3_3
I0622 04:06:53.886258 13672 net.cpp:100] Creating Layer conv3_3
I0622 04:06:53.886258 13672 net.cpp:434] conv3_3 <- conv3_2
I0622 04:06:53.886258 13672 net.cpp:408] conv3_3 -> conv3_3
I0622 04:06:53.907361 13672 net.cpp:150] Setting up conv3_3
I0622 04:06:53.907361 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:53.907361 13672 net.cpp:165] Memory required for data: 368640032
I0622 04:06:53.907361 13672 layer_factory.hpp:77] Creating layer relu3_3
I0622 04:06:53.907361 13672 net.cpp:100] Creating Layer relu3_3
I0622 04:06:53.907361 13672 net.cpp:434] relu3_3 <- conv3_3
I0622 04:06:53.907361 13672 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0622 04:06:53.908594 13672 net.cpp:150] Setting up relu3_3
I0622 04:06:53.908594 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:53.908594 13672 net.cpp:165] Memory required for data: 380160032
I0622 04:06:53.908594 13672 layer_factory.hpp:77] Creating layer pool3
I0622 04:06:53.908594 13672 net.cpp:100] Creating Layer pool3
I0622 04:06:53.908594 13672 net.cpp:434] pool3 <- conv3_3
I0622 04:06:53.908594 13672 net.cpp:408] pool3 -> pool3
I0622 04:06:53.908594 13672 net.cpp:150] Setting up pool3
I0622 04:06:53.908594 13672 net.cpp:157] Top shape: 2 256 38 38 (739328)
I0622 04:06:53.908594 13672 net.cpp:165] Memory required for data: 383117344
I0622 04:06:53.908594 13672 layer_factory.hpp:77] Creating layer conv4_1
I0622 04:06:53.908594 13672 net.cpp:100] Creating Layer conv4_1
I0622 04:06:53.908594 13672 net.cpp:434] conv4_1 <- pool3
I0622 04:06:53.909591 13672 net.cpp:408] conv4_1 -> conv4_1
I0622 04:06:53.936916 13672 net.cpp:150] Setting up conv4_1
I0622 04:06:53.936916 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:53.936916 13672 net.cpp:165] Memory required for data: 389031968
I0622 04:06:53.936916 13672 layer_factory.hpp:77] Creating layer relu4_1
I0622 04:06:53.936916 13672 net.cpp:100] Creating Layer relu4_1
I0622 04:06:53.936916 13672 net.cpp:434] relu4_1 <- conv4_1
I0622 04:06:53.936916 13672 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0622 04:06:53.939203 13672 net.cpp:150] Setting up relu4_1
I0622 04:06:53.939203 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:53.939203 13672 net.cpp:165] Memory required for data: 394946592
I0622 04:06:53.939203 13672 layer_factory.hpp:77] Creating layer conv4_2
I0622 04:06:53.939203 13672 net.cpp:100] Creating Layer conv4_2
I0622 04:06:53.939203 13672 net.cpp:434] conv4_2 <- conv4_1
I0622 04:06:53.939203 13672 net.cpp:408] conv4_2 -> conv4_2
I0622 04:06:53.967306 13672 net.cpp:150] Setting up conv4_2
I0622 04:06:53.967306 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:53.967306 13672 net.cpp:165] Memory required for data: 400861216
I0622 04:06:53.967306 13672 layer_factory.hpp:77] Creating layer relu4_2
I0622 04:06:53.967512 13672 net.cpp:100] Creating Layer relu4_2
I0622 04:06:53.967512 13672 net.cpp:434] relu4_2 <- conv4_2
I0622 04:06:53.967512 13672 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0622 04:06:53.968513 13672 net.cpp:150] Setting up relu4_2
I0622 04:06:53.968513 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:53.968513 13672 net.cpp:165] Memory required for data: 406775840
I0622 04:06:53.968513 13672 layer_factory.hpp:77] Creating layer conv4_3
I0622 04:06:53.968513 13672 net.cpp:100] Creating Layer conv4_3
I0622 04:06:53.968513 13672 net.cpp:434] conv4_3 <- conv4_2
I0622 04:06:53.968513 13672 net.cpp:408] conv4_3 -> conv4_3
I0622 04:06:53.996459 13672 net.cpp:150] Setting up conv4_3
I0622 04:06:53.997458 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:53.997458 13672 net.cpp:165] Memory required for data: 412690464
I0622 04:06:53.997458 13672 layer_factory.hpp:77] Creating layer relu4_3
I0622 04:06:53.997458 13672 net.cpp:100] Creating Layer relu4_3
I0622 04:06:53.997458 13672 net.cpp:434] relu4_3 <- conv4_3
I0622 04:06:53.997567 13672 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0622 04:06:53.998565 13672 net.cpp:150] Setting up relu4_3
I0622 04:06:53.998565 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:53.998565 13672 net.cpp:165] Memory required for data: 418605088
I0622 04:06:53.998565 13672 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0622 04:06:53.998565 13672 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0622 04:06:53.998565 13672 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0622 04:06:53.998565 13672 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0622 04:06:53.998565 13672 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0622 04:06:53.998565 13672 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0622 04:06:53.998565 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:53.998565 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:53.998565 13672 net.cpp:165] Memory required for data: 430434336
I0622 04:06:53.998565 13672 layer_factory.hpp:77] Creating layer pool4
I0622 04:06:53.998565 13672 net.cpp:100] Creating Layer pool4
I0622 04:06:53.998565 13672 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0622 04:06:53.999562 13672 net.cpp:408] pool4 -> pool4
I0622 04:06:53.999562 13672 net.cpp:150] Setting up pool4
I0622 04:06:53.999562 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:53.999562 13672 net.cpp:165] Memory required for data: 431912992
I0622 04:06:53.999562 13672 layer_factory.hpp:77] Creating layer conv5_1
I0622 04:06:53.999562 13672 net.cpp:100] Creating Layer conv5_1
I0622 04:06:53.999562 13672 net.cpp:434] conv5_1 <- pool4
I0622 04:06:53.999562 13672 net.cpp:408] conv5_1 -> conv5_1
I0622 04:06:54.047281 13672 net.cpp:150] Setting up conv5_1
I0622 04:06:54.047281 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:54.047281 13672 net.cpp:165] Memory required for data: 433391648
I0622 04:06:54.047281 13672 layer_factory.hpp:77] Creating layer relu5_1
I0622 04:06:54.047281 13672 net.cpp:100] Creating Layer relu5_1
I0622 04:06:54.047281 13672 net.cpp:434] relu5_1 <- conv5_1
I0622 04:06:54.047281 13672 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0622 04:06:54.048278 13672 net.cpp:150] Setting up relu5_1
I0622 04:06:54.048278 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:54.048278 13672 net.cpp:165] Memory required for data: 434870304
I0622 04:06:54.048278 13672 layer_factory.hpp:77] Creating layer conv5_2
I0622 04:06:54.048278 13672 net.cpp:100] Creating Layer conv5_2
I0622 04:06:54.048278 13672 net.cpp:434] conv5_2 <- conv5_1
I0622 04:06:54.048278 13672 net.cpp:408] conv5_2 -> conv5_2
I0622 04:06:54.070497 13672 net.cpp:150] Setting up conv5_2
I0622 04:06:54.070497 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:54.070497 13672 net.cpp:165] Memory required for data: 436348960
I0622 04:06:54.070497 13672 layer_factory.hpp:77] Creating layer relu5_2
I0622 04:06:54.070497 13672 net.cpp:100] Creating Layer relu5_2
I0622 04:06:54.070497 13672 net.cpp:434] relu5_2 <- conv5_2
I0622 04:06:54.070497 13672 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0622 04:06:54.072556 13672 net.cpp:150] Setting up relu5_2
I0622 04:06:54.072556 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:54.072556 13672 net.cpp:165] Memory required for data: 437827616
I0622 04:06:54.072556 13672 layer_factory.hpp:77] Creating layer conv5_3
I0622 04:06:54.072556 13672 net.cpp:100] Creating Layer conv5_3
I0622 04:06:54.072556 13672 net.cpp:434] conv5_3 <- conv5_2
I0622 04:06:54.072556 13672 net.cpp:408] conv5_3 -> conv5_3
I0622 04:06:54.109989 13672 net.cpp:150] Setting up conv5_3
I0622 04:06:54.109989 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:54.109989 13672 net.cpp:165] Memory required for data: 439306272
I0622 04:06:54.109989 13672 layer_factory.hpp:77] Creating layer relu5_3
I0622 04:06:54.109989 13672 net.cpp:100] Creating Layer relu5_3
I0622 04:06:54.109989 13672 net.cpp:434] relu5_3 <- conv5_3
I0622 04:06:54.109989 13672 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0622 04:06:54.111984 13672 net.cpp:150] Setting up relu5_3
I0622 04:06:54.111984 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:54.111984 13672 net.cpp:165] Memory required for data: 440784928
I0622 04:06:54.111984 13672 layer_factory.hpp:77] Creating layer pool5
I0622 04:06:54.111984 13672 net.cpp:100] Creating Layer pool5
I0622 04:06:54.111984 13672 net.cpp:434] pool5 <- conv5_3
I0622 04:06:54.111984 13672 net.cpp:408] pool5 -> pool5
I0622 04:06:54.111984 13672 net.cpp:150] Setting up pool5
I0622 04:06:54.111984 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:54.111984 13672 net.cpp:165] Memory required for data: 442263584
I0622 04:06:54.111984 13672 layer_factory.hpp:77] Creating layer fc6
I0622 04:06:54.111984 13672 net.cpp:100] Creating Layer fc6
I0622 04:06:54.111984 13672 net.cpp:434] fc6 <- pool5
I0622 04:06:54.111984 13672 net.cpp:408] fc6 -> fc6
I0622 04:06:54.146121 13672 net.cpp:150] Setting up fc6
I0622 04:06:54.146121 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:54.146121 13672 net.cpp:165] Memory required for data: 445220896
I0622 04:06:54.146121 13672 layer_factory.hpp:77] Creating layer relu6
I0622 04:06:54.146121 13672 net.cpp:100] Creating Layer relu6
I0622 04:06:54.146121 13672 net.cpp:434] relu6 <- fc6
I0622 04:06:54.146121 13672 net.cpp:395] relu6 -> fc6 (in-place)
I0622 04:06:54.150512 13672 net.cpp:150] Setting up relu6
I0622 04:06:54.150512 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:54.150512 13672 net.cpp:165] Memory required for data: 448178208
I0622 04:06:54.150512 13672 layer_factory.hpp:77] Creating layer fc7
I0622 04:06:54.150512 13672 net.cpp:100] Creating Layer fc7
I0622 04:06:54.150512 13672 net.cpp:434] fc7 <- fc6
I0622 04:06:54.150512 13672 net.cpp:408] fc7 -> fc7
I0622 04:06:54.163798 13672 net.cpp:150] Setting up fc7
I0622 04:06:54.163798 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:54.163798 13672 net.cpp:165] Memory required for data: 451135520
I0622 04:06:54.163798 13672 layer_factory.hpp:77] Creating layer relu7
I0622 04:06:54.163798 13672 net.cpp:100] Creating Layer relu7
I0622 04:06:54.163798 13672 net.cpp:434] relu7 <- fc7
I0622 04:06:54.163798 13672 net.cpp:395] relu7 -> fc7 (in-place)
I0622 04:06:54.164795 13672 net.cpp:150] Setting up relu7
I0622 04:06:54.164795 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:54.164795 13672 net.cpp:165] Memory required for data: 454092832
I0622 04:06:54.164795 13672 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0622 04:06:54.164795 13672 net.cpp:100] Creating Layer fc7_relu7_0_split
I0622 04:06:54.164795 13672 net.cpp:434] fc7_relu7_0_split <- fc7
I0622 04:06:54.164795 13672 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0622 04:06:54.164795 13672 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0622 04:06:54.164795 13672 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0622 04:06:54.164795 13672 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0622 04:06:54.164795 13672 net.cpp:150] Setting up fc7_relu7_0_split
I0622 04:06:54.164795 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:54.165792 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:54.165792 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:54.165792 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:54.165792 13672 net.cpp:165] Memory required for data: 465922080
I0622 04:06:54.165792 13672 layer_factory.hpp:77] Creating layer conv8_1
I0622 04:06:54.165792 13672 net.cpp:100] Creating Layer conv8_1
I0622 04:06:54.165792 13672 net.cpp:434] conv8_1 <- fc7_relu7_0_split_0
I0622 04:06:54.165792 13672 net.cpp:408] conv8_1 -> conv8_1
I0622 04:06:54.183400 13672 net.cpp:150] Setting up conv8_1
I0622 04:06:54.183400 13672 net.cpp:157] Top shape: 2 256 19 19 (184832)
I0622 04:06:54.183400 13672 net.cpp:165] Memory required for data: 466661408
I0622 04:06:54.183400 13672 layer_factory.hpp:77] Creating layer conv8_1_relu
I0622 04:06:54.183400 13672 net.cpp:100] Creating Layer conv8_1_relu
I0622 04:06:54.183400 13672 net.cpp:434] conv8_1_relu <- conv8_1
I0622 04:06:54.183400 13672 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0622 04:06:54.184397 13672 net.cpp:150] Setting up conv8_1_relu
I0622 04:06:54.184397 13672 net.cpp:157] Top shape: 2 256 19 19 (184832)
I0622 04:06:54.184397 13672 net.cpp:165] Memory required for data: 467400736
I0622 04:06:54.184397 13672 layer_factory.hpp:77] Creating layer conv8_2
I0622 04:06:54.185395 13672 net.cpp:100] Creating Layer conv8_2
I0622 04:06:54.185395 13672 net.cpp:434] conv8_2 <- conv8_1
I0622 04:06:54.185395 13672 net.cpp:408] conv8_2 -> conv8_2
I0622 04:06:54.228369 13672 net.cpp:150] Setting up conv8_2
I0622 04:06:54.228369 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:54.228369 13672 net.cpp:165] Memory required for data: 467810336
I0622 04:06:54.228369 13672 layer_factory.hpp:77] Creating layer conv8_2_relu
I0622 04:06:54.228369 13672 net.cpp:100] Creating Layer conv8_2_relu
I0622 04:06:54.228369 13672 net.cpp:434] conv8_2_relu <- conv8_2
I0622 04:06:54.228369 13672 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0622 04:06:54.247295 13672 net.cpp:150] Setting up conv8_2_relu
I0622 04:06:54.247295 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:54.247295 13672 net.cpp:165] Memory required for data: 468219936
I0622 04:06:54.247295 13672 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0622 04:06:54.247295 13672 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0622 04:06:54.248294 13672 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0622 04:06:54.248294 13672 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0622 04:06:54.248294 13672 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0622 04:06:54.248294 13672 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0622 04:06:54.248294 13672 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0622 04:06:54.248294 13672 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0622 04:06:54.248294 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:54.248294 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:54.248294 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:54.248294 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:54.248294 13672 net.cpp:165] Memory required for data: 469858336
I0622 04:06:54.248294 13672 layer_factory.hpp:77] Creating layer conv9_1
I0622 04:06:54.248294 13672 net.cpp:100] Creating Layer conv9_1
I0622 04:06:54.248294 13672 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0622 04:06:54.248294 13672 net.cpp:408] conv9_1 -> conv9_1
I0622 04:06:54.252281 13672 net.cpp:150] Setting up conv9_1
I0622 04:06:54.252281 13672 net.cpp:157] Top shape: 2 128 10 10 (25600)
I0622 04:06:54.252281 13672 net.cpp:165] Memory required for data: 469960736
I0622 04:06:54.252281 13672 layer_factory.hpp:77] Creating layer conv9_1_relu
I0622 04:06:54.252281 13672 net.cpp:100] Creating Layer conv9_1_relu
I0622 04:06:54.252281 13672 net.cpp:434] conv9_1_relu <- conv9_1
I0622 04:06:54.252281 13672 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0622 04:06:54.253279 13672 net.cpp:150] Setting up conv9_1_relu
I0622 04:06:54.253279 13672 net.cpp:157] Top shape: 2 128 10 10 (25600)
I0622 04:06:54.253279 13672 net.cpp:165] Memory required for data: 470063136
I0622 04:06:54.253279 13672 layer_factory.hpp:77] Creating layer conv9_2
I0622 04:06:54.254276 13672 net.cpp:100] Creating Layer conv9_2
I0622 04:06:54.254276 13672 net.cpp:434] conv9_2 <- conv9_1
I0622 04:06:54.254276 13672 net.cpp:408] conv9_2 -> conv9_2
I0622 04:06:54.266928 13672 net.cpp:150] Setting up conv9_2
I0622 04:06:54.266928 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:54.266928 13672 net.cpp:165] Memory required for data: 470114336
I0622 04:06:54.266928 13672 layer_factory.hpp:77] Creating layer conv9_2_relu
I0622 04:06:54.266928 13672 net.cpp:100] Creating Layer conv9_2_relu
I0622 04:06:54.266928 13672 net.cpp:434] conv9_2_relu <- conv9_2
I0622 04:06:54.266928 13672 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0622 04:06:54.267928 13672 net.cpp:150] Setting up conv9_2_relu
I0622 04:06:54.267928 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:54.267928 13672 net.cpp:165] Memory required for data: 470165536
I0622 04:06:54.267928 13672 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0622 04:06:54.267928 13672 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0622 04:06:54.267928 13672 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0622 04:06:54.267928 13672 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0622 04:06:54.267928 13672 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0622 04:06:54.267928 13672 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0622 04:06:54.267928 13672 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_3
I0622 04:06:54.267928 13672 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0622 04:06:54.267928 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:54.267928 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:54.267928 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:54.267928 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:54.267928 13672 net.cpp:165] Memory required for data: 470370336
I0622 04:06:54.267928 13672 layer_factory.hpp:77] Creating layer conv10_1
I0622 04:06:54.267928 13672 net.cpp:100] Creating Layer conv10_1
I0622 04:06:54.268923 13672 net.cpp:434] conv10_1 <- conv9_2_conv9_2_relu_0_split_0
I0622 04:06:54.268923 13672 net.cpp:408] conv10_1 -> conv10_1
I0622 04:06:54.271915 13672 net.cpp:150] Setting up conv10_1
I0622 04:06:54.272912 13672 net.cpp:157] Top shape: 2 128 5 5 (6400)
I0622 04:06:54.272912 13672 net.cpp:165] Memory required for data: 470395936
I0622 04:06:54.272912 13672 layer_factory.hpp:77] Creating layer conv10_1_relu
I0622 04:06:54.272912 13672 net.cpp:100] Creating Layer conv10_1_relu
I0622 04:06:54.272912 13672 net.cpp:434] conv10_1_relu <- conv10_1
I0622 04:06:54.272912 13672 net.cpp:395] conv10_1_relu -> conv10_1 (in-place)
I0622 04:06:54.272912 13672 net.cpp:150] Setting up conv10_1_relu
I0622 04:06:54.272912 13672 net.cpp:157] Top shape: 2 128 5 5 (6400)
I0622 04:06:54.272912 13672 net.cpp:165] Memory required for data: 470421536
I0622 04:06:54.272912 13672 layer_factory.hpp:77] Creating layer conv10_2
I0622 04:06:54.272912 13672 net.cpp:100] Creating Layer conv10_2
I0622 04:06:54.272912 13672 net.cpp:434] conv10_2 <- conv10_1
I0622 04:06:54.272912 13672 net.cpp:408] conv10_2 -> conv10_2
I0622 04:06:54.282385 13672 net.cpp:150] Setting up conv10_2
I0622 04:06:54.282385 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:54.282385 13672 net.cpp:165] Memory required for data: 470439968
I0622 04:06:54.282385 13672 layer_factory.hpp:77] Creating layer conv10_2_relu
I0622 04:06:54.282385 13672 net.cpp:100] Creating Layer conv10_2_relu
I0622 04:06:54.282385 13672 net.cpp:434] conv10_2_relu <- conv10_2
I0622 04:06:54.282385 13672 net.cpp:395] conv10_2_relu -> conv10_2 (in-place)
I0622 04:06:54.283382 13672 net.cpp:150] Setting up conv10_2_relu
I0622 04:06:54.283382 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:54.283382 13672 net.cpp:165] Memory required for data: 470458400
I0622 04:06:54.283382 13672 layer_factory.hpp:77] Creating layer conv10_2_conv10_2_relu_0_split
I0622 04:06:54.283382 13672 net.cpp:100] Creating Layer conv10_2_conv10_2_relu_0_split
I0622 04:06:54.283382 13672 net.cpp:434] conv10_2_conv10_2_relu_0_split <- conv10_2
I0622 04:06:54.283382 13672 net.cpp:408] conv10_2_conv10_2_relu_0_split -> conv10_2_conv10_2_relu_0_split_0
I0622 04:06:54.283382 13672 net.cpp:408] conv10_2_conv10_2_relu_0_split -> conv10_2_conv10_2_relu_0_split_1
I0622 04:06:54.283382 13672 net.cpp:408] conv10_2_conv10_2_relu_0_split -> conv10_2_conv10_2_relu_0_split_2
I0622 04:06:54.283382 13672 net.cpp:408] conv10_2_conv10_2_relu_0_split -> conv10_2_conv10_2_relu_0_split_3
I0622 04:06:54.283382 13672 net.cpp:150] Setting up conv10_2_conv10_2_relu_0_split
I0622 04:06:54.283382 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:54.283382 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:54.283382 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:54.283382 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:54.285383 13672 net.cpp:165] Memory required for data: 470532128
I0622 04:06:54.285383 13672 layer_factory.hpp:77] Creating layer conv11_1
I0622 04:06:54.285383 13672 net.cpp:100] Creating Layer conv11_1
I0622 04:06:54.285383 13672 net.cpp:434] conv11_1 <- conv10_2_conv10_2_relu_0_split_0
I0622 04:06:54.285383 13672 net.cpp:408] conv11_1 -> conv11_1
I0622 04:06:54.296649 13672 net.cpp:150] Setting up conv11_1
I0622 04:06:54.296649 13672 net.cpp:157] Top shape: 2 128 3 3 (2304)
I0622 04:06:54.296649 13672 net.cpp:165] Memory required for data: 470541344
I0622 04:06:54.296649 13672 layer_factory.hpp:77] Creating layer conv11_1_relu
I0622 04:06:54.296649 13672 net.cpp:100] Creating Layer conv11_1_relu
I0622 04:06:54.296649 13672 net.cpp:434] conv11_1_relu <- conv11_1
I0622 04:06:54.296649 13672 net.cpp:395] conv11_1_relu -> conv11_1 (in-place)
I0622 04:06:54.297647 13672 net.cpp:150] Setting up conv11_1_relu
I0622 04:06:54.297647 13672 net.cpp:157] Top shape: 2 128 3 3 (2304)
I0622 04:06:54.297647 13672 net.cpp:165] Memory required for data: 470550560
I0622 04:06:54.297647 13672 layer_factory.hpp:77] Creating layer conv11_2
I0622 04:06:54.297647 13672 net.cpp:100] Creating Layer conv11_2
I0622 04:06:54.297647 13672 net.cpp:434] conv11_2 <- conv11_1
I0622 04:06:54.297647 13672 net.cpp:408] conv11_2 -> conv11_2
I0622 04:06:54.305711 13672 net.cpp:150] Setting up conv11_2
I0622 04:06:54.305711 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:54.305711 13672 net.cpp:165] Memory required for data: 470552608
I0622 04:06:54.305711 13672 layer_factory.hpp:77] Creating layer conv11_2_relu
I0622 04:06:54.305711 13672 net.cpp:100] Creating Layer conv11_2_relu
I0622 04:06:54.305711 13672 net.cpp:434] conv11_2_relu <- conv11_2
I0622 04:06:54.305711 13672 net.cpp:395] conv11_2_relu -> conv11_2 (in-place)
I0622 04:06:54.306654 13672 net.cpp:150] Setting up conv11_2_relu
I0622 04:06:54.306654 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:54.306654 13672 net.cpp:165] Memory required for data: 470554656
I0622 04:06:54.306654 13672 layer_factory.hpp:77] Creating layer conv11_2_conv11_2_relu_0_split
I0622 04:06:54.306654 13672 net.cpp:100] Creating Layer conv11_2_conv11_2_relu_0_split
I0622 04:06:54.306654 13672 net.cpp:434] conv11_2_conv11_2_relu_0_split <- conv11_2
I0622 04:06:54.306654 13672 net.cpp:408] conv11_2_conv11_2_relu_0_split -> conv11_2_conv11_2_relu_0_split_0
I0622 04:06:54.306654 13672 net.cpp:408] conv11_2_conv11_2_relu_0_split -> conv11_2_conv11_2_relu_0_split_1
I0622 04:06:54.306654 13672 net.cpp:408] conv11_2_conv11_2_relu_0_split -> conv11_2_conv11_2_relu_0_split_2
I0622 04:06:54.306654 13672 net.cpp:150] Setting up conv11_2_conv11_2_relu_0_split
I0622 04:06:54.306654 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:54.306654 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:54.306654 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:54.306654 13672 net.cpp:165] Memory required for data: 470560800
I0622 04:06:54.306654 13672 layer_factory.hpp:77] Creating layer conv4_3_norm
I0622 04:06:54.306654 13672 net.cpp:100] Creating Layer conv4_3_norm
I0622 04:06:54.306654 13672 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0622 04:06:54.306654 13672 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0622 04:06:54.307652 13672 net.cpp:150] Setting up conv4_3_norm
I0622 04:06:54.307652 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:54.307652 13672 net.cpp:165] Memory required for data: 476475424
I0622 04:06:54.307652 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0622 04:06:54.307652 13672 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0622 04:06:54.307652 13672 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0622 04:06:54.307652 13672 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0622 04:06:54.307652 13672 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0622 04:06:54.307652 13672 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0622 04:06:54.307652 13672 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0622 04:06:54.307652 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:54.307652 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:54.307652 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:54.307652 13672 net.cpp:165] Memory required for data: 494219296
I0622 04:06:54.307652 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0622 04:06:54.307652 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0622 04:06:54.307652 13672 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0622 04:06:54.307652 13672 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0622 04:06:54.315109 13672 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0622 04:06:54.315109 13672 net.cpp:157] Top shape: 2 16 38 38 (46208)
I0622 04:06:54.315109 13672 net.cpp:165] Memory required for data: 494404128
I0622 04:06:54.315109 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0622 04:06:54.315109 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0622 04:06:54.315109 13672 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0622 04:06:54.315109 13672 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0622 04:06:54.315109 13672 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0622 04:06:54.315109 13672 net.cpp:157] Top shape: 2 38 38 16 (46208)
I0622 04:06:54.315109 13672 net.cpp:165] Memory required for data: 494588960
I0622 04:06:54.315109 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0622 04:06:54.315109 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0622 04:06:54.315109 13672 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0622 04:06:54.315109 13672 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0622 04:06:54.315109 13672 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0622 04:06:54.315109 13672 net.cpp:157] Top shape: 2 23104 (46208)
I0622 04:06:54.315109 13672 net.cpp:165] Memory required for data: 494773792
I0622 04:06:54.315109 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0622 04:06:54.315109 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0622 04:06:54.315109 13672 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0622 04:06:54.315109 13672 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0622 04:06:54.329349 13672 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0622 04:06:54.329349 13672 net.cpp:157] Top shape: 2 12 38 38 (34656)
I0622 04:06:54.329349 13672 net.cpp:165] Memory required for data: 494912416
I0622 04:06:54.329349 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0622 04:06:54.329349 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0622 04:06:54.329349 13672 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0622 04:06:54.329349 13672 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0622 04:06:54.329349 13672 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0622 04:06:54.329349 13672 net.cpp:157] Top shape: 2 38 38 12 (34656)
I0622 04:06:54.329349 13672 net.cpp:165] Memory required for data: 495051040
I0622 04:06:54.329349 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0622 04:06:54.329349 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0622 04:06:54.329349 13672 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0622 04:06:54.329349 13672 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0622 04:06:54.329349 13672 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0622 04:06:54.329349 13672 net.cpp:157] Top shape: 2 17328 (34656)
I0622 04:06:54.329349 13672 net.cpp:165] Memory required for data: 495189664
I0622 04:06:54.329349 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0622 04:06:54.329349 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0622 04:06:54.329349 13672 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0622 04:06:54.329349 13672 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0622 04:06:54.329349 13672 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0622 04:06:54.329349 13672 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0622 04:06:54.329349 13672 net.cpp:157] Top shape: 1 2 23104 (46208)
I0622 04:06:54.329349 13672 net.cpp:165] Memory required for data: 495374496
I0622 04:06:54.329349 13672 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0622 04:06:54.329349 13672 net.cpp:100] Creating Layer fc7_mbox_loc
I0622 04:06:54.329349 13672 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0622 04:06:54.329349 13672 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0622 04:06:54.351929 13672 net.cpp:150] Setting up fc7_mbox_loc
I0622 04:06:54.351929 13672 net.cpp:157] Top shape: 2 24 19 19 (17328)
I0622 04:06:54.351929 13672 net.cpp:165] Memory required for data: 495443808
I0622 04:06:54.351929 13672 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0622 04:06:54.351929 13672 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0622 04:06:54.351929 13672 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0622 04:06:54.351929 13672 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0622 04:06:54.351929 13672 net.cpp:150] Setting up fc7_mbox_loc_perm
I0622 04:06:54.351929 13672 net.cpp:157] Top shape: 2 19 19 24 (17328)
I0622 04:06:54.351929 13672 net.cpp:165] Memory required for data: 495513120
I0622 04:06:54.351929 13672 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0622 04:06:54.351929 13672 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0622 04:06:54.351929 13672 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0622 04:06:54.351929 13672 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0622 04:06:54.351929 13672 net.cpp:150] Setting up fc7_mbox_loc_flat
I0622 04:06:54.351929 13672 net.cpp:157] Top shape: 2 8664 (17328)
I0622 04:06:54.351929 13672 net.cpp:165] Memory required for data: 495582432
I0622 04:06:54.351929 13672 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0622 04:06:54.351929 13672 net.cpp:100] Creating Layer fc7_mbox_conf
I0622 04:06:54.351929 13672 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0622 04:06:54.351929 13672 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0622 04:06:54.359127 13672 net.cpp:150] Setting up fc7_mbox_conf
I0622 04:06:54.359127 13672 net.cpp:157] Top shape: 2 18 19 19 (12996)
I0622 04:06:54.359127 13672 net.cpp:165] Memory required for data: 495634416
I0622 04:06:54.359127 13672 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0622 04:06:54.359127 13672 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0622 04:06:54.359127 13672 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0622 04:06:54.359127 13672 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0622 04:06:54.359127 13672 net.cpp:150] Setting up fc7_mbox_conf_perm
I0622 04:06:54.359127 13672 net.cpp:157] Top shape: 2 19 19 18 (12996)
I0622 04:06:54.359127 13672 net.cpp:165] Memory required for data: 495686400
I0622 04:06:54.359127 13672 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0622 04:06:54.359127 13672 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0622 04:06:54.359127 13672 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0622 04:06:54.359127 13672 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0622 04:06:54.359127 13672 net.cpp:150] Setting up fc7_mbox_conf_flat
I0622 04:06:54.359127 13672 net.cpp:157] Top shape: 2 6498 (12996)
I0622 04:06:54.359127 13672 net.cpp:165] Memory required for data: 495738384
I0622 04:06:54.359127 13672 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0622 04:06:54.359127 13672 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0622 04:06:54.359127 13672 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0622 04:06:54.359127 13672 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0622 04:06:54.359127 13672 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0622 04:06:54.359127 13672 net.cpp:150] Setting up fc7_mbox_priorbox
I0622 04:06:54.359127 13672 net.cpp:157] Top shape: 1 2 8664 (17328)
I0622 04:06:54.359127 13672 net.cpp:165] Memory required for data: 495807696
I0622 04:06:54.359127 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0622 04:06:54.359127 13672 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0622 04:06:54.359127 13672 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0622 04:06:54.359127 13672 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0622 04:06:54.366415 13672 net.cpp:150] Setting up conv8_2_mbox_loc
I0622 04:06:54.366415 13672 net.cpp:157] Top shape: 2 24 10 10 (4800)
I0622 04:06:54.366415 13672 net.cpp:165] Memory required for data: 495826896
I0622 04:06:54.366415 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0622 04:06:54.366415 13672 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0622 04:06:54.366415 13672 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0622 04:06:54.366415 13672 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0622 04:06:54.366415 13672 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0622 04:06:54.366415 13672 net.cpp:157] Top shape: 2 10 10 24 (4800)
I0622 04:06:54.366415 13672 net.cpp:165] Memory required for data: 495846096
I0622 04:06:54.366415 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0622 04:06:54.366415 13672 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0622 04:06:54.366415 13672 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0622 04:06:54.366415 13672 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0622 04:06:54.366415 13672 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0622 04:06:54.366415 13672 net.cpp:157] Top shape: 2 2400 (4800)
I0622 04:06:54.366415 13672 net.cpp:165] Memory required for data: 495865296
I0622 04:06:54.366415 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0622 04:06:54.366415 13672 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0622 04:06:54.366415 13672 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0622 04:06:54.366415 13672 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0622 04:06:54.399403 13672 net.cpp:150] Setting up conv8_2_mbox_conf
I0622 04:06:54.399403 13672 net.cpp:157] Top shape: 2 18 10 10 (3600)
I0622 04:06:54.399403 13672 net.cpp:165] Memory required for data: 495879696
I0622 04:06:54.399403 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0622 04:06:54.399403 13672 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0622 04:06:54.399403 13672 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0622 04:06:54.399403 13672 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0622 04:06:54.399403 13672 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0622 04:06:54.399403 13672 net.cpp:157] Top shape: 2 10 10 18 (3600)
I0622 04:06:54.399403 13672 net.cpp:165] Memory required for data: 495894096
I0622 04:06:54.399403 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0622 04:06:54.399403 13672 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0622 04:06:54.399403 13672 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0622 04:06:54.399403 13672 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0622 04:06:54.399403 13672 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0622 04:06:54.399403 13672 net.cpp:157] Top shape: 2 1800 (3600)
I0622 04:06:54.399403 13672 net.cpp:165] Memory required for data: 495908496
I0622 04:06:54.399403 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0622 04:06:54.399403 13672 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0622 04:06:54.399403 13672 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0622 04:06:54.399403 13672 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_3
I0622 04:06:54.399403 13672 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0622 04:06:54.400400 13672 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0622 04:06:54.400413 13672 net.cpp:157] Top shape: 1 2 2400 (4800)
I0622 04:06:54.400413 13672 net.cpp:165] Memory required for data: 495927696
I0622 04:06:54.400413 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0622 04:06:54.400413 13672 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0622 04:06:54.400413 13672 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_1
I0622 04:06:54.400413 13672 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0622 04:06:54.404402 13672 net.cpp:150] Setting up conv9_2_mbox_loc
I0622 04:06:54.404402 13672 net.cpp:157] Top shape: 2 24 5 5 (1200)
I0622 04:06:54.404402 13672 net.cpp:165] Memory required for data: 495932496
I0622 04:06:54.404402 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0622 04:06:54.404402 13672 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0622 04:06:54.404402 13672 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0622 04:06:54.404402 13672 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0622 04:06:54.404402 13672 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0622 04:06:54.404402 13672 net.cpp:157] Top shape: 2 5 5 24 (1200)
I0622 04:06:54.404402 13672 net.cpp:165] Memory required for data: 495937296
I0622 04:06:54.404402 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0622 04:06:54.404402 13672 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0622 04:06:54.404402 13672 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0622 04:06:54.404402 13672 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0622 04:06:54.405400 13672 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0622 04:06:54.405400 13672 net.cpp:157] Top shape: 2 600 (1200)
I0622 04:06:54.405400 13672 net.cpp:165] Memory required for data: 495942096
I0622 04:06:54.405400 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0622 04:06:54.405400 13672 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0622 04:06:54.405400 13672 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_2
I0622 04:06:54.405400 13672 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0622 04:06:54.410387 13672 net.cpp:150] Setting up conv9_2_mbox_conf
I0622 04:06:54.410387 13672 net.cpp:157] Top shape: 2 18 5 5 (900)
I0622 04:06:54.410387 13672 net.cpp:165] Memory required for data: 495945696
I0622 04:06:54.410387 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0622 04:06:54.410387 13672 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0622 04:06:54.410387 13672 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0622 04:06:54.410387 13672 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0622 04:06:54.410387 13672 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0622 04:06:54.410387 13672 net.cpp:157] Top shape: 2 5 5 18 (900)
I0622 04:06:54.410387 13672 net.cpp:165] Memory required for data: 495949296
I0622 04:06:54.410387 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0622 04:06:54.410387 13672 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0622 04:06:54.410387 13672 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0622 04:06:54.410387 13672 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0622 04:06:54.410387 13672 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0622 04:06:54.410387 13672 net.cpp:157] Top shape: 2 450 (900)
I0622 04:06:54.410387 13672 net.cpp:165] Memory required for data: 495952896
I0622 04:06:54.410387 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0622 04:06:54.410387 13672 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0622 04:06:54.410387 13672 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_3
I0622 04:06:54.410387 13672 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_4
I0622 04:06:54.410387 13672 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0622 04:06:54.410387 13672 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0622 04:06:54.410387 13672 net.cpp:157] Top shape: 1 2 600 (1200)
I0622 04:06:54.410387 13672 net.cpp:165] Memory required for data: 495957696
I0622 04:06:54.410387 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_loc
I0622 04:06:54.410387 13672 net.cpp:100] Creating Layer conv10_2_mbox_loc
I0622 04:06:54.410387 13672 net.cpp:434] conv10_2_mbox_loc <- conv10_2_conv10_2_relu_0_split_1
I0622 04:06:54.410387 13672 net.cpp:408] conv10_2_mbox_loc -> conv10_2_mbox_loc
I0622 04:06:54.457005 13672 net.cpp:150] Setting up conv10_2_mbox_loc
I0622 04:06:54.457005 13672 net.cpp:157] Top shape: 2 16 3 3 (288)
I0622 04:06:54.457005 13672 net.cpp:165] Memory required for data: 495958848
I0622 04:06:54.457005 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_loc_perm
I0622 04:06:54.457005 13672 net.cpp:100] Creating Layer conv10_2_mbox_loc_perm
I0622 04:06:54.457005 13672 net.cpp:434] conv10_2_mbox_loc_perm <- conv10_2_mbox_loc
I0622 04:06:54.457005 13672 net.cpp:408] conv10_2_mbox_loc_perm -> conv10_2_mbox_loc_perm
I0622 04:06:54.457631 13672 net.cpp:150] Setting up conv10_2_mbox_loc_perm
I0622 04:06:54.457631 13672 net.cpp:157] Top shape: 2 3 3 16 (288)
I0622 04:06:54.457631 13672 net.cpp:165] Memory required for data: 495960000
I0622 04:06:54.457631 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_loc_flat
I0622 04:06:54.457631 13672 net.cpp:100] Creating Layer conv10_2_mbox_loc_flat
I0622 04:06:54.457631 13672 net.cpp:434] conv10_2_mbox_loc_flat <- conv10_2_mbox_loc_perm
I0622 04:06:54.457631 13672 net.cpp:408] conv10_2_mbox_loc_flat -> conv10_2_mbox_loc_flat
I0622 04:06:54.457631 13672 net.cpp:150] Setting up conv10_2_mbox_loc_flat
I0622 04:06:54.457631 13672 net.cpp:157] Top shape: 2 144 (288)
I0622 04:06:54.457631 13672 net.cpp:165] Memory required for data: 495961152
I0622 04:06:54.457631 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_conf
I0622 04:06:54.457631 13672 net.cpp:100] Creating Layer conv10_2_mbox_conf
I0622 04:06:54.457631 13672 net.cpp:434] conv10_2_mbox_conf <- conv10_2_conv10_2_relu_0_split_2
I0622 04:06:54.457631 13672 net.cpp:408] conv10_2_mbox_conf -> conv10_2_mbox_conf
I0622 04:06:54.462823 13672 net.cpp:150] Setting up conv10_2_mbox_conf
I0622 04:06:54.462823 13672 net.cpp:157] Top shape: 2 12 3 3 (216)
I0622 04:06:54.462823 13672 net.cpp:165] Memory required for data: 495962016
I0622 04:06:54.462823 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_conf_perm
I0622 04:06:54.462823 13672 net.cpp:100] Creating Layer conv10_2_mbox_conf_perm
I0622 04:06:54.462823 13672 net.cpp:434] conv10_2_mbox_conf_perm <- conv10_2_mbox_conf
I0622 04:06:54.462823 13672 net.cpp:408] conv10_2_mbox_conf_perm -> conv10_2_mbox_conf_perm
I0622 04:06:54.462823 13672 net.cpp:150] Setting up conv10_2_mbox_conf_perm
I0622 04:06:54.462823 13672 net.cpp:157] Top shape: 2 3 3 12 (216)
I0622 04:06:54.462823 13672 net.cpp:165] Memory required for data: 495962880
I0622 04:06:54.462823 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_conf_flat
I0622 04:06:54.462823 13672 net.cpp:100] Creating Layer conv10_2_mbox_conf_flat
I0622 04:06:54.462823 13672 net.cpp:434] conv10_2_mbox_conf_flat <- conv10_2_mbox_conf_perm
I0622 04:06:54.462823 13672 net.cpp:408] conv10_2_mbox_conf_flat -> conv10_2_mbox_conf_flat
I0622 04:06:54.462823 13672 net.cpp:150] Setting up conv10_2_mbox_conf_flat
I0622 04:06:54.462823 13672 net.cpp:157] Top shape: 2 108 (216)
I0622 04:06:54.462823 13672 net.cpp:165] Memory required for data: 495963744
I0622 04:06:54.462823 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_priorbox
I0622 04:06:54.463820 13672 net.cpp:100] Creating Layer conv10_2_mbox_priorbox
I0622 04:06:54.463820 13672 net.cpp:434] conv10_2_mbox_priorbox <- conv10_2_conv10_2_relu_0_split_3
I0622 04:06:54.463820 13672 net.cpp:434] conv10_2_mbox_priorbox <- data_data_0_split_5
I0622 04:06:54.463820 13672 net.cpp:408] conv10_2_mbox_priorbox -> conv10_2_mbox_priorbox
I0622 04:06:54.463820 13672 net.cpp:150] Setting up conv10_2_mbox_priorbox
I0622 04:06:54.463820 13672 net.cpp:157] Top shape: 1 2 144 (288)
I0622 04:06:54.463820 13672 net.cpp:165] Memory required for data: 495964896
I0622 04:06:54.463820 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_loc
I0622 04:06:54.463820 13672 net.cpp:100] Creating Layer conv11_2_mbox_loc
I0622 04:06:54.463820 13672 net.cpp:434] conv11_2_mbox_loc <- conv11_2_conv11_2_relu_0_split_0
I0622 04:06:54.463820 13672 net.cpp:408] conv11_2_mbox_loc -> conv11_2_mbox_loc
I0622 04:06:54.467586 13672 net.cpp:150] Setting up conv11_2_mbox_loc
I0622 04:06:54.467586 13672 net.cpp:157] Top shape: 2 16 1 1 (32)
I0622 04:06:54.467586 13672 net.cpp:165] Memory required for data: 495965024
I0622 04:06:54.467586 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_loc_perm
I0622 04:06:54.467586 13672 net.cpp:100] Creating Layer conv11_2_mbox_loc_perm
I0622 04:06:54.467586 13672 net.cpp:434] conv11_2_mbox_loc_perm <- conv11_2_mbox_loc
I0622 04:06:54.467586 13672 net.cpp:408] conv11_2_mbox_loc_perm -> conv11_2_mbox_loc_perm
I0622 04:06:54.467586 13672 net.cpp:150] Setting up conv11_2_mbox_loc_perm
I0622 04:06:54.467586 13672 net.cpp:157] Top shape: 2 1 1 16 (32)
I0622 04:06:54.467586 13672 net.cpp:165] Memory required for data: 495965152
I0622 04:06:54.467586 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_loc_flat
I0622 04:06:54.467586 13672 net.cpp:100] Creating Layer conv11_2_mbox_loc_flat
I0622 04:06:54.467586 13672 net.cpp:434] conv11_2_mbox_loc_flat <- conv11_2_mbox_loc_perm
I0622 04:06:54.467586 13672 net.cpp:408] conv11_2_mbox_loc_flat -> conv11_2_mbox_loc_flat
I0622 04:06:54.467586 13672 net.cpp:150] Setting up conv11_2_mbox_loc_flat
I0622 04:06:54.467586 13672 net.cpp:157] Top shape: 2 16 (32)
I0622 04:06:54.467586 13672 net.cpp:165] Memory required for data: 495965280
I0622 04:06:54.467586 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_conf
I0622 04:06:54.467586 13672 net.cpp:100] Creating Layer conv11_2_mbox_conf
I0622 04:06:54.467586 13672 net.cpp:434] conv11_2_mbox_conf <- conv11_2_conv11_2_relu_0_split_1
I0622 04:06:54.467586 13672 net.cpp:408] conv11_2_mbox_conf -> conv11_2_mbox_conf
I0622 04:06:54.472450 13672 net.cpp:150] Setting up conv11_2_mbox_conf
I0622 04:06:54.472450 13672 net.cpp:157] Top shape: 2 12 1 1 (24)
I0622 04:06:54.472450 13672 net.cpp:165] Memory required for data: 495965376
I0622 04:06:54.472450 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_conf_perm
I0622 04:06:54.472450 13672 net.cpp:100] Creating Layer conv11_2_mbox_conf_perm
I0622 04:06:54.472450 13672 net.cpp:434] conv11_2_mbox_conf_perm <- conv11_2_mbox_conf
I0622 04:06:54.472450 13672 net.cpp:408] conv11_2_mbox_conf_perm -> conv11_2_mbox_conf_perm
I0622 04:06:54.472450 13672 net.cpp:150] Setting up conv11_2_mbox_conf_perm
I0622 04:06:54.472450 13672 net.cpp:157] Top shape: 2 1 1 12 (24)
I0622 04:06:54.472450 13672 net.cpp:165] Memory required for data: 495965472
I0622 04:06:54.472450 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_conf_flat
I0622 04:06:54.472450 13672 net.cpp:100] Creating Layer conv11_2_mbox_conf_flat
I0622 04:06:54.472450 13672 net.cpp:434] conv11_2_mbox_conf_flat <- conv11_2_mbox_conf_perm
I0622 04:06:54.472450 13672 net.cpp:408] conv11_2_mbox_conf_flat -> conv11_2_mbox_conf_flat
I0622 04:06:54.472450 13672 net.cpp:150] Setting up conv11_2_mbox_conf_flat
I0622 04:06:54.472450 13672 net.cpp:157] Top shape: 2 12 (24)
I0622 04:06:54.472450 13672 net.cpp:165] Memory required for data: 495965568
I0622 04:06:54.472450 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_priorbox
I0622 04:06:54.472450 13672 net.cpp:100] Creating Layer conv11_2_mbox_priorbox
I0622 04:06:54.472450 13672 net.cpp:434] conv11_2_mbox_priorbox <- conv11_2_conv11_2_relu_0_split_2
I0622 04:06:54.497822 13672 net.cpp:434] conv11_2_mbox_priorbox <- data_data_0_split_6
I0622 04:06:54.497822 13672 net.cpp:408] conv11_2_mbox_priorbox -> conv11_2_mbox_priorbox
I0622 04:06:54.498783 13672 net.cpp:150] Setting up conv11_2_mbox_priorbox
I0622 04:06:54.498783 13672 net.cpp:157] Top shape: 1 2 16 (32)
I0622 04:06:54.498783 13672 net.cpp:165] Memory required for data: 495965696
I0622 04:06:54.498783 13672 layer_factory.hpp:77] Creating layer mbox_loc
I0622 04:06:54.498783 13672 net.cpp:100] Creating Layer mbox_loc
I0622 04:06:54.498783 13672 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0622 04:06:54.498783 13672 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0622 04:06:54.498783 13672 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0622 04:06:54.498783 13672 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0622 04:06:54.498783 13672 net.cpp:434] mbox_loc <- conv10_2_mbox_loc_flat
I0622 04:06:54.498783 13672 net.cpp:434] mbox_loc <- conv11_2_mbox_loc_flat
I0622 04:06:54.498783 13672 net.cpp:408] mbox_loc -> mbox_loc
I0622 04:06:54.499784 13672 net.cpp:150] Setting up mbox_loc
I0622 04:06:54.499784 13672 net.cpp:157] Top shape: 2 34928 (69856)
I0622 04:06:54.499784 13672 net.cpp:165] Memory required for data: 496245120
I0622 04:06:54.499784 13672 layer_factory.hpp:77] Creating layer mbox_conf
I0622 04:06:54.499784 13672 net.cpp:100] Creating Layer mbox_conf
I0622 04:06:54.499784 13672 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0622 04:06:54.499784 13672 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0622 04:06:54.499784 13672 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0622 04:06:54.499784 13672 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0622 04:06:54.499784 13672 net.cpp:434] mbox_conf <- conv10_2_mbox_conf_flat
I0622 04:06:54.499784 13672 net.cpp:434] mbox_conf <- conv11_2_mbox_conf_flat
I0622 04:06:54.499784 13672 net.cpp:408] mbox_conf -> mbox_conf
I0622 04:06:54.499784 13672 net.cpp:150] Setting up mbox_conf
I0622 04:06:54.499784 13672 net.cpp:157] Top shape: 2 26196 (52392)
I0622 04:06:54.501812 13672 net.cpp:165] Memory required for data: 496454688
I0622 04:06:54.501812 13672 layer_factory.hpp:77] Creating layer mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:100] Creating Layer mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:434] mbox_priorbox <- conv10_2_mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:434] mbox_priorbox <- conv11_2_mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:150] Setting up mbox_priorbox
I0622 04:06:54.501812 13672 net.cpp:157] Top shape: 1 2 34928 (69856)
I0622 04:06:54.501812 13672 net.cpp:165] Memory required for data: 496734112
I0622 04:06:54.503806 13672 layer_factory.hpp:77] Creating layer mbox_loss
I0622 04:06:54.503806 13672 net.cpp:100] Creating Layer mbox_loss
I0622 04:06:54.503806 13672 net.cpp:434] mbox_loss <- mbox_loc
I0622 04:06:54.503806 13672 net.cpp:434] mbox_loss <- mbox_conf
I0622 04:06:54.503806 13672 net.cpp:434] mbox_loss <- mbox_priorbox
I0622 04:06:54.503806 13672 net.cpp:434] mbox_loss <- label
I0622 04:06:54.503806 13672 net.cpp:408] mbox_loss -> mbox_loss
I0622 04:06:54.503806 13672 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0622 04:06:54.503806 13672 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0622 04:06:54.503806 13672 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0622 04:06:54.505769 13672 net.cpp:150] Setting up mbox_loss
I0622 04:06:54.505769 13672 net.cpp:157] Top shape: (1)
I0622 04:06:54.505769 13672 net.cpp:160]     with loss weight 1
I0622 04:06:54.505769 13672 net.cpp:165] Memory required for data: 496734116
I0622 04:06:54.505769 13672 net.cpp:226] mbox_loss needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:228] mbox_priorbox does not need backward computation.
I0622 04:06:54.505769 13672 net.cpp:226] mbox_conf needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:226] mbox_loc needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:228] conv11_2_mbox_priorbox does not need backward computation.
I0622 04:06:54.505769 13672 net.cpp:226] conv11_2_mbox_conf_flat needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:226] conv11_2_mbox_conf_perm needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:226] conv11_2_mbox_conf needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:226] conv11_2_mbox_loc_flat needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:226] conv11_2_mbox_loc_perm needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:226] conv11_2_mbox_loc needs backward computation.
I0622 04:06:54.505769 13672 net.cpp:228] conv10_2_mbox_priorbox does not need backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv10_2_mbox_conf_flat needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv10_2_mbox_conf_perm needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv10_2_mbox_conf needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv10_2_mbox_loc_flat needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv10_2_mbox_loc_perm needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv10_2_mbox_loc needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv9_2_mbox_conf_flat needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv9_2_mbox_conf_perm needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv9_2_mbox_conf needs backward computation.
I0622 04:06:54.507797 13672 net.cpp:226] conv9_2_mbox_loc_flat needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] conv9_2_mbox_loc_perm needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] conv9_2_mbox_loc needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] conv8_2_mbox_conf_flat needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] conv8_2_mbox_conf_perm needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] conv8_2_mbox_conf needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] conv8_2_mbox_loc_flat needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] conv8_2_mbox_loc_perm needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] conv8_2_mbox_loc needs backward computation.
I0622 04:06:54.513792 13672 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0622 04:06:54.513792 13672 net.cpp:226] fc7_mbox_conf_flat needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] fc7_mbox_conf_perm needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] fc7_mbox_conf needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] fc7_mbox_loc_flat needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] fc7_mbox_loc_perm needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] fc7_mbox_loc needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] conv4_3_norm_mbox_conf_flat needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] conv4_3_norm_mbox_conf_perm needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] conv4_3_norm_mbox_conf needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] conv4_3_norm_mbox_loc_flat needs backward computation.
I0622 04:06:54.515786 13672 net.cpp:226] conv4_3_norm_mbox_loc_perm needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv4_3_norm_mbox_loc needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv4_3_norm needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv11_2_conv11_2_relu_0_split needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv11_2_relu needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv11_2 needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv11_1_relu needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv11_1 needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv10_2_conv10_2_relu_0_split needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv10_2_relu needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv10_2 needs backward computation.
I0622 04:06:54.517778 13672 net.cpp:226] conv10_1_relu needs backward computation.
I0622 04:06:54.518744 13672 net.cpp:226] conv10_1 needs backward computation.
I0622 04:06:54.518744 13672 net.cpp:226] conv9_2_conv9_2_relu_0_split needs backward computation.
I0622 04:06:54.518744 13672 net.cpp:226] conv9_2_relu needs backward computation.
I0622 04:06:54.518744 13672 net.cpp:226] conv9_2 needs backward computation.
I0622 04:06:54.518744 13672 net.cpp:226] conv9_1_relu needs backward computation.
I0622 04:06:54.518744 13672 net.cpp:226] conv9_1 needs backward computation.
I0622 04:06:54.518744 13672 net.cpp:226] conv8_2_conv8_2_relu_0_split needs backward computation.
I0622 04:06:54.519740 13672 net.cpp:226] conv8_2_relu needs backward computation.
I0622 04:06:54.519740 13672 net.cpp:226] conv8_2 needs backward computation.
I0622 04:06:54.519740 13672 net.cpp:226] conv8_1_relu needs backward computation.
I0622 04:06:54.519740 13672 net.cpp:226] conv8_1 needs backward computation.
I0622 04:06:54.519740 13672 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] relu7 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] fc7 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] relu6 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] fc6 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] pool5 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] relu5_3 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] conv5_3 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] relu5_2 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] conv5_2 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] relu5_1 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] conv5_1 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] pool4 needs backward computation.
I0622 04:06:54.520740 13672 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] relu4_3 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] conv4_3 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] relu4_2 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] conv4_2 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] relu4_1 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] conv4_1 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] pool3 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] relu3_3 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] conv3_3 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] relu3_2 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] conv3_2 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] relu3_1 needs backward computation.
I0622 04:06:54.522766 13672 net.cpp:226] conv3_1 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] pool2 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] relu2_2 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] conv2_2 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] relu2_1 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] conv2_1 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] pool1 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] relu1_2 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] conv1_2 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] relu1_1 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:226] conv1_1 needs backward computation.
I0622 04:06:54.523730 13672 net.cpp:228] data_data_0_split does not need backward computation.
I0622 04:06:54.523730 13672 net.cpp:228] data does not need backward computation.
I0622 04:06:54.523730 13672 net.cpp:270] This network produces output mbox_loss
I0622 04:06:54.530861 13672 net.cpp:283] Network initialization done.
I0622 04:06:54.531824 13672 solver.cpp:196] Creating test net (#0) specified by test_net file: models\VGGNet\wastedata\SSD_300x300\test.prototxt
I0622 04:06:54.532821 13672 net.cpp:58] Initializing net from parameters: 
name: "VGG_wastedata_SSD_300x300_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "examples\\wastedata\\wastedata_test_lmdb"
    batch_size: 2
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "data\\wastedata\\labelmap_waste.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv10_1"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv10_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv10_1_relu"
  type: "ReLU"
  bottom: "conv10_1"
  top: "conv10_1"
}
layer {
  name: "conv10_2"
  type: "Convolution"
  bottom: "conv10_1"
  top: "conv10_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv10_2_relu"
  type: "ReLU"
  bottom: "conv10_2"
  top: "conv10_2"
}
layer {
  name: "conv11_1"
  type: "Convolution"
  bottom: "conv10_2"
  top: "conv11_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_1_relu"
  type: "ReLU"
  bottom: "conv11_1"
  top: "conv11_1"
}
layer {
  name: "conv11_2"
  type: "Convolution"
  bottom: "conv11_1"
  top: "conv11_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_2_relu"
  type: "ReLU"
  bottom: "conv11_2"
  top: "conv11_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv10_2_mbox_loc"
  type: "Convolution"
  bottom: "conv10_2"
  top: "conv10_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv10_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv10_2_mbox_loc"
  top: "conv10_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv10_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv10_2_mbox_loc_perm"
  top: "conv10_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv10_2_mbox_conf"
  type: "Convolution"
  bottom: "conv10_2"
  top: "conv10_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv10_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv10_2_mbox_conf"
  top: "conv10_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv10_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv10_2_mbox_conf_perm"
  top: "conv10_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv10_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv10_2"
  bottom: "data"
  top: "conv10_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv11_2_mbox_loc"
  type: "Convolution"
  bottom: "conv11_2"
  top: "conv11_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv11_2_mbox_loc"
  top: "conv11_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv11_2_mbox_loc_perm"
  top: "conv11_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_2_mbox_conf"
  type: "Convolution"
  bottom: "conv11_2"
  top: "conv11_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv11_2_mbox_conf"
  top: "conv11_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv11_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv11_2_mbox_conf_perm"
  top: "conv11_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv11_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv11_2"
  bottom: "data"
  top: "conv11_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  bottom: "conv10_2_mbox_loc_flat"
  bottom: "conv11_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  bottom: "conv10_2_mbox_conf_flat"
  bottom: "conv11_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  bottom: "conv10_2_mbox_priorbox"
  bottom: "conv11_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 3
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 3
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "data\\wastedata\\results\\SSD_300x300\\Main"
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "data\\wastedata\\labelmap_waste.prototxt"
      name_size_file: "data\\wastedata\\test_name_size.txt"
      num_test_image: 1000
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 3
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "data\\wastedata\\test_name_size.txt"
  }
}
I0622 04:06:54.796533 13672 layer_factory.hpp:77] Creating layer data
I0622 04:06:54.796533 13672 net.cpp:100] Creating Layer data
I0622 04:06:54.796533 13672 net.cpp:408] data -> data
I0622 04:06:54.796533 13672 net.cpp:408] data -> label
I0622 04:06:54.800523 13268 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0622 04:06:54.878458 13268 db_lmdb.cpp:40] Opened lmdb examples\wastedata\wastedata_test_lmdb
I0622 04:06:54.896049 13672 annotated_data_layer.cpp:62] output data size: 2,3,300,300
I0622 04:06:54.911412 13672 net.cpp:150] Setting up data
I0622 04:06:54.911412 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:54.911412 13672 net.cpp:157] Top shape: 1 1 3 8 (24)
I0622 04:06:54.911412 13672 net.cpp:165] Memory required for data: 2160096
I0622 04:06:54.911412 13672 layer_factory.hpp:77] Creating layer data_data_0_split
I0622 04:06:54.911412 13672 net.cpp:100] Creating Layer data_data_0_split
I0622 04:06:54.911412 13672 net.cpp:434] data_data_0_split <- data
I0622 04:06:54.911412 13672 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0622 04:06:54.911412 13672 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0622 04:06:54.911412 13672 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0622 04:06:54.911412 13672 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0622 04:06:54.911412 13672 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0622 04:06:54.911412 13672 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0622 04:06:54.911412 13672 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0622 04:06:54.912408 13672 net.cpp:150] Setting up data_data_0_split
I0622 04:06:54.912408 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:54.912408 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:54.912408 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:54.912408 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:54.912408 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:54.912408 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:54.912408 13672 net.cpp:157] Top shape: 2 3 300 300 (540000)
I0622 04:06:54.912408 13672 net.cpp:165] Memory required for data: 17280096
I0622 04:06:54.912408 13672 layer_factory.hpp:77] Creating layer conv1_1
I0622 04:06:54.912408 13672 net.cpp:100] Creating Layer conv1_1
I0622 04:06:54.912408 13672 net.cpp:434] conv1_1 <- data_data_0_split_0
I0622 04:06:54.912408 13672 net.cpp:408] conv1_1 -> conv1_1
I0622 04:06:54.915400 12540 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0622 04:06:54.918392 13672 net.cpp:150] Setting up conv1_1
I0622 04:06:54.918392 13672 net.cpp:157] Top shape: 2 64 300 300 (11520000)
I0622 04:06:54.918392 13672 net.cpp:165] Memory required for data: 63360096
I0622 04:06:54.918392 13672 layer_factory.hpp:77] Creating layer relu1_1
I0622 04:06:54.918392 13672 net.cpp:100] Creating Layer relu1_1
I0622 04:06:54.918392 13672 net.cpp:434] relu1_1 <- conv1_1
I0622 04:06:54.918392 13672 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0622 04:06:54.919389 13672 net.cpp:150] Setting up relu1_1
I0622 04:06:54.919389 13672 net.cpp:157] Top shape: 2 64 300 300 (11520000)
I0622 04:06:54.919389 13672 net.cpp:165] Memory required for data: 109440096
I0622 04:06:54.919389 13672 layer_factory.hpp:77] Creating layer conv1_2
I0622 04:06:54.919389 13672 net.cpp:100] Creating Layer conv1_2
I0622 04:06:54.919389 13672 net.cpp:434] conv1_2 <- conv1_1
I0622 04:06:54.919389 13672 net.cpp:408] conv1_2 -> conv1_2
I0622 04:06:54.926970 13672 net.cpp:150] Setting up conv1_2
I0622 04:06:54.926970 13672 net.cpp:157] Top shape: 2 64 300 300 (11520000)
I0622 04:06:54.926970 13672 net.cpp:165] Memory required for data: 155520096
I0622 04:06:54.926970 13672 layer_factory.hpp:77] Creating layer relu1_2
I0622 04:06:54.926970 13672 net.cpp:100] Creating Layer relu1_2
I0622 04:06:54.926970 13672 net.cpp:434] relu1_2 <- conv1_2
I0622 04:06:54.926970 13672 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0622 04:06:54.929150 13672 net.cpp:150] Setting up relu1_2
I0622 04:06:54.929150 13672 net.cpp:157] Top shape: 2 64 300 300 (11520000)
I0622 04:06:54.929150 13672 net.cpp:165] Memory required for data: 201600096
I0622 04:06:54.929150 13672 layer_factory.hpp:77] Creating layer pool1
I0622 04:06:54.929150 13672 net.cpp:100] Creating Layer pool1
I0622 04:06:54.929150 13672 net.cpp:434] pool1 <- conv1_2
I0622 04:06:54.929150 13672 net.cpp:408] pool1 -> pool1
I0622 04:06:54.929150 13672 net.cpp:150] Setting up pool1
I0622 04:06:54.929150 13672 net.cpp:157] Top shape: 2 64 150 150 (2880000)
I0622 04:06:54.929150 13672 net.cpp:165] Memory required for data: 213120096
I0622 04:06:54.929150 13672 layer_factory.hpp:77] Creating layer conv2_1
I0622 04:06:54.929150 13672 net.cpp:100] Creating Layer conv2_1
I0622 04:06:54.929150 13672 net.cpp:434] conv2_1 <- pool1
I0622 04:06:54.929150 13672 net.cpp:408] conv2_1 -> conv2_1
I0622 04:06:54.964851 13672 net.cpp:150] Setting up conv2_1
I0622 04:06:54.964851 13672 net.cpp:157] Top shape: 2 128 150 150 (5760000)
I0622 04:06:54.964851 13672 net.cpp:165] Memory required for data: 236160096
I0622 04:06:54.964851 13672 layer_factory.hpp:77] Creating layer relu2_1
I0622 04:06:54.964851 13672 net.cpp:100] Creating Layer relu2_1
I0622 04:06:54.964851 13672 net.cpp:434] relu2_1 <- conv2_1
I0622 04:06:54.964851 13672 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0622 04:06:54.966845 13672 net.cpp:150] Setting up relu2_1
I0622 04:06:54.966845 13672 net.cpp:157] Top shape: 2 128 150 150 (5760000)
I0622 04:06:54.966845 13672 net.cpp:165] Memory required for data: 259200096
I0622 04:06:54.966845 13672 layer_factory.hpp:77] Creating layer conv2_2
I0622 04:06:54.966845 13672 net.cpp:100] Creating Layer conv2_2
I0622 04:06:54.966845 13672 net.cpp:434] conv2_2 <- conv2_1
I0622 04:06:54.966845 13672 net.cpp:408] conv2_2 -> conv2_2
I0622 04:06:54.985975 13672 net.cpp:150] Setting up conv2_2
I0622 04:06:54.985975 13672 net.cpp:157] Top shape: 2 128 150 150 (5760000)
I0622 04:06:54.985975 13672 net.cpp:165] Memory required for data: 282240096
I0622 04:06:54.985975 13672 layer_factory.hpp:77] Creating layer relu2_2
I0622 04:06:54.985975 13672 net.cpp:100] Creating Layer relu2_2
I0622 04:06:54.985975 13672 net.cpp:434] relu2_2 <- conv2_2
I0622 04:06:54.985975 13672 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0622 04:06:54.987993 13672 net.cpp:150] Setting up relu2_2
I0622 04:06:54.987993 13672 net.cpp:157] Top shape: 2 128 150 150 (5760000)
I0622 04:06:54.987993 13672 net.cpp:165] Memory required for data: 305280096
I0622 04:06:54.987993 13672 layer_factory.hpp:77] Creating layer pool2
I0622 04:06:54.987993 13672 net.cpp:100] Creating Layer pool2
I0622 04:06:54.987993 13672 net.cpp:434] pool2 <- conv2_2
I0622 04:06:54.987993 13672 net.cpp:408] pool2 -> pool2
I0622 04:06:54.987993 13672 net.cpp:150] Setting up pool2
I0622 04:06:54.987993 13672 net.cpp:157] Top shape: 2 128 75 75 (1440000)
I0622 04:06:54.987993 13672 net.cpp:165] Memory required for data: 311040096
I0622 04:06:54.987993 13672 layer_factory.hpp:77] Creating layer conv3_1
I0622 04:06:54.987993 13672 net.cpp:100] Creating Layer conv3_1
I0622 04:06:54.987993 13672 net.cpp:434] conv3_1 <- pool2
I0622 04:06:54.987993 13672 net.cpp:408] conv3_1 -> conv3_1
I0622 04:06:55.011713 13672 net.cpp:150] Setting up conv3_1
I0622 04:06:55.011713 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:55.011713 13672 net.cpp:165] Memory required for data: 322560096
I0622 04:06:55.011713 13672 layer_factory.hpp:77] Creating layer relu3_1
I0622 04:06:55.011713 13672 net.cpp:100] Creating Layer relu3_1
I0622 04:06:55.011713 13672 net.cpp:434] relu3_1 <- conv3_1
I0622 04:06:55.011713 13672 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0622 04:06:55.012706 13672 net.cpp:150] Setting up relu3_1
I0622 04:06:55.012706 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:55.012706 13672 net.cpp:165] Memory required for data: 334080096
I0622 04:06:55.012706 13672 layer_factory.hpp:77] Creating layer conv3_2
I0622 04:06:55.012706 13672 net.cpp:100] Creating Layer conv3_2
I0622 04:06:55.012706 13672 net.cpp:434] conv3_2 <- conv3_1
I0622 04:06:55.012706 13672 net.cpp:408] conv3_2 -> conv3_2
I0622 04:06:55.039075 13672 net.cpp:150] Setting up conv3_2
I0622 04:06:55.039075 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:55.039075 13672 net.cpp:165] Memory required for data: 345600096
I0622 04:06:55.039075 13672 layer_factory.hpp:77] Creating layer relu3_2
I0622 04:06:55.039075 13672 net.cpp:100] Creating Layer relu3_2
I0622 04:06:55.039075 13672 net.cpp:434] relu3_2 <- conv3_2
I0622 04:06:55.039075 13672 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0622 04:06:55.040041 13672 net.cpp:150] Setting up relu3_2
I0622 04:06:55.040041 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:55.041038 13672 net.cpp:165] Memory required for data: 357120096
I0622 04:06:55.041038 13672 layer_factory.hpp:77] Creating layer conv3_3
I0622 04:06:55.041038 13672 net.cpp:100] Creating Layer conv3_3
I0622 04:06:55.041038 13672 net.cpp:434] conv3_3 <- conv3_2
I0622 04:06:55.041038 13672 net.cpp:408] conv3_3 -> conv3_3
I0622 04:06:55.053828 13672 net.cpp:150] Setting up conv3_3
I0622 04:06:55.053828 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:55.053828 13672 net.cpp:165] Memory required for data: 368640096
I0622 04:06:55.053828 13672 layer_factory.hpp:77] Creating layer relu3_3
I0622 04:06:55.053828 13672 net.cpp:100] Creating Layer relu3_3
I0622 04:06:55.053828 13672 net.cpp:434] relu3_3 <- conv3_3
I0622 04:06:55.053828 13672 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0622 04:06:55.054826 13672 net.cpp:150] Setting up relu3_3
I0622 04:06:55.054826 13672 net.cpp:157] Top shape: 2 256 75 75 (2880000)
I0622 04:06:55.054826 13672 net.cpp:165] Memory required for data: 380160096
I0622 04:06:55.054826 13672 layer_factory.hpp:77] Creating layer pool3
I0622 04:06:55.054826 13672 net.cpp:100] Creating Layer pool3
I0622 04:06:55.054826 13672 net.cpp:434] pool3 <- conv3_3
I0622 04:06:55.054826 13672 net.cpp:408] pool3 -> pool3
I0622 04:06:55.054826 13672 net.cpp:150] Setting up pool3
I0622 04:06:55.054826 13672 net.cpp:157] Top shape: 2 256 38 38 (739328)
I0622 04:06:55.054826 13672 net.cpp:165] Memory required for data: 383117408
I0622 04:06:55.054826 13672 layer_factory.hpp:77] Creating layer conv4_1
I0622 04:06:55.055824 13672 net.cpp:100] Creating Layer conv4_1
I0622 04:06:55.055824 13672 net.cpp:434] conv4_1 <- pool3
I0622 04:06:55.055824 13672 net.cpp:408] conv4_1 -> conv4_1
I0622 04:06:55.092379 13672 net.cpp:150] Setting up conv4_1
I0622 04:06:55.092379 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.092379 13672 net.cpp:165] Memory required for data: 389032032
I0622 04:06:55.092379 13672 layer_factory.hpp:77] Creating layer relu4_1
I0622 04:06:55.092379 13672 net.cpp:100] Creating Layer relu4_1
I0622 04:06:55.092379 13672 net.cpp:434] relu4_1 <- conv4_1
I0622 04:06:55.092379 13672 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0622 04:06:55.094379 13672 net.cpp:150] Setting up relu4_1
I0622 04:06:55.094379 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.094379 13672 net.cpp:165] Memory required for data: 394946656
I0622 04:06:55.094379 13672 layer_factory.hpp:77] Creating layer conv4_2
I0622 04:06:55.094379 13672 net.cpp:100] Creating Layer conv4_2
I0622 04:06:55.094379 13672 net.cpp:434] conv4_2 <- conv4_1
I0622 04:06:55.094379 13672 net.cpp:408] conv4_2 -> conv4_2
I0622 04:06:55.121476 13672 net.cpp:150] Setting up conv4_2
I0622 04:06:55.121476 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.121476 13672 net.cpp:165] Memory required for data: 400861280
I0622 04:06:55.121476 13672 layer_factory.hpp:77] Creating layer relu4_2
I0622 04:06:55.121476 13672 net.cpp:100] Creating Layer relu4_2
I0622 04:06:55.121476 13672 net.cpp:434] relu4_2 <- conv4_2
I0622 04:06:55.121476 13672 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0622 04:06:55.123471 13672 net.cpp:150] Setting up relu4_2
I0622 04:06:55.123471 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.123471 13672 net.cpp:165] Memory required for data: 406775904
I0622 04:06:55.123471 13672 layer_factory.hpp:77] Creating layer conv4_3
I0622 04:06:55.123471 13672 net.cpp:100] Creating Layer conv4_3
I0622 04:06:55.123471 13672 net.cpp:434] conv4_3 <- conv4_2
I0622 04:06:55.123471 13672 net.cpp:408] conv4_3 -> conv4_3
I0622 04:06:55.152423 13672 net.cpp:150] Setting up conv4_3
I0622 04:06:55.152423 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.152423 13672 net.cpp:165] Memory required for data: 412690528
I0622 04:06:55.152884 13672 layer_factory.hpp:77] Creating layer relu4_3
I0622 04:06:55.152884 13672 net.cpp:100] Creating Layer relu4_3
I0622 04:06:55.152884 13672 net.cpp:434] relu4_3 <- conv4_3
I0622 04:06:55.152884 13672 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0622 04:06:55.153883 13672 net.cpp:150] Setting up relu4_3
I0622 04:06:55.153883 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.153883 13672 net.cpp:165] Memory required for data: 418605152
I0622 04:06:55.153883 13672 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0622 04:06:55.153883 13672 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0622 04:06:55.153883 13672 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0622 04:06:55.153883 13672 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0622 04:06:55.153883 13672 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0622 04:06:55.153883 13672 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0622 04:06:55.154882 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.154882 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.154882 13672 net.cpp:165] Memory required for data: 430434400
I0622 04:06:55.154882 13672 layer_factory.hpp:77] Creating layer pool4
I0622 04:06:55.154882 13672 net.cpp:100] Creating Layer pool4
I0622 04:06:55.154882 13672 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0622 04:06:55.154882 13672 net.cpp:408] pool4 -> pool4
I0622 04:06:55.154882 13672 net.cpp:150] Setting up pool4
I0622 04:06:55.154882 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:55.154882 13672 net.cpp:165] Memory required for data: 431913056
I0622 04:06:55.154882 13672 layer_factory.hpp:77] Creating layer conv5_1
I0622 04:06:55.154882 13672 net.cpp:100] Creating Layer conv5_1
I0622 04:06:55.154882 13672 net.cpp:434] conv5_1 <- pool4
I0622 04:06:55.154882 13672 net.cpp:408] conv5_1 -> conv5_1
I0622 04:06:55.197444 13672 net.cpp:150] Setting up conv5_1
I0622 04:06:55.197444 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:55.197444 13672 net.cpp:165] Memory required for data: 433391712
I0622 04:06:55.197444 13672 layer_factory.hpp:77] Creating layer relu5_1
I0622 04:06:55.197444 13672 net.cpp:100] Creating Layer relu5_1
I0622 04:06:55.197444 13672 net.cpp:434] relu5_1 <- conv5_1
I0622 04:06:55.197444 13672 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0622 04:06:55.199038 13672 net.cpp:150] Setting up relu5_1
I0622 04:06:55.199038 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:55.199038 13672 net.cpp:165] Memory required for data: 434870368
I0622 04:06:55.199038 13672 layer_factory.hpp:77] Creating layer conv5_2
I0622 04:06:55.199038 13672 net.cpp:100] Creating Layer conv5_2
I0622 04:06:55.199038 13672 net.cpp:434] conv5_2 <- conv5_1
I0622 04:06:55.199038 13672 net.cpp:408] conv5_2 -> conv5_2
I0622 04:06:55.235792 13672 net.cpp:150] Setting up conv5_2
I0622 04:06:55.235792 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:55.235792 13672 net.cpp:165] Memory required for data: 436349024
I0622 04:06:55.235792 13672 layer_factory.hpp:77] Creating layer relu5_2
I0622 04:06:55.235916 13672 net.cpp:100] Creating Layer relu5_2
I0622 04:06:55.235916 13672 net.cpp:434] relu5_2 <- conv5_2
I0622 04:06:55.235916 13672 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0622 04:06:55.235916 13672 net.cpp:150] Setting up relu5_2
I0622 04:06:55.236913 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:55.236913 13672 net.cpp:165] Memory required for data: 437827680
I0622 04:06:55.236913 13672 layer_factory.hpp:77] Creating layer conv5_3
I0622 04:06:55.236913 13672 net.cpp:100] Creating Layer conv5_3
I0622 04:06:55.236913 13672 net.cpp:434] conv5_3 <- conv5_2
I0622 04:06:55.236913 13672 net.cpp:408] conv5_3 -> conv5_3
I0622 04:06:55.263370 13672 net.cpp:150] Setting up conv5_3
I0622 04:06:55.263370 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:55.264328 13672 net.cpp:165] Memory required for data: 439306336
I0622 04:06:55.264328 13672 layer_factory.hpp:77] Creating layer relu5_3
I0622 04:06:55.264328 13672 net.cpp:100] Creating Layer relu5_3
I0622 04:06:55.264328 13672 net.cpp:434] relu5_3 <- conv5_3
I0622 04:06:55.264328 13672 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0622 04:06:55.265450 13672 net.cpp:150] Setting up relu5_3
I0622 04:06:55.265450 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:55.265450 13672 net.cpp:165] Memory required for data: 440784992
I0622 04:06:55.265450 13672 layer_factory.hpp:77] Creating layer pool5
I0622 04:06:55.265450 13672 net.cpp:100] Creating Layer pool5
I0622 04:06:55.265450 13672 net.cpp:434] pool5 <- conv5_3
I0622 04:06:55.265450 13672 net.cpp:408] pool5 -> pool5
I0622 04:06:55.265450 13672 net.cpp:150] Setting up pool5
I0622 04:06:55.265450 13672 net.cpp:157] Top shape: 2 512 19 19 (369664)
I0622 04:06:55.265450 13672 net.cpp:165] Memory required for data: 442263648
I0622 04:06:55.265450 13672 layer_factory.hpp:77] Creating layer fc6
I0622 04:06:55.265450 13672 net.cpp:100] Creating Layer fc6
I0622 04:06:55.265450 13672 net.cpp:434] fc6 <- pool5
I0622 04:06:55.265450 13672 net.cpp:408] fc6 -> fc6
I0622 04:06:55.311735 13672 net.cpp:150] Setting up fc6
I0622 04:06:55.311735 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:55.311735 13672 net.cpp:165] Memory required for data: 445220960
I0622 04:06:55.311735 13672 layer_factory.hpp:77] Creating layer relu6
I0622 04:06:55.311735 13672 net.cpp:100] Creating Layer relu6
I0622 04:06:55.311735 13672 net.cpp:434] relu6 <- fc6
I0622 04:06:55.311735 13672 net.cpp:395] relu6 -> fc6 (in-place)
I0622 04:06:55.313302 13672 net.cpp:150] Setting up relu6
I0622 04:06:55.313302 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:55.313302 13672 net.cpp:165] Memory required for data: 448178272
I0622 04:06:55.313302 13672 layer_factory.hpp:77] Creating layer fc7
I0622 04:06:55.313302 13672 net.cpp:100] Creating Layer fc7
I0622 04:06:55.313302 13672 net.cpp:434] fc7 <- fc6
I0622 04:06:55.313302 13672 net.cpp:408] fc7 -> fc7
I0622 04:06:55.334348 13672 net.cpp:150] Setting up fc7
I0622 04:06:55.334348 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:55.334348 13672 net.cpp:165] Memory required for data: 451135584
I0622 04:06:55.334348 13672 layer_factory.hpp:77] Creating layer relu7
I0622 04:06:55.334348 13672 net.cpp:100] Creating Layer relu7
I0622 04:06:55.334348 13672 net.cpp:434] relu7 <- fc7
I0622 04:06:55.334348 13672 net.cpp:395] relu7 -> fc7 (in-place)
I0622 04:06:55.336359 13672 net.cpp:150] Setting up relu7
I0622 04:06:55.336359 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:55.336359 13672 net.cpp:165] Memory required for data: 454092896
I0622 04:06:55.336359 13672 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0622 04:06:55.336359 13672 net.cpp:100] Creating Layer fc7_relu7_0_split
I0622 04:06:55.336359 13672 net.cpp:434] fc7_relu7_0_split <- fc7
I0622 04:06:55.336359 13672 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0622 04:06:55.336359 13672 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0622 04:06:55.336359 13672 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0622 04:06:55.336359 13672 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0622 04:06:55.336359 13672 net.cpp:150] Setting up fc7_relu7_0_split
I0622 04:06:55.336359 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:55.336359 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:55.336359 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:55.336359 13672 net.cpp:157] Top shape: 2 1024 19 19 (739328)
I0622 04:06:55.336359 13672 net.cpp:165] Memory required for data: 465922144
I0622 04:06:55.336359 13672 layer_factory.hpp:77] Creating layer conv8_1
I0622 04:06:55.336359 13672 net.cpp:100] Creating Layer conv8_1
I0622 04:06:55.337353 13672 net.cpp:434] conv8_1 <- fc7_relu7_0_split_0
I0622 04:06:55.337353 13672 net.cpp:408] conv8_1 -> conv8_1
I0622 04:06:55.350944 13672 net.cpp:150] Setting up conv8_1
I0622 04:06:55.350944 13672 net.cpp:157] Top shape: 2 256 19 19 (184832)
I0622 04:06:55.350944 13672 net.cpp:165] Memory required for data: 466661472
I0622 04:06:55.350944 13672 layer_factory.hpp:77] Creating layer conv8_1_relu
I0622 04:06:55.350944 13672 net.cpp:100] Creating Layer conv8_1_relu
I0622 04:06:55.350944 13672 net.cpp:434] conv8_1_relu <- conv8_1
I0622 04:06:55.350944 13672 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0622 04:06:55.351905 13672 net.cpp:150] Setting up conv8_1_relu
I0622 04:06:55.351905 13672 net.cpp:157] Top shape: 2 256 19 19 (184832)
I0622 04:06:55.351905 13672 net.cpp:165] Memory required for data: 467400800
I0622 04:06:55.351905 13672 layer_factory.hpp:77] Creating layer conv8_2
I0622 04:06:55.351905 13672 net.cpp:100] Creating Layer conv8_2
I0622 04:06:55.351905 13672 net.cpp:434] conv8_2 <- conv8_1
I0622 04:06:55.351905 13672 net.cpp:408] conv8_2 -> conv8_2
I0622 04:06:55.368938 13672 net.cpp:150] Setting up conv8_2
I0622 04:06:55.368938 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:55.368938 13672 net.cpp:165] Memory required for data: 467810400
I0622 04:06:55.368938 13672 layer_factory.hpp:77] Creating layer conv8_2_relu
I0622 04:06:55.368938 13672 net.cpp:100] Creating Layer conv8_2_relu
I0622 04:06:55.368938 13672 net.cpp:434] conv8_2_relu <- conv8_2
I0622 04:06:55.368938 13672 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0622 04:06:55.370932 13672 net.cpp:150] Setting up conv8_2_relu
I0622 04:06:55.370932 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:55.370932 13672 net.cpp:165] Memory required for data: 468220000
I0622 04:06:55.370932 13672 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0622 04:06:55.370932 13672 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0622 04:06:55.370932 13672 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0622 04:06:55.370932 13672 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0622 04:06:55.370932 13672 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0622 04:06:55.370932 13672 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0622 04:06:55.370932 13672 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0622 04:06:55.370932 13672 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0622 04:06:55.370932 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:55.370932 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:55.370932 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:55.370932 13672 net.cpp:157] Top shape: 2 512 10 10 (102400)
I0622 04:06:55.370932 13672 net.cpp:165] Memory required for data: 469858400
I0622 04:06:55.370932 13672 layer_factory.hpp:77] Creating layer conv9_1
I0622 04:06:55.370932 13672 net.cpp:100] Creating Layer conv9_1
I0622 04:06:55.370932 13672 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0622 04:06:55.370932 13672 net.cpp:408] conv9_1 -> conv9_1
I0622 04:06:55.378649 13672 net.cpp:150] Setting up conv9_1
I0622 04:06:55.378649 13672 net.cpp:157] Top shape: 2 128 10 10 (25600)
I0622 04:06:55.378649 13672 net.cpp:165] Memory required for data: 469960800
I0622 04:06:55.378649 13672 layer_factory.hpp:77] Creating layer conv9_1_relu
I0622 04:06:55.378649 13672 net.cpp:100] Creating Layer conv9_1_relu
I0622 04:06:55.378649 13672 net.cpp:434] conv9_1_relu <- conv9_1
I0622 04:06:55.378649 13672 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0622 04:06:55.379647 13672 net.cpp:150] Setting up conv9_1_relu
I0622 04:06:55.379647 13672 net.cpp:157] Top shape: 2 128 10 10 (25600)
I0622 04:06:55.380645 13672 net.cpp:165] Memory required for data: 470063200
I0622 04:06:55.380645 13672 layer_factory.hpp:77] Creating layer conv9_2
I0622 04:06:55.380645 13672 net.cpp:100] Creating Layer conv9_2
I0622 04:06:55.380645 13672 net.cpp:434] conv9_2 <- conv9_1
I0622 04:06:55.380645 13672 net.cpp:408] conv9_2 -> conv9_2
I0622 04:06:55.388041 13672 net.cpp:150] Setting up conv9_2
I0622 04:06:55.388041 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:55.388041 13672 net.cpp:165] Memory required for data: 470114400
I0622 04:06:55.389039 13672 layer_factory.hpp:77] Creating layer conv9_2_relu
I0622 04:06:55.389058 13672 net.cpp:100] Creating Layer conv9_2_relu
I0622 04:06:55.389058 13672 net.cpp:434] conv9_2_relu <- conv9_2
I0622 04:06:55.389058 13672 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0622 04:06:55.405014 13672 net.cpp:150] Setting up conv9_2_relu
I0622 04:06:55.406010 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:55.406010 13672 net.cpp:165] Memory required for data: 470165600
I0622 04:06:55.406010 13672 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0622 04:06:55.406010 13672 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0622 04:06:55.406010 13672 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0622 04:06:55.406010 13672 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0622 04:06:55.406010 13672 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0622 04:06:55.406010 13672 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0622 04:06:55.406010 13672 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_3
I0622 04:06:55.406010 13672 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0622 04:06:55.406010 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:55.406010 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:55.406010 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:55.406010 13672 net.cpp:157] Top shape: 2 256 5 5 (12800)
I0622 04:06:55.406010 13672 net.cpp:165] Memory required for data: 470370400
I0622 04:06:55.406010 13672 layer_factory.hpp:77] Creating layer conv10_1
I0622 04:06:55.406010 13672 net.cpp:100] Creating Layer conv10_1
I0622 04:06:55.406010 13672 net.cpp:434] conv10_1 <- conv9_2_conv9_2_relu_0_split_0
I0622 04:06:55.406010 13672 net.cpp:408] conv10_1 -> conv10_1
I0622 04:06:55.425500 13672 net.cpp:150] Setting up conv10_1
I0622 04:06:55.425500 13672 net.cpp:157] Top shape: 2 128 5 5 (6400)
I0622 04:06:55.425500 13672 net.cpp:165] Memory required for data: 470396000
I0622 04:06:55.425500 13672 layer_factory.hpp:77] Creating layer conv10_1_relu
I0622 04:06:55.425500 13672 net.cpp:100] Creating Layer conv10_1_relu
I0622 04:06:55.425500 13672 net.cpp:434] conv10_1_relu <- conv10_1
I0622 04:06:55.425500 13672 net.cpp:395] conv10_1_relu -> conv10_1 (in-place)
I0622 04:06:55.428499 13672 net.cpp:150] Setting up conv10_1_relu
I0622 04:06:55.428499 13672 net.cpp:157] Top shape: 2 128 5 5 (6400)
I0622 04:06:55.428499 13672 net.cpp:165] Memory required for data: 470421600
I0622 04:06:55.428499 13672 layer_factory.hpp:77] Creating layer conv10_2
I0622 04:06:55.428499 13672 net.cpp:100] Creating Layer conv10_2
I0622 04:06:55.428499 13672 net.cpp:434] conv10_2 <- conv10_1
I0622 04:06:55.428499 13672 net.cpp:408] conv10_2 -> conv10_2
I0622 04:06:55.438747 13672 net.cpp:150] Setting up conv10_2
I0622 04:06:55.438747 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:55.438747 13672 net.cpp:165] Memory required for data: 470440032
I0622 04:06:55.438747 13672 layer_factory.hpp:77] Creating layer conv10_2_relu
I0622 04:06:55.438747 13672 net.cpp:100] Creating Layer conv10_2_relu
I0622 04:06:55.438747 13672 net.cpp:434] conv10_2_relu <- conv10_2
I0622 04:06:55.438747 13672 net.cpp:395] conv10_2_relu -> conv10_2 (in-place)
I0622 04:06:55.439777 13672 net.cpp:150] Setting up conv10_2_relu
I0622 04:06:55.439777 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:55.439777 13672 net.cpp:165] Memory required for data: 470458464
I0622 04:06:55.440740 13672 layer_factory.hpp:77] Creating layer conv10_2_conv10_2_relu_0_split
I0622 04:06:55.440740 13672 net.cpp:100] Creating Layer conv10_2_conv10_2_relu_0_split
I0622 04:06:55.440780 13672 net.cpp:434] conv10_2_conv10_2_relu_0_split <- conv10_2
I0622 04:06:55.440780 13672 net.cpp:408] conv10_2_conv10_2_relu_0_split -> conv10_2_conv10_2_relu_0_split_0
I0622 04:06:55.440780 13672 net.cpp:408] conv10_2_conv10_2_relu_0_split -> conv10_2_conv10_2_relu_0_split_1
I0622 04:06:55.440780 13672 net.cpp:408] conv10_2_conv10_2_relu_0_split -> conv10_2_conv10_2_relu_0_split_2
I0622 04:06:55.440780 13672 net.cpp:408] conv10_2_conv10_2_relu_0_split -> conv10_2_conv10_2_relu_0_split_3
I0622 04:06:55.440780 13672 net.cpp:150] Setting up conv10_2_conv10_2_relu_0_split
I0622 04:06:55.440780 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:55.440780 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:55.440780 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:55.440780 13672 net.cpp:157] Top shape: 2 256 3 3 (4608)
I0622 04:06:55.440780 13672 net.cpp:165] Memory required for data: 470532192
I0622 04:06:55.440780 13672 layer_factory.hpp:77] Creating layer conv11_1
I0622 04:06:55.440780 13672 net.cpp:100] Creating Layer conv11_1
I0622 04:06:55.440780 13672 net.cpp:434] conv11_1 <- conv10_2_conv10_2_relu_0_split_0
I0622 04:06:55.440780 13672 net.cpp:408] conv11_1 -> conv11_1
I0622 04:06:55.448469 13672 net.cpp:150] Setting up conv11_1
I0622 04:06:55.448469 13672 net.cpp:157] Top shape: 2 128 3 3 (2304)
I0622 04:06:55.448469 13672 net.cpp:165] Memory required for data: 470541408
I0622 04:06:55.449466 13672 layer_factory.hpp:77] Creating layer conv11_1_relu
I0622 04:06:55.449466 13672 net.cpp:100] Creating Layer conv11_1_relu
I0622 04:06:55.449466 13672 net.cpp:434] conv11_1_relu <- conv11_1
I0622 04:06:55.449466 13672 net.cpp:395] conv11_1_relu -> conv11_1 (in-place)
I0622 04:06:55.450477 13672 net.cpp:150] Setting up conv11_1_relu
I0622 04:06:55.450477 13672 net.cpp:157] Top shape: 2 128 3 3 (2304)
I0622 04:06:55.450477 13672 net.cpp:165] Memory required for data: 470550624
I0622 04:06:55.450477 13672 layer_factory.hpp:77] Creating layer conv11_2
I0622 04:06:55.450477 13672 net.cpp:100] Creating Layer conv11_2
I0622 04:06:55.450477 13672 net.cpp:434] conv11_2 <- conv11_1
I0622 04:06:55.450477 13672 net.cpp:408] conv11_2 -> conv11_2
I0622 04:06:55.459936 13672 net.cpp:150] Setting up conv11_2
I0622 04:06:55.459936 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:55.459936 13672 net.cpp:165] Memory required for data: 470552672
I0622 04:06:55.459936 13672 layer_factory.hpp:77] Creating layer conv11_2_relu
I0622 04:06:55.459936 13672 net.cpp:100] Creating Layer conv11_2_relu
I0622 04:06:55.459936 13672 net.cpp:434] conv11_2_relu <- conv11_2
I0622 04:06:55.459936 13672 net.cpp:395] conv11_2_relu -> conv11_2 (in-place)
I0622 04:06:55.461932 13672 net.cpp:150] Setting up conv11_2_relu
I0622 04:06:55.461932 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:55.461932 13672 net.cpp:165] Memory required for data: 470554720
I0622 04:06:55.461932 13672 layer_factory.hpp:77] Creating layer conv11_2_conv11_2_relu_0_split
I0622 04:06:55.461932 13672 net.cpp:100] Creating Layer conv11_2_conv11_2_relu_0_split
I0622 04:06:55.461932 13672 net.cpp:434] conv11_2_conv11_2_relu_0_split <- conv11_2
I0622 04:06:55.461932 13672 net.cpp:408] conv11_2_conv11_2_relu_0_split -> conv11_2_conv11_2_relu_0_split_0
I0622 04:06:55.461932 13672 net.cpp:408] conv11_2_conv11_2_relu_0_split -> conv11_2_conv11_2_relu_0_split_1
I0622 04:06:55.461932 13672 net.cpp:408] conv11_2_conv11_2_relu_0_split -> conv11_2_conv11_2_relu_0_split_2
I0622 04:06:55.461932 13672 net.cpp:150] Setting up conv11_2_conv11_2_relu_0_split
I0622 04:06:55.461932 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:55.461932 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:55.461932 13672 net.cpp:157] Top shape: 2 256 1 1 (512)
I0622 04:06:55.461932 13672 net.cpp:165] Memory required for data: 470560864
I0622 04:06:55.461932 13672 layer_factory.hpp:77] Creating layer conv4_3_norm
I0622 04:06:55.461932 13672 net.cpp:100] Creating Layer conv4_3_norm
I0622 04:06:55.461932 13672 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0622 04:06:55.461932 13672 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0622 04:06:55.462927 13672 net.cpp:150] Setting up conv4_3_norm
I0622 04:06:55.462927 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.462927 13672 net.cpp:165] Memory required for data: 476475488
I0622 04:06:55.462927 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0622 04:06:55.462927 13672 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0622 04:06:55.462927 13672 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0622 04:06:55.462927 13672 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0622 04:06:55.462927 13672 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0622 04:06:55.462927 13672 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0622 04:06:55.462927 13672 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0622 04:06:55.462927 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.462927 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.462927 13672 net.cpp:157] Top shape: 2 512 38 38 (1478656)
I0622 04:06:55.462927 13672 net.cpp:165] Memory required for data: 494219360
I0622 04:06:55.462927 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0622 04:06:55.462927 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0622 04:06:55.462927 13672 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0622 04:06:55.462927 13672 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0622 04:06:55.470350 13672 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0622 04:06:55.470350 13672 net.cpp:157] Top shape: 2 16 38 38 (46208)
I0622 04:06:55.470350 13672 net.cpp:165] Memory required for data: 494404192
I0622 04:06:55.470350 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0622 04:06:55.470350 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0622 04:06:55.470350 13672 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0622 04:06:55.470350 13672 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0622 04:06:55.470350 13672 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0622 04:06:55.470350 13672 net.cpp:157] Top shape: 2 38 38 16 (46208)
I0622 04:06:55.470350 13672 net.cpp:165] Memory required for data: 494589024
I0622 04:06:55.470350 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0622 04:06:55.470350 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0622 04:06:55.470350 13672 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0622 04:06:55.470350 13672 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0622 04:06:55.470350 13672 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0622 04:06:55.470350 13672 net.cpp:157] Top shape: 2 23104 (46208)
I0622 04:06:55.470350 13672 net.cpp:165] Memory required for data: 494773856
I0622 04:06:55.470350 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0622 04:06:55.470350 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0622 04:06:55.470350 13672 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0622 04:06:55.470350 13672 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0622 04:06:55.479230 13672 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0622 04:06:55.479230 13672 net.cpp:157] Top shape: 2 12 38 38 (34656)
I0622 04:06:55.479230 13672 net.cpp:165] Memory required for data: 494912480
I0622 04:06:55.479230 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0622 04:06:55.479230 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0622 04:06:55.479230 13672 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0622 04:06:55.479230 13672 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0622 04:06:55.479230 13672 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0622 04:06:55.479230 13672 net.cpp:157] Top shape: 2 38 38 12 (34656)
I0622 04:06:55.479230 13672 net.cpp:165] Memory required for data: 495051104
I0622 04:06:55.479230 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0622 04:06:55.479230 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0622 04:06:55.479230 13672 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0622 04:06:55.479230 13672 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0622 04:06:55.479230 13672 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0622 04:06:55.479230 13672 net.cpp:157] Top shape: 2 17328 (34656)
I0622 04:06:55.479230 13672 net.cpp:165] Memory required for data: 495189728
I0622 04:06:55.479230 13672 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0622 04:06:55.479230 13672 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0622 04:06:55.479230 13672 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0622 04:06:55.479230 13672 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0622 04:06:55.479230 13672 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0622 04:06:55.480242 13672 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0622 04:06:55.480242 13672 net.cpp:157] Top shape: 1 2 23104 (46208)
I0622 04:06:55.480242 13672 net.cpp:165] Memory required for data: 495374560
I0622 04:06:55.480242 13672 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0622 04:06:55.480242 13672 net.cpp:100] Creating Layer fc7_mbox_loc
I0622 04:06:55.480242 13672 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0622 04:06:55.480242 13672 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0622 04:06:55.490006 13672 net.cpp:150] Setting up fc7_mbox_loc
I0622 04:06:55.490006 13672 net.cpp:157] Top shape: 2 24 19 19 (17328)
I0622 04:06:55.490006 13672 net.cpp:165] Memory required for data: 495443872
I0622 04:06:55.490006 13672 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0622 04:06:55.490006 13672 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0622 04:06:55.490006 13672 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0622 04:06:55.490006 13672 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0622 04:06:55.491003 13672 net.cpp:150] Setting up fc7_mbox_loc_perm
I0622 04:06:55.491003 13672 net.cpp:157] Top shape: 2 19 19 24 (17328)
I0622 04:06:55.491003 13672 net.cpp:165] Memory required for data: 495513184
I0622 04:06:55.491003 13672 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0622 04:06:55.491003 13672 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0622 04:06:55.491003 13672 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0622 04:06:55.491003 13672 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0622 04:06:55.491003 13672 net.cpp:150] Setting up fc7_mbox_loc_flat
I0622 04:06:55.491003 13672 net.cpp:157] Top shape: 2 8664 (17328)
I0622 04:06:55.491003 13672 net.cpp:165] Memory required for data: 495582496
I0622 04:06:55.491003 13672 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0622 04:06:55.491003 13672 net.cpp:100] Creating Layer fc7_mbox_conf
I0622 04:06:55.491003 13672 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0622 04:06:55.491003 13672 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0622 04:06:55.499419 13672 net.cpp:150] Setting up fc7_mbox_conf
I0622 04:06:55.499419 13672 net.cpp:157] Top shape: 2 18 19 19 (12996)
I0622 04:06:55.499419 13672 net.cpp:165] Memory required for data: 495634480
I0622 04:06:55.499419 13672 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0622 04:06:55.499419 13672 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0622 04:06:55.499419 13672 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0622 04:06:55.499419 13672 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0622 04:06:55.500416 13672 net.cpp:150] Setting up fc7_mbox_conf_perm
I0622 04:06:55.500416 13672 net.cpp:157] Top shape: 2 19 19 18 (12996)
I0622 04:06:55.500416 13672 net.cpp:165] Memory required for data: 495686464
I0622 04:06:55.500416 13672 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0622 04:06:55.500416 13672 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0622 04:06:55.500416 13672 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0622 04:06:55.500416 13672 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0622 04:06:55.500416 13672 net.cpp:150] Setting up fc7_mbox_conf_flat
I0622 04:06:55.500416 13672 net.cpp:157] Top shape: 2 6498 (12996)
I0622 04:06:55.500416 13672 net.cpp:165] Memory required for data: 495738448
I0622 04:06:55.500416 13672 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0622 04:06:55.500416 13672 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0622 04:06:55.500416 13672 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0622 04:06:55.500416 13672 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0622 04:06:55.500416 13672 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0622 04:06:55.500416 13672 net.cpp:150] Setting up fc7_mbox_priorbox
I0622 04:06:55.500416 13672 net.cpp:157] Top shape: 1 2 8664 (17328)
I0622 04:06:55.500416 13672 net.cpp:165] Memory required for data: 495807760
I0622 04:06:55.500416 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0622 04:06:55.500416 13672 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0622 04:06:55.500416 13672 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0622 04:06:55.500416 13672 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0622 04:06:55.508426 13672 net.cpp:150] Setting up conv8_2_mbox_loc
I0622 04:06:55.508426 13672 net.cpp:157] Top shape: 2 24 10 10 (4800)
I0622 04:06:55.508426 13672 net.cpp:165] Memory required for data: 495826960
I0622 04:06:55.508426 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0622 04:06:55.508426 13672 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0622 04:06:55.508426 13672 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0622 04:06:55.508426 13672 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0622 04:06:55.508426 13672 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0622 04:06:55.508426 13672 net.cpp:157] Top shape: 2 10 10 24 (4800)
I0622 04:06:55.508426 13672 net.cpp:165] Memory required for data: 495846160
I0622 04:06:55.508426 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0622 04:06:55.508426 13672 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0622 04:06:55.508426 13672 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0622 04:06:55.508426 13672 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0622 04:06:55.509423 13672 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0622 04:06:55.509423 13672 net.cpp:157] Top shape: 2 2400 (4800)
I0622 04:06:55.509423 13672 net.cpp:165] Memory required for data: 495865360
I0622 04:06:55.509423 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0622 04:06:55.509423 13672 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0622 04:06:55.509423 13672 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0622 04:06:55.509423 13672 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0622 04:06:55.540020 13672 net.cpp:150] Setting up conv8_2_mbox_conf
I0622 04:06:55.540020 13672 net.cpp:157] Top shape: 2 18 10 10 (3600)
I0622 04:06:55.540020 13672 net.cpp:165] Memory required for data: 495879760
I0622 04:06:55.540020 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0622 04:06:55.540020 13672 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0622 04:06:55.540020 13672 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0622 04:06:55.540020 13672 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0622 04:06:55.540020 13672 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0622 04:06:55.540020 13672 net.cpp:157] Top shape: 2 10 10 18 (3600)
I0622 04:06:55.540020 13672 net.cpp:165] Memory required for data: 495894160
I0622 04:06:55.540020 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0622 04:06:55.540020 13672 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0622 04:06:55.540020 13672 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0622 04:06:55.540020 13672 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0622 04:06:55.540020 13672 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0622 04:06:55.540020 13672 net.cpp:157] Top shape: 2 1800 (3600)
I0622 04:06:55.540020 13672 net.cpp:165] Memory required for data: 495908560
I0622 04:06:55.540020 13672 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0622 04:06:55.540020 13672 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0622 04:06:55.540020 13672 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0622 04:06:55.540020 13672 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_3
I0622 04:06:55.540020 13672 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0622 04:06:55.541018 13672 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0622 04:06:55.541018 13672 net.cpp:157] Top shape: 1 2 2400 (4800)
I0622 04:06:55.541018 13672 net.cpp:165] Memory required for data: 495927760
I0622 04:06:55.541018 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0622 04:06:55.541018 13672 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0622 04:06:55.541018 13672 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_1
I0622 04:06:55.541018 13672 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0622 04:06:55.547592 13672 net.cpp:150] Setting up conv9_2_mbox_loc
I0622 04:06:55.547592 13672 net.cpp:157] Top shape: 2 24 5 5 (1200)
I0622 04:06:55.547592 13672 net.cpp:165] Memory required for data: 495932560
I0622 04:06:55.547592 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0622 04:06:55.547592 13672 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0622 04:06:55.547592 13672 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0622 04:06:55.547592 13672 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0622 04:06:55.547592 13672 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0622 04:06:55.547592 13672 net.cpp:157] Top shape: 2 5 5 24 (1200)
I0622 04:06:55.547592 13672 net.cpp:165] Memory required for data: 495937360
I0622 04:06:55.547592 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0622 04:06:55.547592 13672 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0622 04:06:55.547592 13672 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0622 04:06:55.547592 13672 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0622 04:06:55.547592 13672 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0622 04:06:55.547592 13672 net.cpp:157] Top shape: 2 600 (1200)
I0622 04:06:55.547592 13672 net.cpp:165] Memory required for data: 495942160
I0622 04:06:55.547592 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0622 04:06:55.547592 13672 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0622 04:06:55.547592 13672 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_2
I0622 04:06:55.547592 13672 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0622 04:06:55.553578 13672 net.cpp:150] Setting up conv9_2_mbox_conf
I0622 04:06:55.553578 13672 net.cpp:157] Top shape: 2 18 5 5 (900)
I0622 04:06:55.553578 13672 net.cpp:165] Memory required for data: 495945760
I0622 04:06:55.553578 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0622 04:06:55.553578 13672 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0622 04:06:55.553578 13672 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0622 04:06:55.553578 13672 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0622 04:06:55.553578 13672 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0622 04:06:55.553578 13672 net.cpp:157] Top shape: 2 5 5 18 (900)
I0622 04:06:55.553578 13672 net.cpp:165] Memory required for data: 495949360
I0622 04:06:55.553578 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0622 04:06:55.553578 13672 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0622 04:06:55.553578 13672 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0622 04:06:55.553578 13672 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0622 04:06:55.553578 13672 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0622 04:06:55.553578 13672 net.cpp:157] Top shape: 2 450 (900)
I0622 04:06:55.553578 13672 net.cpp:165] Memory required for data: 495952960
I0622 04:06:55.553578 13672 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0622 04:06:55.553578 13672 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0622 04:06:55.553578 13672 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_3
I0622 04:06:55.553578 13672 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_4
I0622 04:06:55.553578 13672 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0622 04:06:55.553578 13672 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0622 04:06:55.553578 13672 net.cpp:157] Top shape: 1 2 600 (1200)
I0622 04:06:55.553578 13672 net.cpp:165] Memory required for data: 495957760
I0622 04:06:55.553578 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_loc
I0622 04:06:55.553578 13672 net.cpp:100] Creating Layer conv10_2_mbox_loc
I0622 04:06:55.553578 13672 net.cpp:434] conv10_2_mbox_loc <- conv10_2_conv10_2_relu_0_split_1
I0622 04:06:55.553578 13672 net.cpp:408] conv10_2_mbox_loc -> conv10_2_mbox_loc
I0622 04:06:55.560237 13672 net.cpp:150] Setting up conv10_2_mbox_loc
I0622 04:06:55.560237 13672 net.cpp:157] Top shape: 2 16 3 3 (288)
I0622 04:06:55.560237 13672 net.cpp:165] Memory required for data: 495958912
I0622 04:06:55.560237 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_loc_perm
I0622 04:06:55.560237 13672 net.cpp:100] Creating Layer conv10_2_mbox_loc_perm
I0622 04:06:55.560237 13672 net.cpp:434] conv10_2_mbox_loc_perm <- conv10_2_mbox_loc
I0622 04:06:55.560237 13672 net.cpp:408] conv10_2_mbox_loc_perm -> conv10_2_mbox_loc_perm
I0622 04:06:55.561240 13672 net.cpp:150] Setting up conv10_2_mbox_loc_perm
I0622 04:06:55.561240 13672 net.cpp:157] Top shape: 2 3 3 16 (288)
I0622 04:06:55.561240 13672 net.cpp:165] Memory required for data: 495960064
I0622 04:06:55.561240 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_loc_flat
I0622 04:06:55.561240 13672 net.cpp:100] Creating Layer conv10_2_mbox_loc_flat
I0622 04:06:55.561240 13672 net.cpp:434] conv10_2_mbox_loc_flat <- conv10_2_mbox_loc_perm
I0622 04:06:55.561240 13672 net.cpp:408] conv10_2_mbox_loc_flat -> conv10_2_mbox_loc_flat
I0622 04:06:55.561240 13672 net.cpp:150] Setting up conv10_2_mbox_loc_flat
I0622 04:06:55.561240 13672 net.cpp:157] Top shape: 2 144 (288)
I0622 04:06:55.561240 13672 net.cpp:165] Memory required for data: 495961216
I0622 04:06:55.561240 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_conf
I0622 04:06:55.561240 13672 net.cpp:100] Creating Layer conv10_2_mbox_conf
I0622 04:06:55.561240 13672 net.cpp:434] conv10_2_mbox_conf <- conv10_2_conv10_2_relu_0_split_2
I0622 04:06:55.561240 13672 net.cpp:408] conv10_2_mbox_conf -> conv10_2_mbox_conf
I0622 04:06:55.581526 13672 net.cpp:150] Setting up conv10_2_mbox_conf
I0622 04:06:55.581526 13672 net.cpp:157] Top shape: 2 12 3 3 (216)
I0622 04:06:55.581526 13672 net.cpp:165] Memory required for data: 495962080
I0622 04:06:55.581526 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_conf_perm
I0622 04:06:55.581526 13672 net.cpp:100] Creating Layer conv10_2_mbox_conf_perm
I0622 04:06:55.581526 13672 net.cpp:434] conv10_2_mbox_conf_perm <- conv10_2_mbox_conf
I0622 04:06:55.581526 13672 net.cpp:408] conv10_2_mbox_conf_perm -> conv10_2_mbox_conf_perm
I0622 04:06:55.581526 13672 net.cpp:150] Setting up conv10_2_mbox_conf_perm
I0622 04:06:55.581526 13672 net.cpp:157] Top shape: 2 3 3 12 (216)
I0622 04:06:55.581526 13672 net.cpp:165] Memory required for data: 495962944
I0622 04:06:55.581526 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_conf_flat
I0622 04:06:55.581526 13672 net.cpp:100] Creating Layer conv10_2_mbox_conf_flat
I0622 04:06:55.581526 13672 net.cpp:434] conv10_2_mbox_conf_flat <- conv10_2_mbox_conf_perm
I0622 04:06:55.581526 13672 net.cpp:408] conv10_2_mbox_conf_flat -> conv10_2_mbox_conf_flat
I0622 04:06:55.581526 13672 net.cpp:150] Setting up conv10_2_mbox_conf_flat
I0622 04:06:55.581526 13672 net.cpp:157] Top shape: 2 108 (216)
I0622 04:06:55.581526 13672 net.cpp:165] Memory required for data: 495963808
I0622 04:06:55.581526 13672 layer_factory.hpp:77] Creating layer conv10_2_mbox_priorbox
I0622 04:06:55.581526 13672 net.cpp:100] Creating Layer conv10_2_mbox_priorbox
I0622 04:06:55.581526 13672 net.cpp:434] conv10_2_mbox_priorbox <- conv10_2_conv10_2_relu_0_split_3
I0622 04:06:55.581526 13672 net.cpp:434] conv10_2_mbox_priorbox <- data_data_0_split_5
I0622 04:06:55.581526 13672 net.cpp:408] conv10_2_mbox_priorbox -> conv10_2_mbox_priorbox
I0622 04:06:55.582523 13672 net.cpp:150] Setting up conv10_2_mbox_priorbox
I0622 04:06:55.582523 13672 net.cpp:157] Top shape: 1 2 144 (288)
I0622 04:06:55.582523 13672 net.cpp:165] Memory required for data: 495964960
I0622 04:06:55.582523 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_loc
I0622 04:06:55.582523 13672 net.cpp:100] Creating Layer conv11_2_mbox_loc
I0622 04:06:55.582523 13672 net.cpp:434] conv11_2_mbox_loc <- conv11_2_conv11_2_relu_0_split_0
I0622 04:06:55.582523 13672 net.cpp:408] conv11_2_mbox_loc -> conv11_2_mbox_loc
I0622 04:06:55.591853 13672 net.cpp:150] Setting up conv11_2_mbox_loc
I0622 04:06:55.591853 13672 net.cpp:157] Top shape: 2 16 1 1 (32)
I0622 04:06:55.591853 13672 net.cpp:165] Memory required for data: 495965088
I0622 04:06:55.591853 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_loc_perm
I0622 04:06:55.591853 13672 net.cpp:100] Creating Layer conv11_2_mbox_loc_perm
I0622 04:06:55.591853 13672 net.cpp:434] conv11_2_mbox_loc_perm <- conv11_2_mbox_loc
I0622 04:06:55.591853 13672 net.cpp:408] conv11_2_mbox_loc_perm -> conv11_2_mbox_loc_perm
I0622 04:06:55.591853 13672 net.cpp:150] Setting up conv11_2_mbox_loc_perm
I0622 04:06:55.591853 13672 net.cpp:157] Top shape: 2 1 1 16 (32)
I0622 04:06:55.591853 13672 net.cpp:165] Memory required for data: 495965216
I0622 04:06:55.591853 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_loc_flat
I0622 04:06:55.591853 13672 net.cpp:100] Creating Layer conv11_2_mbox_loc_flat
I0622 04:06:55.591853 13672 net.cpp:434] conv11_2_mbox_loc_flat <- conv11_2_mbox_loc_perm
I0622 04:06:55.591853 13672 net.cpp:408] conv11_2_mbox_loc_flat -> conv11_2_mbox_loc_flat
I0622 04:06:55.591853 13672 net.cpp:150] Setting up conv11_2_mbox_loc_flat
I0622 04:06:55.591853 13672 net.cpp:157] Top shape: 2 16 (32)
I0622 04:06:55.591853 13672 net.cpp:165] Memory required for data: 495965344
I0622 04:06:55.591853 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_conf
I0622 04:06:55.591853 13672 net.cpp:100] Creating Layer conv11_2_mbox_conf
I0622 04:06:55.591853 13672 net.cpp:434] conv11_2_mbox_conf <- conv11_2_conv11_2_relu_0_split_1
I0622 04:06:55.591853 13672 net.cpp:408] conv11_2_mbox_conf -> conv11_2_mbox_conf
I0622 04:06:55.599207 13672 net.cpp:150] Setting up conv11_2_mbox_conf
I0622 04:06:55.599207 13672 net.cpp:157] Top shape: 2 12 1 1 (24)
I0622 04:06:55.599207 13672 net.cpp:165] Memory required for data: 495965440
I0622 04:06:55.599207 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_conf_perm
I0622 04:06:55.599207 13672 net.cpp:100] Creating Layer conv11_2_mbox_conf_perm
I0622 04:06:55.599207 13672 net.cpp:434] conv11_2_mbox_conf_perm <- conv11_2_mbox_conf
I0622 04:06:55.599207 13672 net.cpp:408] conv11_2_mbox_conf_perm -> conv11_2_mbox_conf_perm
I0622 04:06:55.599207 13672 net.cpp:150] Setting up conv11_2_mbox_conf_perm
I0622 04:06:55.599207 13672 net.cpp:157] Top shape: 2 1 1 12 (24)
I0622 04:06:55.599207 13672 net.cpp:165] Memory required for data: 495965536
I0622 04:06:55.599207 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_conf_flat
I0622 04:06:55.599207 13672 net.cpp:100] Creating Layer conv11_2_mbox_conf_flat
I0622 04:06:55.599207 13672 net.cpp:434] conv11_2_mbox_conf_flat <- conv11_2_mbox_conf_perm
I0622 04:06:55.599207 13672 net.cpp:408] conv11_2_mbox_conf_flat -> conv11_2_mbox_conf_flat
I0622 04:06:55.599207 13672 net.cpp:150] Setting up conv11_2_mbox_conf_flat
I0622 04:06:55.599207 13672 net.cpp:157] Top shape: 2 12 (24)
I0622 04:06:55.599207 13672 net.cpp:165] Memory required for data: 495965632
I0622 04:06:55.599207 13672 layer_factory.hpp:77] Creating layer conv11_2_mbox_priorbox
I0622 04:06:55.599207 13672 net.cpp:100] Creating Layer conv11_2_mbox_priorbox
I0622 04:06:55.599207 13672 net.cpp:434] conv11_2_mbox_priorbox <- conv11_2_conv11_2_relu_0_split_2
I0622 04:06:55.599207 13672 net.cpp:434] conv11_2_mbox_priorbox <- data_data_0_split_6
I0622 04:06:55.600204 13672 net.cpp:408] conv11_2_mbox_priorbox -> conv11_2_mbox_priorbox
I0622 04:06:55.600204 13672 net.cpp:150] Setting up conv11_2_mbox_priorbox
I0622 04:06:55.600204 13672 net.cpp:157] Top shape: 1 2 16 (32)
I0622 04:06:55.600204 13672 net.cpp:165] Memory required for data: 495965760
I0622 04:06:55.600204 13672 layer_factory.hpp:77] Creating layer mbox_loc
I0622 04:06:55.600204 13672 net.cpp:100] Creating Layer mbox_loc
I0622 04:06:55.600204 13672 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0622 04:06:55.600204 13672 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0622 04:06:55.600204 13672 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0622 04:06:55.600204 13672 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0622 04:06:55.600204 13672 net.cpp:434] mbox_loc <- conv10_2_mbox_loc_flat
I0622 04:06:55.600204 13672 net.cpp:434] mbox_loc <- conv11_2_mbox_loc_flat
I0622 04:06:55.600204 13672 net.cpp:408] mbox_loc -> mbox_loc
I0622 04:06:55.600204 13672 net.cpp:150] Setting up mbox_loc
I0622 04:06:55.629701 13672 net.cpp:157] Top shape: 2 34928 (69856)
I0622 04:06:55.629701 13672 net.cpp:165] Memory required for data: 496245184
I0622 04:06:55.629701 13672 layer_factory.hpp:77] Creating layer mbox_conf
I0622 04:06:55.641310 13672 net.cpp:100] Creating Layer mbox_conf
I0622 04:06:55.641310 13672 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0622 04:06:55.641310 13672 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0622 04:06:55.641310 13672 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0622 04:06:55.641310 13672 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0622 04:06:55.641310 13672 net.cpp:434] mbox_conf <- conv10_2_mbox_conf_flat
I0622 04:06:55.641310 13672 net.cpp:434] mbox_conf <- conv11_2_mbox_conf_flat
I0622 04:06:55.641310 13672 net.cpp:408] mbox_conf -> mbox_conf
I0622 04:06:55.641310 13672 net.cpp:150] Setting up mbox_conf
I0622 04:06:55.641310 13672 net.cpp:157] Top shape: 2 26196 (52392)
I0622 04:06:55.641310 13672 net.cpp:165] Memory required for data: 496454752
I0622 04:06:55.641310 13672 layer_factory.hpp:77] Creating layer mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:100] Creating Layer mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:434] mbox_priorbox <- conv10_2_mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:434] mbox_priorbox <- conv11_2_mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:150] Setting up mbox_priorbox
I0622 04:06:55.641310 13672 net.cpp:157] Top shape: 1 2 34928 (69856)
I0622 04:06:55.641310 13672 net.cpp:165] Memory required for data: 496734176
I0622 04:06:55.641310 13672 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0622 04:06:55.641310 13672 net.cpp:100] Creating Layer mbox_conf_reshape
I0622 04:06:55.641310 13672 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0622 04:06:55.641310 13672 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0622 04:06:55.641310 13672 net.cpp:150] Setting up mbox_conf_reshape
I0622 04:06:55.641310 13672 net.cpp:157] Top shape: 2 8732 3 (52392)
I0622 04:06:55.641310 13672 net.cpp:165] Memory required for data: 496943744
I0622 04:06:55.641310 13672 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0622 04:06:55.641310 13672 net.cpp:100] Creating Layer mbox_conf_softmax
I0622 04:06:55.641310 13672 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0622 04:06:55.641310 13672 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0622 04:06:55.644305 13672 net.cpp:150] Setting up mbox_conf_softmax
I0622 04:06:55.644305 13672 net.cpp:157] Top shape: 2 8732 3 (52392)
I0622 04:06:55.645299 13672 net.cpp:165] Memory required for data: 497153312
I0622 04:06:55.645299 13672 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0622 04:06:55.645299 13672 net.cpp:100] Creating Layer mbox_conf_flatten
I0622 04:06:55.645299 13672 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0622 04:06:55.645299 13672 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0622 04:06:55.645299 13672 net.cpp:150] Setting up mbox_conf_flatten
I0622 04:06:55.645299 13672 net.cpp:157] Top shape: 2 26196 (52392)
I0622 04:06:55.645299 13672 net.cpp:165] Memory required for data: 497362880
I0622 04:06:55.645299 13672 layer_factory.hpp:77] Creating layer detection_out
I0622 04:06:55.645299 13672 net.cpp:100] Creating Layer detection_out
I0622 04:06:55.645299 13672 net.cpp:434] detection_out <- mbox_loc
I0622 04:06:55.645299 13672 net.cpp:434] detection_out <- mbox_conf_flatten
I0622 04:06:55.645299 13672 net.cpp:434] detection_out <- mbox_priorbox
I0622 04:06:55.645299 13672 net.cpp:408] detection_out -> detection_out
W0622 04:06:55.647301 13672 detection_output_layer.cpp:49] Failed to create directory: data\wastedata\results\SSD_300x300\Main
I0622 04:06:55.713488 13672 net.cpp:150] Setting up detection_out
I0622 04:06:55.713488 13672 net.cpp:157] Top shape: 1 1 1 7 (7)
I0622 04:06:55.713488 13672 net.cpp:165] Memory required for data: 497362908
I0622 04:06:55.714165 13672 layer_factory.hpp:77] Creating layer detection_eval
I0622 04:06:55.714165 13672 net.cpp:100] Creating Layer detection_eval
I0622 04:06:55.714165 13672 net.cpp:434] detection_eval <- detection_out
I0622 04:06:55.714165 13672 net.cpp:434] detection_eval <- label
I0622 04:06:55.714165 13672 net.cpp:408] detection_eval -> detection_eval
I0622 04:06:55.716176 13672 net.cpp:150] Setting up detection_eval
I0622 04:06:55.716176 13672 net.cpp:157] Top shape: 1 1 3 5 (15)
I0622 04:06:55.716176 13672 net.cpp:165] Memory required for data: 497362968
I0622 04:06:55.716176 13672 net.cpp:228] detection_eval does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] detection_out does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] mbox_priorbox does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] mbox_conf does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] mbox_loc does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv11_2_mbox_priorbox does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv11_2_mbox_conf_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv11_2_mbox_conf_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv11_2_mbox_conf does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv11_2_mbox_loc_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv11_2_mbox_loc_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv11_2_mbox_loc does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv10_2_mbox_priorbox does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv10_2_mbox_conf_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv10_2_mbox_conf_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv10_2_mbox_conf does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv10_2_mbox_loc_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv10_2_mbox_loc_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv10_2_mbox_loc does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv9_2_mbox_conf_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv9_2_mbox_conf_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv9_2_mbox_conf does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv9_2_mbox_loc_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv9_2_mbox_loc_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv9_2_mbox_loc does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv8_2_mbox_conf_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv8_2_mbox_conf_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv8_2_mbox_conf does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv8_2_mbox_loc_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv8_2_mbox_loc_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv8_2_mbox_loc does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] fc7_mbox_conf_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] fc7_mbox_conf_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] fc7_mbox_conf does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] fc7_mbox_loc_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] fc7_mbox_loc_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] fc7_mbox_loc does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv4_3_norm_mbox_conf_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv4_3_norm_mbox_conf_perm does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv4_3_norm_mbox_conf does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv4_3_norm_mbox_loc_flat does not need backward computation.
I0622 04:06:55.716646 13672 net.cpp:228] conv4_3_norm_mbox_loc_perm does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv4_3_norm_mbox_loc does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv4_3_norm does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv11_2_conv11_2_relu_0_split does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv11_2_relu does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv11_2 does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv11_1_relu does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv11_1 does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv10_2_conv10_2_relu_0_split does not need backward computation.
I0622 04:06:55.717666 13672 net.cpp:228] conv10_2_relu does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv10_2 does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv10_1_relu does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv10_1 does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv9_2_conv9_2_relu_0_split does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv9_2_relu does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv9_2 does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv9_1_relu does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv9_1 does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv8_2_relu does not need backward computation.
I0622 04:06:55.719660 13672 net.cpp:228] conv8_2 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] conv8_1_relu does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] conv8_1 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] fc7_relu7_0_split does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] relu7 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] fc7 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] relu6 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] fc6 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] pool5 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] relu5_3 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] conv5_3 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] relu5_2 does not need backward computation.
I0622 04:06:55.721655 13672 net.cpp:228] conv5_2 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] relu5_1 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] conv5_1 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] pool4 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] relu4_3 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] conv4_3 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] relu4_2 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] conv4_2 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] relu4_1 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] conv4_1 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] pool3 does not need backward computation.
I0622 04:06:55.723650 13672 net.cpp:228] relu3_3 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] conv3_3 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] relu3_2 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] conv3_2 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] relu3_1 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] conv3_1 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] pool2 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] relu2_2 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] conv2_2 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] relu2_1 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] conv2_1 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] pool1 does not need backward computation.
I0622 04:06:55.729607 13672 net.cpp:228] relu1_2 does not need backward computation.
I0622 04:06:55.731597 13672 net.cpp:228] conv1_2 does not need backward computation.
I0622 04:06:55.731597 13672 net.cpp:228] relu1_1 does not need backward computation.
I0622 04:06:55.731597 13672 net.cpp:228] conv1_1 does not need backward computation.
I0622 04:06:55.731597 13672 net.cpp:228] data_data_0_split does not need backward computation.
I0622 04:06:55.731597 13672 net.cpp:228] data does not need backward computation.
I0622 04:06:55.731597 13672 net.cpp:270] This network produces output detection_eval
I0622 04:06:55.731597 13672 net.cpp:283] Network initialization done.
I0622 04:06:55.732595 13672 solver.cpp:75] Solver scaffolding done.
I0622 04:06:55.739575 13672 caffe.cpp:155] Finetuning from models\VGGNet\VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0622 04:06:55.761699 13672 caffe.cpp:257] Starting Optimization
I0622 04:06:55.761699 13672 solver.cpp:294] Solving VGG_wastedata_SSD_300x300_train
I0622 04:06:55.761699 13672 solver.cpp:295] Learning Rate Policy: multistep
I0622 04:06:55.827343 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0622 04:07:15.562515 13672 solver.cpp:243] Iteration 0, loss = 11.6927
I0622 04:07:15.562515 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.2473 (* 1 = 12.2473 loss)
I0622 04:07:15.562515 13672 sgd_solver.cpp:138] Iteration 0, lr = 0.001
I0622 04:10:34.207751 13672 solver.cpp:243] Iteration 10, loss = 8.55683
I0622 04:10:34.238994 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.1809 (* 1 = 10.1809 loss)
I0622 04:10:34.238994 13672 sgd_solver.cpp:138] Iteration 10, lr = 0.001
I0622 04:13:44.675905 13672 solver.cpp:243] Iteration 20, loss = 8.44349
I0622 04:13:44.675905 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.09627 (* 1 = 6.09627 loss)
I0622 04:13:44.675905 13672 sgd_solver.cpp:138] Iteration 20, lr = 0.001
I0622 04:16:55.052232 13672 solver.cpp:243] Iteration 30, loss = 10.8352
I0622 04:16:55.052232 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.31414 (* 1 = 5.31414 loss)
I0622 04:16:55.052232 13672 sgd_solver.cpp:138] Iteration 30, lr = 0.001
I0622 04:20:14.674293 13672 solver.cpp:243] Iteration 40, loss = 12.1031
I0622 04:20:14.674293 13672 solver.cpp:259]     Train net output #0: mbox_loss = 23.4952 (* 1 = 23.4952 loss)
I0622 04:20:14.674293 13672 sgd_solver.cpp:138] Iteration 40, lr = 0.001
I0622 04:23:37.064612 13672 solver.cpp:243] Iteration 50, loss = 11.8126
I0622 04:23:37.064612 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.3664 (* 1 = 7.3664 loss)
I0622 04:23:37.064612 13672 sgd_solver.cpp:138] Iteration 50, lr = 0.001
I0622 04:27:04.797382 13672 solver.cpp:243] Iteration 60, loss = 11.7074
I0622 04:27:04.797382 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.58899 (* 1 = 6.58899 loss)
I0622 04:27:04.797382 13672 sgd_solver.cpp:138] Iteration 60, lr = 0.001
I0622 04:30:24.797907 13672 solver.cpp:243] Iteration 70, loss = 13.9583
I0622 04:30:24.797907 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.97389 (* 1 = 5.97389 loss)
I0622 04:30:24.797907 13672 sgd_solver.cpp:138] Iteration 70, lr = 0.001
I0622 04:33:36.206399 13672 solver.cpp:243] Iteration 80, loss = 16.1568
I0622 04:33:36.206399 13672 solver.cpp:259]     Train net output #0: mbox_loss = 47.9534 (* 1 = 47.9534 loss)
I0622 04:33:36.206399 13672 sgd_solver.cpp:138] Iteration 80, lr = 0.001
I0622 04:36:50.239284 13672 solver.cpp:243] Iteration 90, loss = 14.2209
I0622 04:36:50.239284 13672 solver.cpp:259]     Train net output #0: mbox_loss = 34.9407 (* 1 = 34.9407 loss)
I0622 04:36:50.239284 13672 sgd_solver.cpp:138] Iteration 90, lr = 0.001
I0622 04:40:02.288314 13672 solver.cpp:243] Iteration 100, loss = 12.2288
I0622 04:40:02.288314 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.19423 (* 1 = 5.19423 loss)
I0622 04:40:02.288314 13672 sgd_solver.cpp:138] Iteration 100, lr = 0.001
I0622 04:43:18.320729 13672 solver.cpp:243] Iteration 110, loss = 16.0123
I0622 04:43:18.320729 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.50496 (* 1 = 8.50496 loss)
I0622 04:43:18.320729 13672 sgd_solver.cpp:138] Iteration 110, lr = 0.001
I0622 04:46:23.121392 13672 solver.cpp:243] Iteration 120, loss = 15.7108
I0622 04:46:23.121392 13672 solver.cpp:259]     Train net output #0: mbox_loss = 32.5071 (* 1 = 32.5071 loss)
I0622 04:46:23.121392 13672 sgd_solver.cpp:138] Iteration 120, lr = 0.001
I0622 04:49:44.949378 13672 solver.cpp:243] Iteration 130, loss = 13.0371
I0622 04:49:44.949378 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.05178 (* 1 = 6.05178 loss)
I0622 04:49:44.949378 13672 sgd_solver.cpp:138] Iteration 130, lr = 0.001
I0622 04:53:01.997140 13672 solver.cpp:243] Iteration 140, loss = 11.9018
I0622 04:53:01.997140 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.3528 (* 1 = 12.3528 loss)
I0622 04:53:01.997140 13672 sgd_solver.cpp:138] Iteration 140, lr = 0.001
I0622 04:56:14.264853 13672 solver.cpp:243] Iteration 150, loss = 17.2029
I0622 04:56:14.264853 13672 solver.cpp:259]     Train net output #0: mbox_loss = 33.742 (* 1 = 33.742 loss)
I0622 04:56:14.264853 13672 sgd_solver.cpp:138] Iteration 150, lr = 0.001
I0622 04:59:33.171635 13672 solver.cpp:243] Iteration 160, loss = 15.4085
I0622 04:59:33.171635 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.3399 (* 1 = 11.3399 loss)
I0622 04:59:33.171635 13672 sgd_solver.cpp:138] Iteration 160, lr = 0.001
I0622 05:03:02.466014 13672 solver.cpp:243] Iteration 170, loss = 11.5116
I0622 05:03:02.481637 13672 solver.cpp:259]     Train net output #0: mbox_loss = 38.9905 (* 1 = 38.9905 loss)
I0622 05:03:02.481637 13672 sgd_solver.cpp:138] Iteration 170, lr = 0.001
I0622 05:06:15.135941 13672 solver.cpp:243] Iteration 180, loss = 11.2762
I0622 05:06:15.135941 13672 solver.cpp:259]     Train net output #0: mbox_loss = 22.8118 (* 1 = 22.8118 loss)
I0622 05:06:15.135941 13672 sgd_solver.cpp:138] Iteration 180, lr = 0.001
I0622 05:09:20.155315 13672 solver.cpp:243] Iteration 190, loss = 11.6252
I0622 05:09:20.155315 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.82567 (* 1 = 4.82567 loss)
I0622 05:09:20.155315 13672 sgd_solver.cpp:138] Iteration 190, lr = 0.001
I0622 05:12:40.983582 13672 solver.cpp:243] Iteration 200, loss = 13.085
I0622 05:12:40.983582 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.80934 (* 1 = 9.80934 loss)
I0622 05:12:40.983582 13672 sgd_solver.cpp:138] Iteration 200, lr = 0.001
I0622 05:15:50.626906 13672 solver.cpp:243] Iteration 210, loss = 11.8556
I0622 05:15:50.626906 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.3333 (* 1 = 17.3333 loss)
I0622 05:15:50.626906 13672 sgd_solver.cpp:138] Iteration 210, lr = 0.001
I0622 05:19:11.569986 13672 solver.cpp:243] Iteration 220, loss = 10.2453
I0622 05:19:11.569986 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.59219 (* 1 = 4.59219 loss)
I0622 05:19:11.569986 13672 sgd_solver.cpp:138] Iteration 220, lr = 0.001
I0622 05:22:31.070374 13672 solver.cpp:243] Iteration 230, loss = 9.19099
I0622 05:22:31.070374 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.71473 (* 1 = 5.71473 loss)
I0622 05:22:31.070374 13672 sgd_solver.cpp:138] Iteration 230, lr = 0.001
I0622 05:25:44.197191 13672 solver.cpp:243] Iteration 240, loss = 10.7541
I0622 05:25:44.197191 13672 solver.cpp:259]     Train net output #0: mbox_loss = 22.6313 (* 1 = 22.6313 loss)
I0622 05:25:44.197191 13672 sgd_solver.cpp:138] Iteration 240, lr = 0.001
I0622 05:28:56.955910 13672 solver.cpp:243] Iteration 250, loss = 8.35875
I0622 05:28:56.955910 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.96635 (* 1 = 6.96635 loss)
I0622 05:28:56.955910 13672 sgd_solver.cpp:138] Iteration 250, lr = 0.001
I0622 05:32:06.146323 13672 solver.cpp:243] Iteration 260, loss = 10.4356
I0622 05:32:06.146323 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.8285 (* 1 = 17.8285 loss)
I0622 05:32:06.146323 13672 sgd_solver.cpp:138] Iteration 260, lr = 0.001
I0622 05:35:26.224673 13672 solver.cpp:243] Iteration 270, loss = 14.1055
I0622 05:35:26.224673 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.40104 (* 1 = 4.40104 loss)
I0622 05:35:26.224673 13672 sgd_solver.cpp:138] Iteration 270, lr = 0.001
I0622 05:38:35.055675 13672 solver.cpp:243] Iteration 280, loss = 8.63813
I0622 05:38:35.055675 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.46567 (* 1 = 4.46567 loss)
I0622 05:38:35.055675 13672 sgd_solver.cpp:138] Iteration 280, lr = 0.001
I0622 05:41:45.212345 13672 solver.cpp:243] Iteration 290, loss = 10.1038
I0622 05:41:45.212345 13672 solver.cpp:259]     Train net output #0: mbox_loss = 22.6019 (* 1 = 22.6019 loss)
I0622 05:41:45.212345 13672 sgd_solver.cpp:138] Iteration 290, lr = 0.001
I0622 05:44:52.613068 13672 solver.cpp:243] Iteration 300, loss = 11.8848
I0622 05:44:52.613068 13672 solver.cpp:259]     Train net output #0: mbox_loss = 28.0967 (* 1 = 28.0967 loss)
I0622 05:44:52.613068 13672 sgd_solver.cpp:138] Iteration 300, lr = 0.001
I0622 05:48:05.945245 13672 solver.cpp:243] Iteration 310, loss = 12.2969
I0622 05:48:05.945245 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.4262 (* 1 = 5.4262 loss)
I0622 05:48:05.945245 13672 sgd_solver.cpp:138] Iteration 310, lr = 0.001
I0622 05:51:18.244118 13672 solver.cpp:243] Iteration 320, loss = 10.9811
I0622 05:51:18.244118 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.87201 (* 1 = 5.87201 loss)
I0622 05:51:18.244118 13672 sgd_solver.cpp:138] Iteration 320, lr = 0.001
I0622 05:54:39.619042 13672 solver.cpp:243] Iteration 330, loss = 9.54186
I0622 05:54:39.619042 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.48448 (* 1 = 4.48448 loss)
I0622 05:54:39.619042 13672 sgd_solver.cpp:138] Iteration 330, lr = 0.001
I0622 05:57:49.402954 13672 solver.cpp:243] Iteration 340, loss = 10.1669
I0622 05:57:49.402954 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.57519 (* 1 = 4.57519 loss)
I0622 05:57:49.402954 13672 sgd_solver.cpp:138] Iteration 340, lr = 0.001
I0622 06:01:02.575641 13672 solver.cpp:243] Iteration 350, loss = 8.7077
I0622 06:01:02.575641 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.59431 (* 1 = 4.59431 loss)
I0622 06:01:02.575641 13672 sgd_solver.cpp:138] Iteration 350, lr = 0.001
I0622 06:04:13.187419 13672 solver.cpp:243] Iteration 360, loss = 11.0583
I0622 06:04:13.187419 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.63344 (* 1 = 5.63344 loss)
I0622 06:04:13.187419 13672 sgd_solver.cpp:138] Iteration 360, lr = 0.001
I0622 06:07:17.252187 13672 solver.cpp:243] Iteration 370, loss = 13.0945
I0622 06:07:17.252187 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.3527 (* 1 = 5.3527 loss)
I0622 06:07:17.252187 13672 sgd_solver.cpp:138] Iteration 370, lr = 0.001
I0622 06:10:41.558193 13672 solver.cpp:243] Iteration 380, loss = 11.4751
I0622 06:10:41.558193 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.40517 (* 1 = 5.40517 loss)
I0622 06:10:41.558193 13672 sgd_solver.cpp:138] Iteration 380, lr = 0.001
I0622 06:13:48.994459 13672 solver.cpp:243] Iteration 390, loss = 11.0111
I0622 06:13:48.994459 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.78647 (* 1 = 2.78647 loss)
I0622 06:13:48.994459 13672 sgd_solver.cpp:138] Iteration 390, lr = 0.001
I0622 06:16:50.342748 13672 solver.cpp:243] Iteration 400, loss = 9.85181
I0622 06:16:50.342748 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.63003 (* 1 = 4.63003 loss)
I0622 06:16:50.342748 13672 sgd_solver.cpp:138] Iteration 400, lr = 0.001
I0622 06:19:52.487815 13672 solver.cpp:243] Iteration 410, loss = 9.51937
I0622 06:19:52.487815 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.4658 (* 1 = 17.4658 loss)
I0622 06:19:52.487815 13672 sgd_solver.cpp:138] Iteration 410, lr = 0.001
I0622 06:23:04.064231 13672 solver.cpp:243] Iteration 420, loss = 7.39399
I0622 06:23:04.064231 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.2616 (* 1 = 12.2616 loss)
I0622 06:23:04.064231 13672 sgd_solver.cpp:138] Iteration 420, lr = 0.001
I0622 06:26:17.897724 13672 solver.cpp:243] Iteration 430, loss = 8.50795
I0622 06:26:17.897724 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.8168 (* 1 = 11.8168 loss)
I0622 06:26:17.897724 13672 sgd_solver.cpp:138] Iteration 430, lr = 0.001
I0622 06:29:24.447970 13672 solver.cpp:243] Iteration 440, loss = 10.9985
I0622 06:29:24.447970 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.41328 (* 1 = 4.41328 loss)
I0622 06:29:24.447970 13672 sgd_solver.cpp:138] Iteration 440, lr = 0.001
I0622 06:32:35.372242 13672 solver.cpp:243] Iteration 450, loss = 10.1799
I0622 06:32:35.372242 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.44706 (* 1 = 4.44706 loss)
I0622 06:32:35.372242 13672 sgd_solver.cpp:138] Iteration 450, lr = 0.001
I0622 06:35:37.407896 13672 solver.cpp:243] Iteration 460, loss = 8.36855
I0622 06:35:37.407896 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.87262 (* 1 = 5.87262 loss)
I0622 06:35:37.407896 13672 sgd_solver.cpp:138] Iteration 460, lr = 0.001
I0622 06:39:04.531476 13672 solver.cpp:243] Iteration 470, loss = 8.75664
I0622 06:39:04.547103 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.12643 (* 1 = 4.12643 loss)
I0622 06:39:04.547103 13672 sgd_solver.cpp:138] Iteration 470, lr = 0.001
I0622 06:42:13.112516 13672 solver.cpp:243] Iteration 480, loss = 9.68054
I0622 06:42:13.112516 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.39796 (* 1 = 7.39796 loss)
I0622 06:42:13.112516 13672 sgd_solver.cpp:138] Iteration 480, lr = 0.001
I0622 06:45:19.084774 13672 solver.cpp:243] Iteration 490, loss = 8.55081
I0622 06:45:19.084774 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.54192 (* 1 = 3.54192 loss)
I0622 06:45:19.084774 13672 sgd_solver.cpp:138] Iteration 490, lr = 0.001
I0622 06:48:33.616961 13672 solver.cpp:243] Iteration 500, loss = 7.00982
I0622 06:48:33.616961 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.94183 (* 1 = 4.94183 loss)
I0622 06:48:33.616961 13672 sgd_solver.cpp:138] Iteration 500, lr = 0.001
I0622 06:51:41.698189 13672 solver.cpp:243] Iteration 510, loss = 7.47205
I0622 06:51:41.698189 13672 solver.cpp:259]     Train net output #0: mbox_loss = 18.1869 (* 1 = 18.1869 loss)
I0622 06:51:41.698189 13672 sgd_solver.cpp:138] Iteration 510, lr = 0.001
I0622 06:53:53.209003 13720 blocking_queue.cpp:51] Waiting for data
I0622 06:54:54.938901 13672 solver.cpp:243] Iteration 520, loss = 7.80117
I0622 06:54:54.938901 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.12628 (* 1 = 3.12628 loss)
I0622 06:54:54.938901 13672 sgd_solver.cpp:138] Iteration 520, lr = 0.001
I0622 06:57:59.256228 13672 solver.cpp:243] Iteration 530, loss = 9.20948
I0622 06:57:59.256228 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.19319 (* 1 = 2.19319 loss)
I0622 06:57:59.256228 13672 sgd_solver.cpp:138] Iteration 530, lr = 0.001
I0622 07:00:54.621639 13672 solver.cpp:243] Iteration 540, loss = 11.3771
I0622 07:00:54.621639 13672 solver.cpp:259]     Train net output #0: mbox_loss = 35.0715 (* 1 = 35.0715 loss)
I0622 07:00:54.621639 13672 sgd_solver.cpp:138] Iteration 540, lr = 0.001
I0622 07:03:52.423931 13672 solver.cpp:243] Iteration 550, loss = 8.95946
I0622 07:03:52.423931 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.35476 (* 1 = 5.35476 loss)
I0622 07:03:52.423931 13672 sgd_solver.cpp:138] Iteration 550, lr = 0.001
I0622 07:07:03.348165 13672 solver.cpp:243] Iteration 560, loss = 7.45333
I0622 07:07:03.348165 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.0685 (* 1 = 4.0685 loss)
I0622 07:07:03.348165 13672 sgd_solver.cpp:138] Iteration 560, lr = 0.001
I0622 07:10:25.988571 13672 solver.cpp:243] Iteration 570, loss = 8.9065
I0622 07:10:25.988571 13672 solver.cpp:259]     Train net output #0: mbox_loss = 22.3452 (* 1 = 22.3452 loss)
I0622 07:10:25.988571 13672 sgd_solver.cpp:138] Iteration 570, lr = 0.001
I0622 07:13:39.412225 13672 solver.cpp:243] Iteration 580, loss = 10.8831
I0622 07:13:39.412225 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.71443 (* 1 = 7.71443 loss)
I0622 07:13:39.412225 13672 sgd_solver.cpp:138] Iteration 580, lr = 0.001
I0622 07:16:57.075309 13672 solver.cpp:243] Iteration 590, loss = 10.5864
I0622 07:16:57.075309 13672 solver.cpp:259]     Train net output #0: mbox_loss = 15.472 (* 1 = 15.472 loss)
I0622 07:16:57.075309 13672 sgd_solver.cpp:138] Iteration 590, lr = 0.001
I0622 07:20:05.125317 13672 solver.cpp:243] Iteration 600, loss = 13.0563
I0622 07:20:05.125317 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.47456 (* 1 = 4.47456 loss)
I0622 07:20:05.125317 13672 sgd_solver.cpp:138] Iteration 600, lr = 0.001
I0622 07:23:22.922948 13672 solver.cpp:243] Iteration 610, loss = 12.4994
I0622 07:23:22.922948 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.84357 (* 1 = 5.84357 loss)
I0622 07:23:22.922948 13672 sgd_solver.cpp:138] Iteration 610, lr = 0.001
I0622 07:26:29.184486 13672 solver.cpp:243] Iteration 620, loss = 11.7768
I0622 07:26:29.184486 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.28577 (* 1 = 5.28577 loss)
I0622 07:26:29.184486 13672 sgd_solver.cpp:138] Iteration 620, lr = 0.001
I0622 07:29:35.609810 13672 solver.cpp:243] Iteration 630, loss = 10.0015
I0622 07:29:35.609810 13672 solver.cpp:259]     Train net output #0: mbox_loss = 35.2552 (* 1 = 35.2552 loss)
I0622 07:29:35.609810 13672 sgd_solver.cpp:138] Iteration 630, lr = 0.001
I0622 07:32:44.222084 13672 solver.cpp:243] Iteration 640, loss = 10.2612
I0622 07:32:44.222084 13672 solver.cpp:259]     Train net output #0: mbox_loss = 26.1975 (* 1 = 26.1975 loss)
I0622 07:32:44.222084 13672 sgd_solver.cpp:138] Iteration 640, lr = 0.001
I0622 07:35:53.396821 13672 solver.cpp:243] Iteration 650, loss = 9.57205
I0622 07:35:53.396821 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.256 (* 1 = 12.256 loss)
I0622 07:35:53.396821 13672 sgd_solver.cpp:138] Iteration 650, lr = 0.001
I0622 08:05:32.165973 13672 solver.cpp:243] Iteration 660, loss = 10.0518
I0622 08:05:32.165973 13672 solver.cpp:259]     Train net output #0: mbox_loss = 30.1091 (* 1 = 30.1091 loss)
I0622 08:05:32.165973 13672 sgd_solver.cpp:138] Iteration 660, lr = 0.001
I0622 08:08:39.716101 13672 solver.cpp:243] Iteration 670, loss = 11.5381
I0622 08:08:39.716101 13672 solver.cpp:259]     Train net output #0: mbox_loss = 22.1066 (* 1 = 22.1066 loss)
I0622 08:08:39.716101 13672 sgd_solver.cpp:138] Iteration 670, lr = 0.001
I0622 08:11:55.295444 13672 solver.cpp:243] Iteration 680, loss = 10.4728
I0622 08:11:55.295444 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.2606 (* 1 = 12.2606 loss)
I0622 08:11:55.295444 13672 sgd_solver.cpp:138] Iteration 680, lr = 0.001
I0622 08:14:55.440970 13672 solver.cpp:243] Iteration 690, loss = 10.0801
I0622 08:14:55.440970 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.33502 (* 1 = 5.33502 loss)
I0622 08:14:55.440970 13672 sgd_solver.cpp:138] Iteration 690, lr = 0.001
I0622 08:15:30.042281 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0622 08:18:26.594871 13672 solver.cpp:243] Iteration 700, loss = 9.6976
I0622 08:18:26.594871 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.08916 (* 1 = 8.08916 loss)
I0622 08:18:26.594871 13672 sgd_solver.cpp:138] Iteration 700, lr = 0.001
I0622 08:21:25.849478 13672 solver.cpp:243] Iteration 710, loss = 7.96435
I0622 08:21:25.849478 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.1776 (* 1 = 12.1776 loss)
I0622 08:21:25.849478 13672 sgd_solver.cpp:138] Iteration 710, lr = 0.001
I0622 08:24:23.698782 13672 solver.cpp:243] Iteration 720, loss = 8.46084
I0622 08:24:23.698782 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.10979 (* 1 = 4.10979 loss)
I0622 08:24:23.698782 13672 sgd_solver.cpp:138] Iteration 720, lr = 0.001
I0622 08:27:36.716279 13672 solver.cpp:243] Iteration 730, loss = 9.27857
I0622 08:27:36.716279 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.85725 (* 1 = 3.85725 loss)
I0622 08:27:36.716279 13672 sgd_solver.cpp:138] Iteration 730, lr = 0.001
I0622 08:30:53.670320 13672 solver.cpp:243] Iteration 740, loss = 8.99684
I0622 08:30:53.670320 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.23985 (* 1 = 4.23985 loss)
I0622 08:30:53.670320 13672 sgd_solver.cpp:138] Iteration 740, lr = 0.001
I0622 08:34:06.547308 13672 solver.cpp:243] Iteration 750, loss = 7.86818
I0622 08:34:06.547308 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.41576 (* 1 = 5.41576 loss)
I0622 08:34:06.547308 13672 sgd_solver.cpp:138] Iteration 750, lr = 0.001
I0622 08:37:18.190129 13672 solver.cpp:243] Iteration 760, loss = 8.58614
I0622 08:37:18.190129 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.88327 (* 1 = 9.88327 loss)
I0622 08:37:18.190129 13672 sgd_solver.cpp:138] Iteration 760, lr = 0.001
I0622 08:40:51.593536 13672 solver.cpp:243] Iteration 770, loss = 9.54463
I0622 08:40:51.593536 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.05378 (* 1 = 3.05378 loss)
I0622 08:40:51.593536 13672 sgd_solver.cpp:138] Iteration 770, lr = 0.001
I0622 08:43:52.098325 13672 solver.cpp:243] Iteration 780, loss = 9.14232
I0622 08:43:52.098325 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.27525 (* 1 = 3.27525 loss)
I0622 08:43:52.098325 13672 sgd_solver.cpp:138] Iteration 780, lr = 0.001
I0622 08:47:05.366223 13672 solver.cpp:243] Iteration 790, loss = 8.75773
I0622 08:47:05.381844 13672 solver.cpp:259]     Train net output #0: mbox_loss = 16.9761 (* 1 = 16.9761 loss)
I0622 08:47:05.381844 13672 sgd_solver.cpp:138] Iteration 790, lr = 0.001
I0622 08:50:10.229187 13672 solver.cpp:243] Iteration 800, loss = 7.61364
I0622 08:50:10.229187 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.89645 (* 1 = 5.89645 loss)
I0622 08:50:10.229187 13672 sgd_solver.cpp:138] Iteration 800, lr = 0.001
I0622 08:53:13.842674 13672 solver.cpp:243] Iteration 810, loss = 6.58221
I0622 08:53:13.842674 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.87409 (* 1 = 4.87409 loss)
I0622 08:53:13.842674 13672 sgd_solver.cpp:138] Iteration 810, lr = 0.001
I0622 08:56:28.721787 13672 solver.cpp:243] Iteration 820, loss = 7.57248
I0622 08:56:28.721787 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.89873 (* 1 = 8.89873 loss)
I0622 08:56:28.721787 13672 sgd_solver.cpp:138] Iteration 820, lr = 0.001
I0622 08:59:34.912750 13672 solver.cpp:243] Iteration 830, loss = 8.87461
I0622 08:59:34.912750 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.18417 (* 1 = 8.18417 loss)
I0622 08:59:34.912750 13672 sgd_solver.cpp:138] Iteration 830, lr = 0.001
I0622 09:02:47.289770 13672 solver.cpp:243] Iteration 840, loss = 13.7174
I0622 09:02:47.289770 13672 solver.cpp:259]     Train net output #0: mbox_loss = 13.3847 (* 1 = 13.3847 loss)
I0622 09:02:47.289770 13672 sgd_solver.cpp:138] Iteration 840, lr = 0.001
I0622 09:05:50.544009 13672 solver.cpp:243] Iteration 850, loss = 9.45004
I0622 09:05:50.544009 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.27647 (* 1 = 4.27647 loss)
I0622 09:05:50.544009 13672 sgd_solver.cpp:138] Iteration 850, lr = 0.001
I0622 09:09:10.466212 13672 solver.cpp:243] Iteration 860, loss = 10.7915
I0622 09:09:10.466212 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.09319 (* 1 = 6.09319 loss)
I0622 09:09:10.466212 13672 sgd_solver.cpp:138] Iteration 860, lr = 0.001
I0622 09:12:21.531038 13672 solver.cpp:243] Iteration 870, loss = 10.6124
I0622 09:12:21.531038 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.46027 (* 1 = 9.46027 loss)
I0622 09:12:21.531038 13672 sgd_solver.cpp:138] Iteration 870, lr = 0.001
I0622 09:17:07.446393 13672 solver.cpp:243] Iteration 880, loss = 8.51862
I0622 09:17:07.446393 13672 solver.cpp:259]     Train net output #0: mbox_loss = 16.1767 (* 1 = 16.1767 loss)
I0622 09:17:07.446393 13672 sgd_solver.cpp:138] Iteration 880, lr = 0.001
I0622 09:21:50.382241 13672 solver.cpp:243] Iteration 890, loss = 9.2874
I0622 09:21:50.382241 13672 solver.cpp:259]     Train net output #0: mbox_loss = 13.9308 (* 1 = 13.9308 loss)
I0622 09:21:50.382241 13672 sgd_solver.cpp:138] Iteration 890, lr = 0.001
I0622 09:26:25.521318 13672 solver.cpp:243] Iteration 900, loss = 8.72888
I0622 09:26:25.522382 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.95817 (* 1 = 4.95817 loss)
I0622 09:26:25.522382 13672 sgd_solver.cpp:138] Iteration 900, lr = 0.001
I0622 09:31:16.158001 13672 solver.cpp:243] Iteration 910, loss = 10.6764
I0622 09:31:16.158001 13672 solver.cpp:259]     Train net output #0: mbox_loss = 32.443 (* 1 = 32.443 loss)
I0622 09:31:16.158001 13672 sgd_solver.cpp:138] Iteration 910, lr = 0.001
I0622 09:36:00.393551 13672 solver.cpp:243] Iteration 920, loss = 11.5116
I0622 09:36:00.393551 13672 solver.cpp:259]     Train net output #0: mbox_loss = 37.4415 (* 1 = 37.4415 loss)
I0622 09:36:00.393551 13672 sgd_solver.cpp:138] Iteration 920, lr = 0.001
I0622 09:40:33.497931 13672 solver.cpp:243] Iteration 930, loss = 9.71892
I0622 09:40:33.497931 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.52258 (* 1 = 7.52258 loss)
I0622 09:40:33.497931 13672 sgd_solver.cpp:138] Iteration 930, lr = 0.001
I0622 09:43:36.502218 13672 solver.cpp:243] Iteration 940, loss = 8.39887
I0622 09:43:36.502218 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.08541 (* 1 = 6.08541 loss)
I0622 09:43:36.502218 13672 sgd_solver.cpp:138] Iteration 940, lr = 0.001
I0622 09:46:55.705824 13672 solver.cpp:243] Iteration 950, loss = 8.99738
I0622 09:46:55.705824 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.37549 (* 1 = 5.37549 loss)
I0622 09:46:55.705824 13672 sgd_solver.cpp:138] Iteration 950, lr = 0.001
I0622 09:50:06.081776 13672 solver.cpp:243] Iteration 960, loss = 8.94621
I0622 09:50:06.081776 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.31012 (* 1 = 3.31012 loss)
I0622 09:50:06.081776 13672 sgd_solver.cpp:138] Iteration 960, lr = 0.001
I0622 09:53:20.801103 13672 solver.cpp:243] Iteration 970, loss = 9.57894
I0622 09:53:20.801103 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.65585 (* 1 = 4.65585 loss)
I0622 09:53:20.801103 13672 sgd_solver.cpp:138] Iteration 970, lr = 0.001
I0622 09:56:33.209363 13672 solver.cpp:243] Iteration 980, loss = 10.2132
I0622 09:56:33.209363 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.45719 (* 1 = 3.45719 loss)
I0622 09:56:33.209363 13672 sgd_solver.cpp:138] Iteration 980, lr = 0.001
I0622 09:59:47.401902 13672 solver.cpp:243] Iteration 990, loss = 9.28139
I0622 09:59:47.401902 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.11715 (* 1 = 4.11715 loss)
I0622 09:59:47.401902 13672 sgd_solver.cpp:138] Iteration 990, lr = 0.001
I0622 10:02:59.029286 13672 solver.cpp:243] Iteration 1000, loss = 8.37659
I0622 10:02:59.029286 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.94028 (* 1 = 3.94028 loss)
I0622 10:02:59.029286 13672 sgd_solver.cpp:138] Iteration 1000, lr = 0.001
I0622 10:06:05.204632 13672 solver.cpp:243] Iteration 1010, loss = 9.65385
I0622 10:06:05.204632 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.8413 (* 1 = 11.8413 loss)
I0622 10:06:05.204632 13672 sgd_solver.cpp:138] Iteration 1010, lr = 0.001
I0622 10:09:43.747443 13672 solver.cpp:243] Iteration 1020, loss = 8.91902
I0622 10:09:44.075873 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.96144 (* 1 = 3.96144 loss)
I0622 10:09:44.075873 13672 sgd_solver.cpp:138] Iteration 1020, lr = 0.001
I0622 10:12:49.438509 13672 solver.cpp:243] Iteration 1030, loss = 7.35713
I0622 10:12:49.438509 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.00655 (* 1 = 3.00655 loss)
I0622 10:12:49.438509 13672 sgd_solver.cpp:138] Iteration 1030, lr = 0.001
I0622 10:16:08.548367 13672 solver.cpp:243] Iteration 1040, loss = 8.51824
I0622 10:16:08.610888 13672 solver.cpp:259]     Train net output #0: mbox_loss = 25.2721 (* 1 = 25.2721 loss)
I0622 10:16:08.610888 13672 sgd_solver.cpp:138] Iteration 1040, lr = 0.001
I0622 10:19:15.239137 13672 solver.cpp:243] Iteration 1050, loss = 8.46936
I0622 10:19:15.239137 13672 solver.cpp:259]     Train net output #0: mbox_loss = 20.4305 (* 1 = 20.4305 loss)
I0622 10:19:15.239137 13672 sgd_solver.cpp:138] Iteration 1050, lr = 0.001
I0622 10:22:30.365559 13672 solver.cpp:243] Iteration 1060, loss = 7.35224
I0622 10:22:30.365559 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.86631 (* 1 = 3.86631 loss)
I0622 10:22:30.365559 13672 sgd_solver.cpp:138] Iteration 1060, lr = 0.001
I0622 10:25:48.255439 13672 solver.cpp:243] Iteration 1070, loss = 8.12959
I0622 10:25:48.255439 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.43439 (* 1 = 4.43439 loss)
I0622 10:25:48.255439 13672 sgd_solver.cpp:138] Iteration 1070, lr = 0.001
I0622 10:28:57.430079 13672 solver.cpp:243] Iteration 1080, loss = 8.24771
I0622 10:28:57.430079 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.7857 (* 1 = 11.7857 loss)
I0622 10:28:57.430079 13672 sgd_solver.cpp:138] Iteration 1080, lr = 0.001
I0622 10:32:10.947458 13672 solver.cpp:243] Iteration 1090, loss = 8.18222
I0622 10:32:10.947458 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.30564 (* 1 = 4.30564 loss)
I0622 10:32:10.947458 13672 sgd_solver.cpp:138] Iteration 1090, lr = 0.001
I0622 10:35:36.103212 13672 solver.cpp:243] Iteration 1100, loss = 9.3083
I0622 10:35:36.180819 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.01596 (* 1 = 5.01596 loss)
I0622 10:35:36.196877 13672 sgd_solver.cpp:138] Iteration 1100, lr = 0.001
I0622 10:38:56.775012 13672 solver.cpp:243] Iteration 1110, loss = 10.2936
I0622 10:38:56.775012 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.16436 (* 1 = 5.16436 loss)
I0622 10:38:56.775012 13672 sgd_solver.cpp:138] Iteration 1110, lr = 0.001
I0622 10:42:17.790647 13672 solver.cpp:243] Iteration 1120, loss = 11.9044
I0622 10:42:17.790647 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.60936 (* 1 = 4.60936 loss)
I0622 10:42:17.790647 13672 sgd_solver.cpp:138] Iteration 1120, lr = 0.001
I0622 10:45:37.853329 13672 solver.cpp:243] Iteration 1130, loss = 9.80441
I0622 10:45:37.853329 13672 solver.cpp:259]     Train net output #0: mbox_loss = 21.0188 (* 1 = 21.0188 loss)
I0622 10:45:37.853329 13672 sgd_solver.cpp:138] Iteration 1130, lr = 0.001
I0622 10:48:57.728657 13672 solver.cpp:243] Iteration 1140, loss = 8.50742
I0622 10:48:57.728657 13672 solver.cpp:259]     Train net output #0: mbox_loss = 16.6405 (* 1 = 16.6405 loss)
I0622 10:48:57.728657 13672 sgd_solver.cpp:138] Iteration 1140, lr = 0.001
I0622 10:52:07.871825 13672 solver.cpp:243] Iteration 1150, loss = 7.82856
I0622 10:52:07.871825 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.41617 (* 1 = 5.41617 loss)
I0622 10:52:07.871825 13672 sgd_solver.cpp:138] Iteration 1150, lr = 0.001
I0622 10:55:20.123878 13672 solver.cpp:243] Iteration 1160, loss = 6.74659
I0622 10:55:20.123878 13672 solver.cpp:259]     Train net output #0: mbox_loss = 15.6392 (* 1 = 15.6392 loss)
I0622 10:55:20.123878 13672 sgd_solver.cpp:138] Iteration 1160, lr = 0.001
I0622 10:58:36.968873 13672 solver.cpp:243] Iteration 1170, loss = 8.55701
I0622 10:58:36.968873 13672 solver.cpp:259]     Train net output #0: mbox_loss = 38.5232 (* 1 = 38.5232 loss)
I0622 10:58:36.968873 13672 sgd_solver.cpp:138] Iteration 1170, lr = 0.001
I0622 11:01:49.857725 13672 solver.cpp:243] Iteration 1180, loss = 9.64775
I0622 11:01:49.873347 13672 solver.cpp:259]     Train net output #0: mbox_loss = 13.6358 (* 1 = 13.6358 loss)
I0622 11:01:49.873347 13672 sgd_solver.cpp:138] Iteration 1180, lr = 0.001
I0622 11:04:57.657712 13672 solver.cpp:243] Iteration 1190, loss = 9.10933
I0622 11:04:57.657712 13672 solver.cpp:259]     Train net output #0: mbox_loss = 15.6976 (* 1 = 15.6976 loss)
I0622 11:04:57.657712 13672 sgd_solver.cpp:138] Iteration 1190, lr = 0.001
I0622 11:08:12.830967 13672 solver.cpp:243] Iteration 1200, loss = 10.0944
I0622 11:08:12.830967 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.78367 (* 1 = 4.78367 loss)
I0622 11:08:12.830967 13672 sgd_solver.cpp:138] Iteration 1200, lr = 0.001
I0622 11:11:39.485875 13672 solver.cpp:243] Iteration 1210, loss = 7.96247
I0622 11:11:39.485875 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.82892 (* 1 = 5.82892 loss)
I0622 11:11:39.485875 13672 sgd_solver.cpp:138] Iteration 1210, lr = 0.001
I0622 11:14:53.112639 13672 solver.cpp:243] Iteration 1220, loss = 7.70045
I0622 11:14:53.112639 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.2724 (* 1 = 4.2724 loss)
I0622 11:14:53.112639 13672 sgd_solver.cpp:138] Iteration 1220, lr = 0.001
I0622 11:18:01.443863 13672 solver.cpp:243] Iteration 1230, loss = 8.24428
I0622 11:18:01.443863 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.48576 (* 1 = 4.48576 loss)
I0622 11:18:01.443863 13672 sgd_solver.cpp:138] Iteration 1230, lr = 0.001
I0622 11:21:10.556119 13672 solver.cpp:243] Iteration 1240, loss = 10.2257
I0622 11:21:10.556119 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.35041 (* 1 = 2.35041 loss)
I0622 11:21:10.556119 13672 sgd_solver.cpp:138] Iteration 1240, lr = 0.001
I0622 11:24:21.449152 13672 solver.cpp:243] Iteration 1250, loss = 7.8628
I0622 11:24:21.449152 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.82756 (* 1 = 4.82756 loss)
I0622 11:24:21.449152 13672 sgd_solver.cpp:138] Iteration 1250, lr = 0.001
I0622 11:27:43.620724 13672 solver.cpp:243] Iteration 1260, loss = 8.02044
I0622 11:27:43.620724 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.52121 (* 1 = 9.52121 loss)
I0622 11:27:43.620724 13672 sgd_solver.cpp:138] Iteration 1260, lr = 0.001
I0622 11:31:10.641126 13672 solver.cpp:243] Iteration 1270, loss = 9.45936
I0622 11:31:10.688014 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.44339 (* 1 = 4.44339 loss)
I0622 11:31:10.719264 13672 sgd_solver.cpp:138] Iteration 1270, lr = 0.001
I0622 11:34:13.660938 13672 solver.cpp:243] Iteration 1280, loss = 8.214
I0622 11:34:13.660938 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.09187 (* 1 = 2.09187 loss)
I0622 11:34:13.660938 13672 sgd_solver.cpp:138] Iteration 1280, lr = 0.001
I0622 11:37:36.418414 13672 solver.cpp:243] Iteration 1290, loss = 7.52678
I0622 11:37:36.418414 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.41527 (* 1 = 3.41527 loss)
I0622 11:37:36.418414 13672 sgd_solver.cpp:138] Iteration 1290, lr = 0.001
I0622 11:40:53.108491 13672 solver.cpp:243] Iteration 1300, loss = 7.26639
I0622 11:40:53.108491 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.1115 (* 1 = 10.1115 loss)
I0622 11:40:53.108491 13672 sgd_solver.cpp:138] Iteration 1300, lr = 0.001
I0622 11:42:50.253154 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0622 11:43:59.955649 13672 solver.cpp:243] Iteration 1310, loss = 7.11187
I0622 11:43:59.955649 13672 solver.cpp:259]     Train net output #0: mbox_loss = 16.5628 (* 1 = 16.5628 loss)
I0622 11:43:59.955649 13672 sgd_solver.cpp:138] Iteration 1310, lr = 0.001
I0622 11:47:10.333295 13672 solver.cpp:243] Iteration 1320, loss = 9.29525
I0622 11:47:10.333295 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.1175 (* 1 = 6.1175 loss)
I0622 11:47:10.333295 13672 sgd_solver.cpp:138] Iteration 1320, lr = 0.001
I0622 11:50:27.990293 13672 solver.cpp:243] Iteration 1330, loss = 9.31287
I0622 11:50:27.990293 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.55635 (* 1 = 5.55635 loss)
I0622 11:50:27.990293 13672 sgd_solver.cpp:138] Iteration 1330, lr = 0.001
I0622 11:53:36.993098 13672 solver.cpp:243] Iteration 1340, loss = 8.66862
I0622 11:53:36.993098 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.39973 (* 1 = 4.39973 loss)
I0622 11:53:36.993098 13672 sgd_solver.cpp:138] Iteration 1340, lr = 0.001
I0622 11:56:46.089633 13672 solver.cpp:243] Iteration 1350, loss = 8.17796
I0622 11:56:46.089633 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.09398 (* 1 = 4.09398 loss)
I0622 11:56:46.089633 13672 sgd_solver.cpp:138] Iteration 1350, lr = 0.001
I0622 11:59:55.842347 13672 solver.cpp:243] Iteration 1360, loss = 9.42568
I0622 11:59:55.842347 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.78337 (* 1 = 4.78337 loss)
I0622 11:59:55.842347 13672 sgd_solver.cpp:138] Iteration 1360, lr = 0.001
I0622 12:03:03.079955 13672 solver.cpp:243] Iteration 1370, loss = 11.1826
I0622 12:03:03.079955 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.92145 (* 1 = 3.92145 loss)
I0622 12:03:03.079955 13672 sgd_solver.cpp:138] Iteration 1370, lr = 0.001
I0622 12:06:18.129801 13672 solver.cpp:243] Iteration 1380, loss = 7.02818
I0622 12:06:18.129801 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.44167 (* 1 = 6.44167 loss)
I0622 12:06:18.129801 13672 sgd_solver.cpp:138] Iteration 1380, lr = 0.001
I0622 12:09:34.118942 13672 solver.cpp:243] Iteration 1390, loss = 6.9952
I0622 12:09:34.118942 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.92622 (* 1 = 8.92622 loss)
I0622 12:09:34.118942 13672 sgd_solver.cpp:138] Iteration 1390, lr = 0.001
I0622 12:12:50.323197 13672 solver.cpp:243] Iteration 1400, loss = 7.00931
I0622 12:12:50.354439 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.92391 (* 1 = 4.92391 loss)
I0622 12:12:50.354439 13672 sgd_solver.cpp:138] Iteration 1400, lr = 0.001
I0622 12:15:57.123353 13672 solver.cpp:243] Iteration 1410, loss = 6.62537
I0622 12:15:57.123353 13672 solver.cpp:259]     Train net output #0: mbox_loss = 15.4308 (* 1 = 15.4308 loss)
I0622 12:15:57.123353 13672 sgd_solver.cpp:138] Iteration 1410, lr = 0.001
I0622 12:19:31.526695 13672 solver.cpp:243] Iteration 1420, loss = 8.25103
I0622 12:19:31.542629 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.221 (* 1 = 10.221 loss)
I0622 12:19:31.558169 13672 sgd_solver.cpp:138] Iteration 1420, lr = 0.001
I0622 12:22:45.590765 13672 solver.cpp:243] Iteration 1430, loss = 8.03774
I0622 12:22:45.590765 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.9014 (* 1 = 17.9014 loss)
I0622 12:22:45.590765 13672 sgd_solver.cpp:138] Iteration 1430, lr = 0.001
I0622 12:25:58.436425 13672 solver.cpp:243] Iteration 1440, loss = 6.90693
I0622 12:25:58.436425 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.90224 (* 1 = 4.90224 loss)
I0622 12:25:58.436425 13672 sgd_solver.cpp:138] Iteration 1440, lr = 0.001
I0622 12:29:28.231297 13672 solver.cpp:243] Iteration 1450, loss = 7.17954
I0622 12:29:28.231297 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.90801 (* 1 = 8.90801 loss)
I0622 12:29:28.231297 13672 sgd_solver.cpp:138] Iteration 1450, lr = 0.001
I0622 12:32:41.233170 13672 solver.cpp:243] Iteration 1460, loss = 11.1781
I0622 12:32:41.233170 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.5375 (* 1 = 11.5375 loss)
I0622 12:32:41.233170 13672 sgd_solver.cpp:138] Iteration 1460, lr = 0.001
I0622 12:35:57.047230 13672 solver.cpp:243] Iteration 1470, loss = 12.518
I0622 12:35:57.062846 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.74672 (* 1 = 2.74672 loss)
I0622 12:35:57.062846 13672 sgd_solver.cpp:138] Iteration 1470, lr = 0.001
I0622 12:39:29.794529 13672 solver.cpp:243] Iteration 1480, loss = 9.78376
I0622 12:39:29.857057 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.78707 (* 1 = 3.78707 loss)
I0622 12:39:29.872670 13672 sgd_solver.cpp:138] Iteration 1480, lr = 0.001
I0622 12:42:49.779119 13672 solver.cpp:243] Iteration 1490, loss = 9.84481
I0622 12:42:49.779119 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.36794 (* 1 = 4.36794 loss)
I0622 12:42:49.779119 13672 sgd_solver.cpp:138] Iteration 1490, lr = 0.001
I0622 12:46:04.671190 13672 solver.cpp:243] Iteration 1500, loss = 9.77048
I0622 12:46:04.671190 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.06343 (* 1 = 2.06343 loss)
I0622 12:46:04.671190 13672 sgd_solver.cpp:138] Iteration 1500, lr = 0.001
I0622 12:49:22.375142 13672 solver.cpp:243] Iteration 1510, loss = 9.78298
I0622 12:49:22.375142 13672 solver.cpp:259]     Train net output #0: mbox_loss = 22.5261 (* 1 = 22.5261 loss)
I0622 12:49:22.375142 13672 sgd_solver.cpp:138] Iteration 1510, lr = 0.001
I0622 12:52:41.110141 13672 solver.cpp:243] Iteration 1520, loss = 10.5744
I0622 12:52:41.110141 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.47362 (* 1 = 4.47362 loss)
I0622 12:52:41.110141 13672 sgd_solver.cpp:138] Iteration 1520, lr = 0.001
I0622 12:55:58.356752 13672 solver.cpp:243] Iteration 1530, loss = 9.40166
I0622 12:55:58.356752 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.60651 (* 1 = 2.60651 loss)
I0622 12:55:58.356752 13672 sgd_solver.cpp:138] Iteration 1530, lr = 0.001
I0622 12:59:20.450297 13672 solver.cpp:243] Iteration 1540, loss = 10.7799
I0622 12:59:20.450297 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.61547 (* 1 = 6.61547 loss)
I0622 12:59:20.450297 13672 sgd_solver.cpp:138] Iteration 1540, lr = 0.001
I0622 13:02:39.341481 13672 solver.cpp:243] Iteration 1550, loss = 11.6706
I0622 13:02:39.341481 13672 solver.cpp:259]     Train net output #0: mbox_loss = 25.6725 (* 1 = 25.6725 loss)
I0622 13:02:39.341481 13672 sgd_solver.cpp:138] Iteration 1550, lr = 0.001
I0622 13:05:54.154913 13672 solver.cpp:243] Iteration 1560, loss = 8.58728
I0622 13:05:54.154913 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.41783 (* 1 = 5.41783 loss)
I0622 13:05:54.154913 13672 sgd_solver.cpp:138] Iteration 1560, lr = 0.001
I0622 13:09:10.567667 13672 solver.cpp:243] Iteration 1570, loss = 8.32111
I0622 13:09:10.567667 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.53541 (* 1 = 2.53541 loss)
I0622 13:09:10.567667 13672 sgd_solver.cpp:138] Iteration 1570, lr = 0.001
I0622 13:12:37.597548 13672 solver.cpp:243] Iteration 1580, loss = 7.36457
I0622 13:12:37.597548 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.85898 (* 1 = 4.85898 loss)
I0622 13:12:37.597548 13672 sgd_solver.cpp:138] Iteration 1580, lr = 0.001
I0622 13:15:45.913123 13672 solver.cpp:243] Iteration 1590, loss = 7.18401
I0622 13:15:45.913123 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.69853 (* 1 = 4.69853 loss)
I0622 13:15:45.913123 13672 sgd_solver.cpp:138] Iteration 1590, lr = 0.001
I0622 13:19:04.616801 13672 solver.cpp:243] Iteration 1600, loss = 8.315
I0622 13:19:04.616801 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.17852 (* 1 = 5.17852 loss)
I0622 13:19:04.616801 13672 sgd_solver.cpp:138] Iteration 1600, lr = 0.001
I0622 13:22:30.365667 13672 solver.cpp:243] Iteration 1610, loss = 9.81542
I0622 13:22:30.365667 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.07571 (* 1 = 4.07571 loss)
I0622 13:22:30.365667 13672 sgd_solver.cpp:138] Iteration 1610, lr = 0.001
I0622 13:25:38.696782 13672 solver.cpp:243] Iteration 1620, loss = 10.0694
I0622 13:25:38.696782 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.58025 (* 1 = 3.58025 loss)
I0622 13:25:38.696782 13672 sgd_solver.cpp:138] Iteration 1620, lr = 0.001
I0622 13:28:50.777006 13672 solver.cpp:243] Iteration 1630, loss = 7.96084
I0622 13:28:50.777006 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.08262 (* 1 = 9.08262 loss)
I0622 13:28:50.777006 13672 sgd_solver.cpp:138] Iteration 1630, lr = 0.001
I0622 13:32:16.525874 13672 solver.cpp:243] Iteration 1640, loss = 8.65248
I0622 13:32:16.525874 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.01455 (* 1 = 5.01455 loss)
I0622 13:32:16.525874 13672 sgd_solver.cpp:138] Iteration 1640, lr = 0.001
I0622 13:35:23.201097 13672 solver.cpp:243] Iteration 1650, loss = 7.6806
I0622 13:35:23.201097 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.96216 (* 1 = 4.96216 loss)
I0622 13:35:23.201097 13672 sgd_solver.cpp:138] Iteration 1650, lr = 0.001
I0622 13:38:43.045212 13672 solver.cpp:243] Iteration 1660, loss = 6.54662
I0622 13:38:43.045212 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.042 (* 1 = 17.042 loss)
I0622 13:38:43.045212 13672 sgd_solver.cpp:138] Iteration 1660, lr = 0.001
I0622 13:41:59.030860 13672 solver.cpp:243] Iteration 1670, loss = 7.86018
I0622 13:41:59.030860 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.799 (* 1 = 10.799 loss)
I0622 13:41:59.030860 13672 sgd_solver.cpp:138] Iteration 1670, lr = 0.001
I0622 13:45:13.079447 13672 solver.cpp:243] Iteration 1680, loss = 7.91109
I0622 13:45:13.079447 13672 solver.cpp:259]     Train net output #0: mbox_loss = 13.7189 (* 1 = 13.7189 loss)
I0622 13:45:13.079447 13672 sgd_solver.cpp:138] Iteration 1680, lr = 0.001
I0622 13:48:16.247341 13672 solver.cpp:243] Iteration 1690, loss = 6.58893
I0622 13:48:16.247341 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.60712 (* 1 = 4.60712 loss)
I0622 13:48:16.247341 13672 sgd_solver.cpp:138] Iteration 1690, lr = 0.001
I0622 13:51:47.229503 13672 solver.cpp:243] Iteration 1700, loss = 9.3169
I0622 13:51:47.229503 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.24304 (* 1 = 4.24304 loss)
I0622 13:51:47.229503 13672 sgd_solver.cpp:138] Iteration 1700, lr = 0.001
I0622 13:55:04.714706 13672 solver.cpp:243] Iteration 1710, loss = 7.51655
I0622 13:55:04.714706 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.38209 (* 1 = 3.38209 loss)
I0622 13:55:04.714706 13672 sgd_solver.cpp:138] Iteration 1710, lr = 0.001
I0622 13:58:21.418874 13672 solver.cpp:243] Iteration 1720, loss = 6.88576
I0622 13:58:21.418874 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.83936 (* 1 = 6.83936 loss)
I0622 13:58:21.418874 13672 sgd_solver.cpp:138] Iteration 1720, lr = 0.001
I0622 14:01:28.312767 13672 solver.cpp:243] Iteration 1730, loss = 7.69976
I0622 14:01:28.312767 13672 solver.cpp:259]     Train net output #0: mbox_loss = 20.986 (* 1 = 20.986 loss)
I0622 14:01:28.312767 13672 sgd_solver.cpp:138] Iteration 1730, lr = 0.001
I0622 14:04:43.673467 13672 solver.cpp:243] Iteration 1740, loss = 8.67563
I0622 14:04:43.673467 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.44842 (* 1 = 2.44842 loss)
I0622 14:04:43.673467 13672 sgd_solver.cpp:138] Iteration 1740, lr = 0.001
I0622 14:07:56.706624 13672 solver.cpp:243] Iteration 1750, loss = 7.75371
I0622 14:07:56.706624 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.95811 (* 1 = 1.95811 loss)
I0622 14:07:56.706624 13672 sgd_solver.cpp:138] Iteration 1750, lr = 0.001
I0622 14:11:10.927057 13672 solver.cpp:243] Iteration 1760, loss = 6.10559
I0622 14:11:10.927057 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.69228 (* 1 = 5.69228 loss)
I0622 14:11:10.927057 13672 sgd_solver.cpp:138] Iteration 1760, lr = 0.001
I0622 14:14:28.006110 13672 solver.cpp:243] Iteration 1770, loss = 6.47546
I0622 14:14:28.006110 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.41893 (* 1 = 3.41893 loss)
I0622 14:14:28.006110 13672 sgd_solver.cpp:138] Iteration 1770, lr = 0.001
I0622 14:17:30.385630 13672 solver.cpp:243] Iteration 1780, loss = 6.46697
I0622 14:17:30.385630 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.62564 (* 1 = 1.62564 loss)
I0622 14:17:30.385630 13672 sgd_solver.cpp:138] Iteration 1780, lr = 0.001
I0622 14:20:41.794111 13672 solver.cpp:243] Iteration 1790, loss = 8.78022
I0622 14:20:41.794111 13672 solver.cpp:259]     Train net output #0: mbox_loss = 25.6295 (* 1 = 25.6295 loss)
I0622 14:20:41.794111 13672 sgd_solver.cpp:138] Iteration 1790, lr = 0.001
I0622 14:23:55.233346 13672 solver.cpp:243] Iteration 1800, loss = 8.32231
I0622 14:23:55.233346 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.31034 (* 1 = 5.31034 loss)
I0622 14:23:55.233346 13672 sgd_solver.cpp:138] Iteration 1800, lr = 0.001
I0622 14:27:15.374544 13672 solver.cpp:243] Iteration 1810, loss = 7.60114
I0622 14:27:15.374544 13672 solver.cpp:259]     Train net output #0: mbox_loss = 19.2194 (* 1 = 19.2194 loss)
I0622 14:27:15.374544 13672 sgd_solver.cpp:138] Iteration 1810, lr = 0.001
I0622 14:30:34.343777 13672 solver.cpp:243] Iteration 1820, loss = 6.66034
I0622 14:30:34.343777 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.26332 (* 1 = 7.26332 loss)
I0622 14:30:34.343777 13672 sgd_solver.cpp:138] Iteration 1820, lr = 0.001
I0622 14:33:50.001284 13672 solver.cpp:243] Iteration 1830, loss = 5.94812
I0622 14:33:50.001284 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.89687 (* 1 = 4.89687 loss)
I0622 14:33:50.001284 13672 sgd_solver.cpp:138] Iteration 1830, lr = 0.001
I0622 14:37:07.205440 13672 solver.cpp:243] Iteration 1840, loss = 7.12
I0622 14:37:07.205440 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.34047 (* 1 = 5.34047 loss)
I0622 14:37:07.205440 13672 sgd_solver.cpp:138] Iteration 1840, lr = 0.001
I0622 14:40:09.912842 13672 solver.cpp:243] Iteration 1850, loss = 8.04979
I0622 14:40:09.912842 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.47144 (* 1 = 5.47144 loss)
I0622 14:40:09.912842 13672 sgd_solver.cpp:138] Iteration 1850, lr = 0.001
I0622 14:43:25.557224 13672 solver.cpp:243] Iteration 1860, loss = 7.31869
I0622 14:43:25.557224 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.0629 (* 1 = 4.0629 loss)
I0622 14:43:25.557224 13672 sgd_solver.cpp:138] Iteration 1860, lr = 0.001
I0622 14:46:50.634462 13672 solver.cpp:243] Iteration 1870, loss = 6.80291
I0622 14:46:50.634462 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.75445 (* 1 = 2.75445 loss)
I0622 14:46:50.634462 13672 sgd_solver.cpp:138] Iteration 1870, lr = 0.001
I0622 14:50:06.245102 13672 solver.cpp:243] Iteration 1880, loss = 6.17203
I0622 14:50:06.245102 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.67011 (* 1 = 5.67011 loss)
I0622 14:50:06.245102 13672 sgd_solver.cpp:138] Iteration 1880, lr = 0.001
I0622 14:53:15.093200 13672 solver.cpp:243] Iteration 1890, loss = 5.25189
I0622 14:53:15.093200 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.33766 (* 1 = 6.33766 loss)
I0622 14:53:15.093200 13672 sgd_solver.cpp:138] Iteration 1890, lr = 0.001
I0622 14:56:29.001211 13672 solver.cpp:243] Iteration 1900, loss = 6.24008
I0622 14:56:29.001211 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.79662 (* 1 = 4.79662 loss)
I0622 14:56:29.001211 13672 sgd_solver.cpp:138] Iteration 1900, lr = 0.001
I0622 14:59:41.697361 13672 solver.cpp:243] Iteration 1910, loss = 7.7354
I0622 14:59:41.697361 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.10081 (* 1 = 5.10081 loss)
I0622 14:59:41.697361 13672 sgd_solver.cpp:138] Iteration 1910, lr = 0.001
I0622 15:03:03.853312 13672 solver.cpp:243] Iteration 1920, loss = 6.79565
I0622 15:03:03.853312 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.00824 (* 1 = 4.00824 loss)
I0622 15:03:03.853312 13672 sgd_solver.cpp:138] Iteration 1920, lr = 0.001
I0622 15:06:24.436169 13672 solver.cpp:243] Iteration 1930, loss = 6.61456
I0622 15:06:24.436169 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.99735 (* 1 = 6.99735 loss)
I0622 15:06:24.436169 13672 sgd_solver.cpp:138] Iteration 1930, lr = 0.001
I0622 15:09:37.877965 13672 solver.cpp:243] Iteration 1940, loss = 6.64936
I0622 15:09:37.877965 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.15082 (* 1 = 4.15082 loss)
I0622 15:09:37.877965 13672 sgd_solver.cpp:138] Iteration 1940, lr = 0.001
I0622 15:12:56.923745 13672 solver.cpp:243] Iteration 1950, loss = 7.74771
I0622 15:12:56.923745 13672 solver.cpp:259]     Train net output #0: mbox_loss = 21.1118 (* 1 = 21.1118 loss)
I0622 15:12:56.923745 13672 sgd_solver.cpp:138] Iteration 1950, lr = 0.001
I0622 15:16:01.115175 13672 solver.cpp:243] Iteration 1960, loss = 7.57142
I0622 15:16:01.115175 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.88901 (* 1 = 5.88901 loss)
I0622 15:16:01.115175 13672 sgd_solver.cpp:138] Iteration 1960, lr = 0.001
I0622 15:19:21.318497 13672 solver.cpp:243] Iteration 1970, loss = 6.42535
I0622 15:19:21.318497 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.36482 (* 1 = 3.36482 loss)
I0622 15:19:21.318497 13672 sgd_solver.cpp:138] Iteration 1970, lr = 0.001
I0622 15:22:44.521121 13672 solver.cpp:243] Iteration 1980, loss = 7.81736
I0622 15:22:44.521121 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.93293 (* 1 = 8.93293 loss)
I0622 15:22:44.521121 13672 sgd_solver.cpp:138] Iteration 1980, lr = 0.001
I0622 15:26:00.725332 13672 solver.cpp:243] Iteration 1990, loss = 7.4499
I0622 15:26:00.725332 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.67407 (* 1 = 4.67407 loss)
I0622 15:26:00.725332 13672 sgd_solver.cpp:138] Iteration 1990, lr = 0.001
I0622 15:29:16.960867 13672 solver.cpp:243] Iteration 2000, loss = 6.11359
I0622 15:29:16.960867 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.32959 (* 1 = 3.32959 loss)
I0622 15:29:16.960867 13672 sgd_solver.cpp:138] Iteration 2000, lr = 0.001
I0622 15:32:28.869206 13672 solver.cpp:243] Iteration 2010, loss = 6.17222
I0622 15:32:28.869206 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.95448 (* 1 = 9.95448 loss)
I0622 15:32:28.869206 13672 sgd_solver.cpp:138] Iteration 2010, lr = 0.001
I0622 15:35:39.278033 13672 solver.cpp:243] Iteration 2020, loss = 6.72385
I0622 15:35:39.278033 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.69174 (* 1 = 2.69174 loss)
I0622 15:35:39.278033 13672 sgd_solver.cpp:138] Iteration 2020, lr = 0.001
I0622 15:38:47.390509 13672 solver.cpp:243] Iteration 2030, loss = 5.83659
I0622 15:38:47.390509 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.26949 (* 1 = 2.26949 loss)
I0622 15:38:47.390509 13672 sgd_solver.cpp:138] Iteration 2030, lr = 0.001
I0622 15:40:49.658849 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0622 15:42:14.467236 13672 solver.cpp:243] Iteration 2040, loss = 7.05433
I0622 15:42:14.467236 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.73634 (* 1 = 4.73634 loss)
I0622 15:42:14.467236 13672 sgd_solver.cpp:138] Iteration 2040, lr = 0.001
I0622 15:45:23.360657 13672 solver.cpp:243] Iteration 2050, loss = 7.03765
I0622 15:45:23.360657 13672 solver.cpp:259]     Train net output #0: mbox_loss = 14.2139 (* 1 = 14.2139 loss)
I0622 15:45:23.360657 13672 sgd_solver.cpp:138] Iteration 2050, lr = 0.001
I0622 15:48:32.613441 13672 solver.cpp:243] Iteration 2060, loss = 7.55207
I0622 15:48:32.613441 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.35986 (* 1 = 9.35986 loss)
I0622 15:48:32.613441 13672 sgd_solver.cpp:138] Iteration 2060, lr = 0.001
I0622 15:51:46.661914 13672 solver.cpp:243] Iteration 2070, loss = 7.58575
I0622 15:51:46.661914 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.70847 (* 1 = 4.70847 loss)
I0622 15:51:46.661914 13672 sgd_solver.cpp:138] Iteration 2070, lr = 0.001
I0622 15:55:08.882979 13672 solver.cpp:243] Iteration 2080, loss = 6.30299
I0622 15:55:08.882979 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.64053 (* 1 = 4.64053 loss)
I0622 15:55:08.882979 13672 sgd_solver.cpp:138] Iteration 2080, lr = 0.001
I0622 15:58:26.477568 13672 solver.cpp:243] Iteration 2090, loss = 7.74806
I0622 15:58:26.477568 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.4122 (* 1 = 17.4122 loss)
I0622 15:58:26.477568 13672 sgd_solver.cpp:138] Iteration 2090, lr = 0.001
I0622 16:01:43.619108 13672 solver.cpp:243] Iteration 2100, loss = 8.46759
I0622 16:01:43.619108 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.3498 (* 1 = 4.3498 loss)
I0622 16:01:43.619108 13672 sgd_solver.cpp:138] Iteration 2100, lr = 0.001
I0622 16:04:56.730290 13672 solver.cpp:243] Iteration 2110, loss = 9.06541
I0622 16:04:56.730290 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.47943 (* 1 = 3.47943 loss)
I0622 16:04:56.730290 13672 sgd_solver.cpp:138] Iteration 2110, lr = 0.001
I0622 16:08:14.106251 13672 solver.cpp:243] Iteration 2120, loss = 8.68733
I0622 16:08:14.106251 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.07657 (* 1 = 4.07657 loss)
I0622 16:08:14.106251 13672 sgd_solver.cpp:138] Iteration 2120, lr = 0.001
I0622 16:11:23.952560 13672 solver.cpp:243] Iteration 2130, loss = 8.17247
I0622 16:11:23.952560 13672 solver.cpp:259]     Train net output #0: mbox_loss = 30.001 (* 1 = 30.001 loss)
I0622 16:11:23.952560 13672 sgd_solver.cpp:138] Iteration 2130, lr = 0.001
I0622 16:14:42.015825 13672 solver.cpp:243] Iteration 2140, loss = 6.7382
I0622 16:14:42.062721 13672 solver.cpp:259]     Train net output #0: mbox_loss = 13.4661 (* 1 = 13.4661 loss)
I0622 16:14:42.078244 13672 sgd_solver.cpp:138] Iteration 2140, lr = 0.001
I0622 16:17:56.486039 13672 solver.cpp:243] Iteration 2150, loss = 5.73796
I0622 16:17:56.486039 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.72529 (* 1 = 5.72529 loss)
I0622 16:17:56.486039 13672 sgd_solver.cpp:138] Iteration 2150, lr = 0.001
I0622 16:21:03.067536 13672 solver.cpp:243] Iteration 2160, loss = 6.21249
I0622 16:21:03.067536 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.54788 (* 1 = 8.54788 loss)
I0622 16:21:03.067536 13672 sgd_solver.cpp:138] Iteration 2160, lr = 0.001
I0622 16:24:24.489778 13672 solver.cpp:243] Iteration 2170, loss = 6.67768
I0622 16:24:24.520918 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.3021 (* 1 = 11.3021 loss)
I0622 16:24:24.536844 13672 sgd_solver.cpp:138] Iteration 2170, lr = 0.001
I0622 16:27:38.436946 13672 solver.cpp:243] Iteration 2180, loss = 8.74794
I0622 16:27:38.436946 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.85083 (* 1 = 4.85083 loss)
I0622 16:27:38.436946 13672 sgd_solver.cpp:138] Iteration 2180, lr = 0.001
I0622 16:30:44.893513 13672 solver.cpp:243] Iteration 2190, loss = 10.1573
I0622 16:30:44.893513 13672 solver.cpp:259]     Train net output #0: mbox_loss = 26.144 (* 1 = 26.144 loss)
I0622 16:30:44.893513 13672 sgd_solver.cpp:138] Iteration 2190, lr = 0.001
I0622 16:34:18.468783 13672 solver.cpp:243] Iteration 2200, loss = 9.10928
I0622 16:34:18.468783 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.87774 (* 1 = 8.87774 loss)
I0622 16:34:18.468783 13672 sgd_solver.cpp:138] Iteration 2200, lr = 0.001
I0622 16:37:34.860488 13672 solver.cpp:243] Iteration 2210, loss = 6.9984
I0622 16:37:34.860488 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.22645 (* 1 = 9.22645 loss)
I0622 16:37:34.860488 13672 sgd_solver.cpp:138] Iteration 2210, lr = 0.001
I0622 16:41:00.843716 13672 solver.cpp:243] Iteration 2220, loss = 7.12142
I0622 16:41:00.843716 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.14919 (* 1 = 3.14919 loss)
I0622 16:41:00.843716 13672 sgd_solver.cpp:138] Iteration 2220, lr = 0.001
I0622 16:44:17.516665 13672 solver.cpp:243] Iteration 2230, loss = 8.12475
I0622 16:44:17.516665 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.5509 (* 1 = 2.5509 loss)
I0622 16:44:17.516665 13672 sgd_solver.cpp:138] Iteration 2230, lr = 0.001
I0622 16:47:37.266968 13672 solver.cpp:243] Iteration 2240, loss = 8.58934
I0622 16:47:37.266968 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.22362 (* 1 = 3.22362 loss)
I0622 16:47:37.266968 13672 sgd_solver.cpp:138] Iteration 2240, lr = 0.001
I0622 16:50:57.595297 13672 solver.cpp:243] Iteration 2250, loss = 7.46787
I0622 16:50:57.595297 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.38297 (* 1 = 2.38297 loss)
I0622 16:50:57.595297 13672 sgd_solver.cpp:138] Iteration 2250, lr = 0.001
I0622 16:54:13.426434 13672 solver.cpp:243] Iteration 2260, loss = 7.0096
I0622 16:54:13.426434 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.39877 (* 1 = 8.39877 loss)
I0622 16:54:13.426434 13672 sgd_solver.cpp:138] Iteration 2260, lr = 0.001
I0622 16:57:36.894618 13672 solver.cpp:243] Iteration 2270, loss = 7.19463
I0622 16:57:36.894618 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.87741 (* 1 = 2.87741 loss)
I0622 16:57:36.894618 13672 sgd_solver.cpp:138] Iteration 2270, lr = 0.001
I0622 17:00:52.108119 13672 solver.cpp:243] Iteration 2280, loss = 6.52825
I0622 17:00:52.108119 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.24709 (* 1 = 2.24709 loss)
I0622 17:00:52.108119 13672 sgd_solver.cpp:138] Iteration 2280, lr = 0.001
I0622 17:04:08.437422 13672 solver.cpp:243] Iteration 2290, loss = 8.41271
I0622 17:04:08.437422 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.36782 (* 1 = 5.36782 loss)
I0622 17:04:08.437422 13672 sgd_solver.cpp:138] Iteration 2290, lr = 0.001
I0622 17:07:23.735639 13672 solver.cpp:243] Iteration 2300, loss = 7.60757
I0622 17:07:23.735639 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.9495 (* 1 = 10.9495 loss)
I0622 17:07:23.735639 13672 sgd_solver.cpp:138] Iteration 2300, lr = 0.001
I0622 17:10:42.986053 13672 solver.cpp:243] Iteration 2310, loss = 5.80843
I0622 17:10:42.986053 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.4791 (* 1 = 4.4791 loss)
I0622 17:10:42.986053 13672 sgd_solver.cpp:138] Iteration 2310, lr = 0.001
I0622 17:13:59.908895 13672 solver.cpp:243] Iteration 2320, loss = 6.84927
I0622 17:13:59.908895 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.47527 (* 1 = 2.47527 loss)
I0622 17:13:59.908895 13672 sgd_solver.cpp:138] Iteration 2320, lr = 0.001
I0622 17:17:17.144156 13672 solver.cpp:243] Iteration 2330, loss = 5.64105
I0622 17:17:17.144156 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.2348 (* 1 = 10.2348 loss)
I0622 17:17:17.144156 13672 sgd_solver.cpp:138] Iteration 2330, lr = 0.001
I0622 17:20:39.253278 13672 solver.cpp:243] Iteration 2340, loss = 6.90937
I0622 17:20:39.253278 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.64385 (* 1 = 6.64385 loss)
I0622 17:20:39.253278 13672 sgd_solver.cpp:138] Iteration 2340, lr = 0.001
I0622 17:24:09.595057 13672 solver.cpp:243] Iteration 2350, loss = 6.10592
I0622 17:24:09.673382 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.32361 (* 1 = 6.32361 loss)
I0622 17:24:09.688750 13672 sgd_solver.cpp:138] Iteration 2350, lr = 0.001
I0622 17:27:23.455912 13672 solver.cpp:243] Iteration 2360, loss = 7.49702
I0622 17:27:23.455912 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.70027 (* 1 = 3.70027 loss)
I0622 17:27:23.455912 13672 sgd_solver.cpp:138] Iteration 2360, lr = 0.001
I0622 17:30:40.363143 13672 solver.cpp:243] Iteration 2370, loss = 7.19293
I0622 17:30:40.363143 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.02734 (* 1 = 4.02734 loss)
I0622 17:30:40.363143 13672 sgd_solver.cpp:138] Iteration 2370, lr = 0.001
I0622 17:33:49.069087 13672 solver.cpp:243] Iteration 2380, loss = 5.62932
I0622 17:33:49.069087 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.35171 (* 1 = 7.35171 loss)
I0622 17:33:49.069087 13672 sgd_solver.cpp:138] Iteration 2380, lr = 0.001
I0622 17:37:05.726395 13672 solver.cpp:243] Iteration 2390, loss = 6.04501
I0622 17:37:05.726395 13672 solver.cpp:259]     Train net output #0: mbox_loss = 19.0954 (* 1 = 19.0954 loss)
I0622 17:37:05.726395 13672 sgd_solver.cpp:138] Iteration 2390, lr = 0.001
I0622 17:40:10.995702 13672 solver.cpp:243] Iteration 2400, loss = 5.92759
I0622 17:40:10.995702 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.85042 (* 1 = 3.85042 loss)
I0622 17:40:10.995702 13672 sgd_solver.cpp:138] Iteration 2400, lr = 0.001
I0622 17:43:30.667901 13672 solver.cpp:243] Iteration 2410, loss = 6.71881
I0622 17:43:30.667901 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.57281 (* 1 = 3.57281 loss)
I0622 17:43:30.667901 13672 sgd_solver.cpp:138] Iteration 2410, lr = 0.001
I0622 17:46:44.997543 13672 solver.cpp:243] Iteration 2420, loss = 5.25652
I0622 17:46:44.997543 13672 solver.cpp:259]     Train net output #0: mbox_loss = 18.9274 (* 1 = 18.9274 loss)
I0622 17:46:44.997543 13672 sgd_solver.cpp:138] Iteration 2420, lr = 0.001
I0622 17:50:08.856302 13672 solver.cpp:243] Iteration 2430, loss = 6.07338
I0622 17:50:08.856302 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.64476 (* 1 = 9.64476 loss)
I0622 17:50:08.856302 13672 sgd_solver.cpp:138] Iteration 2430, lr = 0.001
I0622 17:53:14.369637 13672 solver.cpp:243] Iteration 2440, loss = 6.21746
I0622 17:53:14.369637 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.69192 (* 1 = 3.69192 loss)
I0622 17:53:14.369637 13672 sgd_solver.cpp:138] Iteration 2440, lr = 0.001
I0622 17:56:52.303246 13672 solver.cpp:243] Iteration 2450, loss = 6.51025
I0622 17:56:52.303246 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.54209 (* 1 = 4.54209 loss)
I0622 17:56:52.303246 13672 sgd_solver.cpp:138] Iteration 2450, lr = 0.001
I0622 18:00:08.241935 13672 solver.cpp:243] Iteration 2460, loss = 6.27687
I0622 18:00:08.664149 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.64057 (* 1 = 3.64057 loss)
I0622 18:00:08.664149 13672 sgd_solver.cpp:138] Iteration 2460, lr = 0.001
I0622 18:03:33.147235 13672 solver.cpp:243] Iteration 2470, loss = 6.92707
I0622 18:03:33.225342 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.12702 (* 1 = 3.12702 loss)
I0622 18:03:33.225342 13672 sgd_solver.cpp:138] Iteration 2470, lr = 0.001
I0622 18:07:04.144960 13672 solver.cpp:243] Iteration 2480, loss = 10.9081
I0622 18:07:04.160570 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.08671 (* 1 = 1.08671 loss)
I0622 18:07:04.160570 13672 sgd_solver.cpp:138] Iteration 2480, lr = 0.001
I0622 18:10:23.754662 13672 solver.cpp:243] Iteration 2490, loss = 9.42636
I0622 18:10:23.754662 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.5905 (* 1 = 12.5905 loss)
I0622 18:10:23.754662 13672 sgd_solver.cpp:138] Iteration 2490, lr = 0.001
I0622 18:13:36.873486 13672 solver.cpp:243] Iteration 2500, loss = 7.5674
I0622 18:13:36.873486 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.21066 (* 1 = 3.21066 loss)
I0622 18:13:36.873486 13672 sgd_solver.cpp:138] Iteration 2500, lr = 0.001
I0622 18:16:53.593205 13672 solver.cpp:243] Iteration 2510, loss = 6.29097
I0622 18:16:53.593205 13672 solver.cpp:259]     Train net output #0: mbox_loss = 13.4966 (* 1 = 13.4966 loss)
I0622 18:16:53.593205 13672 sgd_solver.cpp:138] Iteration 2510, lr = 0.001
I0622 18:20:05.048595 13672 solver.cpp:243] Iteration 2520, loss = 6.37603
I0622 18:20:05.048595 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.48344 (* 1 = 2.48344 loss)
I0622 18:20:05.048595 13672 sgd_solver.cpp:138] Iteration 2520, lr = 0.001
I0622 18:23:18.222316 13672 solver.cpp:243] Iteration 2530, loss = 6.6493
I0622 18:23:18.222316 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.70557 (* 1 = 2.70557 loss)
I0622 18:23:18.222316 13672 sgd_solver.cpp:138] Iteration 2530, lr = 0.001
I0622 18:26:44.472385 13672 solver.cpp:243] Iteration 2540, loss = 6.71692
I0622 18:26:44.519225 13672 solver.cpp:259]     Train net output #0: mbox_loss = 15.1365 (* 1 = 15.1365 loss)
I0622 18:26:44.519225 13672 sgd_solver.cpp:138] Iteration 2540, lr = 0.001
I0622 18:30:02.472621 13672 solver.cpp:243] Iteration 2550, loss = 6.84035
I0622 18:30:02.472621 13672 solver.cpp:259]     Train net output #0: mbox_loss = 21.4691 (* 1 = 21.4691 loss)
I0622 18:30:02.472621 13672 sgd_solver.cpp:138] Iteration 2550, lr = 0.001
I0622 18:33:17.302273 13672 solver.cpp:243] Iteration 2560, loss = 6.15512
I0622 18:33:17.302273 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.91846 (* 1 = 4.91846 loss)
I0622 18:33:17.302273 13672 sgd_solver.cpp:138] Iteration 2560, lr = 0.001
I0622 18:36:35.271734 13672 solver.cpp:243] Iteration 2570, loss = 6.76627
I0622 18:36:35.271734 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.06063 (* 1 = 3.06063 loss)
I0622 18:36:35.271734 13672 sgd_solver.cpp:138] Iteration 2570, lr = 0.001
I0622 18:39:59.864722 13672 solver.cpp:243] Iteration 2580, loss = 8.17957
I0622 18:39:59.864722 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.98854 (* 1 = 3.98854 loss)
I0622 18:39:59.864722 13672 sgd_solver.cpp:138] Iteration 2580, lr = 0.001
I0622 18:43:22.192669 13672 solver.cpp:243] Iteration 2590, loss = 7.09367
I0622 18:43:22.192669 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.84472 (* 1 = 4.84472 loss)
I0622 18:43:22.192669 13672 sgd_solver.cpp:138] Iteration 2590, lr = 0.001
I0622 18:46:38.459369 13672 solver.cpp:243] Iteration 2600, loss = 7.16124
I0622 18:46:38.459369 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.95492 (* 1 = 5.95492 loss)
I0622 18:46:38.459369 13672 sgd_solver.cpp:138] Iteration 2600, lr = 0.001
I0622 18:49:58.366432 13672 solver.cpp:243] Iteration 2610, loss = 7.04173
I0622 18:49:58.413295 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.28448 (* 1 = 4.28448 loss)
I0622 18:49:58.413295 13672 sgd_solver.cpp:138] Iteration 2610, lr = 0.001
I0622 18:53:07.353685 13672 solver.cpp:243] Iteration 2620, loss = 7.72036
I0622 18:53:07.353685 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.84683 (* 1 = 2.84683 loss)
I0622 18:53:07.353685 13672 sgd_solver.cpp:138] Iteration 2620, lr = 0.001
I0622 18:56:15.075651 13672 solver.cpp:243] Iteration 2630, loss = 5.92286
I0622 18:56:15.075651 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.3848 (* 1 = 11.3848 loss)
I0622 18:56:15.075651 13672 sgd_solver.cpp:138] Iteration 2630, lr = 0.001
I0622 18:59:44.698652 13672 solver.cpp:243] Iteration 2640, loss = 4.94806
I0622 18:59:44.698652 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.81529 (* 1 = 6.81529 loss)
I0622 18:59:44.698652 13672 sgd_solver.cpp:138] Iteration 2640, lr = 0.001
I0622 19:03:11.619858 13672 solver.cpp:243] Iteration 2650, loss = 5.0542
I0622 19:03:11.635479 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.38751 (* 1 = 4.38751 loss)
I0622 19:03:11.635479 13672 sgd_solver.cpp:138] Iteration 2650, lr = 0.001
I0622 19:06:34.447566 13672 solver.cpp:243] Iteration 2660, loss = 5.78386
I0622 19:06:34.447566 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.25871 (* 1 = 9.25871 loss)
I0622 19:06:34.447566 13672 sgd_solver.cpp:138] Iteration 2660, lr = 0.001
I0622 19:10:05.227237 13672 solver.cpp:243] Iteration 2670, loss = 5.46611
I0622 19:10:05.258497 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.09845 (* 1 = 8.09845 loss)
I0622 19:10:05.274230 13672 sgd_solver.cpp:138] Iteration 2670, lr = 0.001
I0622 19:13:21.400244 13672 solver.cpp:243] Iteration 2680, loss = 5.62419
I0622 19:13:21.400244 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.06318 (* 1 = 7.06318 loss)
I0622 19:13:21.400244 13672 sgd_solver.cpp:138] Iteration 2680, lr = 0.001
I0622 19:16:35.308156 13672 solver.cpp:243] Iteration 2690, loss = 6.01377
I0622 19:16:35.308156 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.94911 (* 1 = 3.94911 loss)
I0622 19:16:35.308156 13672 sgd_solver.cpp:138] Iteration 2690, lr = 0.001
I0622 19:20:05.884058 13672 solver.cpp:243] Iteration 2700, loss = 5.27153
I0622 19:20:05.884058 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.98885 (* 1 = 4.98885 loss)
I0622 19:20:05.884058 13672 sgd_solver.cpp:138] Iteration 2700, lr = 0.001
I0622 19:23:18.839088 13672 solver.cpp:243] Iteration 2710, loss = 5.97796
I0622 19:23:18.839088 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.85531 (* 1 = 8.85531 loss)
I0622 19:23:18.839088 13672 sgd_solver.cpp:138] Iteration 2710, lr = 0.001
I0622 19:23:41.458789 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0622 19:26:35.761902 13672 solver.cpp:243] Iteration 2720, loss = 5.99681
I0622 19:26:35.761902 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.92086 (* 1 = 4.92086 loss)
I0622 19:26:35.761902 13672 sgd_solver.cpp:138] Iteration 2720, lr = 0.001
I0622 19:29:49.044963 13672 solver.cpp:243] Iteration 2730, loss = 8.77227
I0622 19:29:49.044963 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.32853 (* 1 = 2.32853 loss)
I0622 19:29:49.044963 13672 sgd_solver.cpp:138] Iteration 2730, lr = 0.001
I0622 19:33:05.202312 13672 solver.cpp:243] Iteration 2740, loss = 9.50644
I0622 19:33:05.202312 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.72097 (* 1 = 2.72097 loss)
I0622 19:33:05.202312 13672 sgd_solver.cpp:138] Iteration 2740, lr = 0.001
I0622 19:36:13.861487 13672 solver.cpp:243] Iteration 2750, loss = 7.99248
I0622 19:36:13.861487 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.43568 (* 1 = 3.43568 loss)
I0622 19:36:13.861487 13672 sgd_solver.cpp:138] Iteration 2750, lr = 0.001
I0622 19:39:29.768895 13672 solver.cpp:243] Iteration 2760, loss = 6.5452
I0622 19:39:29.768895 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.5086 (* 1 = 12.5086 loss)
I0622 19:39:29.768895 13672 sgd_solver.cpp:138] Iteration 2760, lr = 0.001
I0622 19:42:49.238051 13672 solver.cpp:243] Iteration 2770, loss = 6.17224
I0622 19:42:49.238051 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.86421 (* 1 = 3.86421 loss)
I0622 19:42:49.238051 13672 sgd_solver.cpp:138] Iteration 2770, lr = 0.001
I0622 19:46:02.239887 13672 solver.cpp:243] Iteration 2780, loss = 5.43855
I0622 19:46:02.239887 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.63047 (* 1 = 2.63047 loss)
I0622 19:46:02.239887 13672 sgd_solver.cpp:138] Iteration 2780, lr = 0.001
I0622 19:49:16.007244 13672 solver.cpp:243] Iteration 2790, loss = 6.11236
I0622 19:49:16.007244 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.8648 (* 1 = 11.8648 loss)
I0622 19:49:16.007244 13672 sgd_solver.cpp:138] Iteration 2790, lr = 0.001
I0622 19:52:28.493579 13672 solver.cpp:243] Iteration 2800, loss = 6.15322
I0622 19:52:28.493579 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.6904 (* 1 = 12.6904 loss)
I0622 19:52:28.493579 13672 sgd_solver.cpp:138] Iteration 2800, lr = 0.001
I0622 19:55:36.996537 13672 solver.cpp:243] Iteration 2810, loss = 6.33774
I0622 19:55:36.996537 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.92018 (* 1 = 2.92018 loss)
I0622 19:55:36.996537 13672 sgd_solver.cpp:138] Iteration 2810, lr = 0.001
I0622 19:59:10.259316 13672 solver.cpp:243] Iteration 2820, loss = 7.79367
I0622 19:59:10.259316 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.6476 (* 1 = 4.6476 loss)
I0622 19:59:10.259316 13672 sgd_solver.cpp:138] Iteration 2820, lr = 0.001
I0622 20:02:29.572280 13672 solver.cpp:243] Iteration 2830, loss = 6.78613
I0622 20:02:29.572280 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.29516 (* 1 = 4.29516 loss)
I0622 20:02:29.572280 13672 sgd_solver.cpp:138] Iteration 2830, lr = 0.001
I0622 20:05:50.306726 13672 solver.cpp:243] Iteration 2840, loss = 5.72605
I0622 20:05:50.306726 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.26515 (* 1 = 8.26515 loss)
I0622 20:05:50.306726 13672 sgd_solver.cpp:138] Iteration 2840, lr = 0.001
I0622 20:09:08.573133 13672 solver.cpp:243] Iteration 2850, loss = 5.86292
I0622 20:09:08.573133 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.60213 (* 1 = 4.60213 loss)
I0622 20:09:08.573133 13672 sgd_solver.cpp:138] Iteration 2850, lr = 0.001
I0622 20:12:25.480340 13672 solver.cpp:243] Iteration 2860, loss = 5.28759
I0622 20:12:25.480340 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.65209 (* 1 = 3.65209 loss)
I0622 20:12:25.480340 13672 sgd_solver.cpp:138] Iteration 2860, lr = 0.001
I0622 20:15:39.497601 13672 solver.cpp:243] Iteration 2870, loss = 5.74007
I0622 20:15:39.497601 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.81923 (* 1 = 4.81923 loss)
I0622 20:15:39.497601 13672 sgd_solver.cpp:138] Iteration 2870, lr = 0.001
I0622 20:18:55.170737 13672 solver.cpp:243] Iteration 2880, loss = 5.34989
I0622 20:18:55.170737 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.07691 (* 1 = 7.07691 loss)
I0622 20:18:55.170737 13672 sgd_solver.cpp:138] Iteration 2880, lr = 0.001
I0622 20:22:09.625393 13672 solver.cpp:243] Iteration 2890, loss = 6.08257
I0622 20:22:09.625393 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.22251 (* 1 = 9.22251 loss)
I0622 20:22:09.625393 13672 sgd_solver.cpp:138] Iteration 2890, lr = 0.001
I0622 20:25:13.160723 13672 solver.cpp:243] Iteration 2900, loss = 6.0031
I0622 20:25:13.160723 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.30874 (* 1 = 4.30874 loss)
I0622 20:25:13.160723 13672 sgd_solver.cpp:138] Iteration 2900, lr = 0.001
I0622 20:28:24.631702 13672 solver.cpp:243] Iteration 2910, loss = 6.85067
I0622 20:28:24.631702 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.1637 (* 1 = 17.1637 loss)
I0622 20:28:24.631702 13672 sgd_solver.cpp:138] Iteration 2910, lr = 0.001
I0622 20:31:43.601029 13672 solver.cpp:243] Iteration 2920, loss = 6.9184
I0622 20:31:43.601029 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.77034 (* 1 = 4.77034 loss)
I0622 20:31:43.601029 13672 sgd_solver.cpp:138] Iteration 2920, lr = 0.001
I0622 20:34:56.805934 13672 solver.cpp:243] Iteration 2930, loss = 6.97877
I0622 20:34:56.805934 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.42291 (* 1 = 9.42291 loss)
I0622 20:34:56.805934 13672 sgd_solver.cpp:138] Iteration 2930, lr = 0.001
I0622 20:38:03.465536 13672 solver.cpp:243] Iteration 2940, loss = 7.06586
I0622 20:38:03.465536 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.95979 (* 1 = 6.95979 loss)
I0622 20:38:03.465536 13672 sgd_solver.cpp:138] Iteration 2940, lr = 0.001
I0622 20:41:29.370652 13672 solver.cpp:243] Iteration 2950, loss = 5.25359
I0622 20:41:29.370652 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.04174 (* 1 = 4.04174 loss)
I0622 20:41:29.370652 13672 sgd_solver.cpp:138] Iteration 2950, lr = 0.001
I0622 20:44:39.560746 13672 solver.cpp:243] Iteration 2960, loss = 5.49163
I0622 20:44:39.560746 13672 solver.cpp:259]     Train net output #0: mbox_loss = 19.8051 (* 1 = 19.8051 loss)
I0622 20:44:39.560746 13672 sgd_solver.cpp:138] Iteration 2960, lr = 0.001
I0622 20:47:54.109182 13672 solver.cpp:243] Iteration 2970, loss = 6.7737
I0622 20:47:54.140424 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.63162 (* 1 = 3.63162 loss)
I0622 20:47:54.171666 13672 sgd_solver.cpp:138] Iteration 2970, lr = 0.001
I0622 20:51:05.189668 13672 solver.cpp:243] Iteration 2980, loss = 6.83387
I0622 20:51:05.189668 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.16562 (* 1 = 3.16562 loss)
I0622 20:51:05.189668 13672 sgd_solver.cpp:138] Iteration 2980, lr = 0.001
I0622 20:54:25.408569 13672 solver.cpp:243] Iteration 2990, loss = 5.49926
I0622 20:54:25.408569 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.18698 (* 1 = 2.18698 loss)
I0622 20:54:25.408569 13672 sgd_solver.cpp:138] Iteration 2990, lr = 0.001
I0622 20:57:48.642478 13672 solver.cpp:243] Iteration 3000, loss = 5.21243
I0622 20:57:48.642478 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.58898 (* 1 = 1.58898 loss)
I0622 20:57:48.642478 13672 sgd_solver.cpp:138] Iteration 3000, lr = 0.001
I0622 21:01:05.393435 13672 solver.cpp:243] Iteration 3010, loss = 5.06241
I0622 21:01:05.393435 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.43116 (* 1 = 7.43116 loss)
I0622 21:01:05.393435 13672 sgd_solver.cpp:138] Iteration 3010, lr = 0.001
I0622 21:04:42.389751 13672 solver.cpp:243] Iteration 3020, loss = 5.01552
I0622 21:04:42.671144 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.69496 (* 1 = 2.69496 loss)
I0622 21:04:42.702580 13672 sgd_solver.cpp:138] Iteration 3020, lr = 0.001
I0622 21:07:52.814065 13672 solver.cpp:243] Iteration 3030, loss = 4.26488
I0622 21:07:52.814065 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.11139 (* 1 = 2.11139 loss)
I0622 21:07:52.814065 13672 sgd_solver.cpp:138] Iteration 3030, lr = 0.001
I0622 21:11:15.594909 13672 solver.cpp:243] Iteration 3040, loss = 5.29621
I0622 21:11:15.594909 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.7125 (* 1 = 12.7125 loss)
I0622 21:11:15.594909 13672 sgd_solver.cpp:138] Iteration 3040, lr = 0.001
I0622 21:14:29.612304 13672 solver.cpp:243] Iteration 3050, loss = 6.60637
I0622 21:14:29.612304 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.4697 (* 1 = 10.4697 loss)
I0622 21:14:29.612304 13672 sgd_solver.cpp:138] Iteration 3050, lr = 0.001
I0622 21:17:39.427421 13672 solver.cpp:243] Iteration 3060, loss = 5.98154
I0622 21:17:39.427421 13672 solver.cpp:259]     Train net output #0: mbox_loss = 14.5158 (* 1 = 14.5158 loss)
I0622 21:17:39.427421 13672 sgd_solver.cpp:138] Iteration 3060, lr = 0.001
I0622 21:20:48.289636 13672 solver.cpp:243] Iteration 3070, loss = 5.99256
I0622 21:20:48.289636 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.52983 (* 1 = 2.52983 loss)
I0622 21:20:48.289636 13672 sgd_solver.cpp:138] Iteration 3070, lr = 0.001
I0622 21:24:06.212239 13672 solver.cpp:243] Iteration 3080, loss = 5.30917
I0622 21:24:06.321591 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.82463 (* 1 = 3.82463 loss)
I0622 21:24:06.321591 13672 sgd_solver.cpp:138] Iteration 3080, lr = 0.001
I0622 21:27:17.495764 13672 solver.cpp:243] Iteration 3090, loss = 4.73297
I0622 21:27:17.495764 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.67125 (* 1 = 4.67125 loss)
I0622 21:27:17.495764 13672 sgd_solver.cpp:138] Iteration 3090, lr = 0.001
I0622 21:30:27.982599 13672 solver.cpp:243] Iteration 3100, loss = 5.04486
I0622 21:30:27.982599 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.71697 (* 1 = 3.71697 loss)
I0622 21:30:27.982599 13672 sgd_solver.cpp:138] Iteration 3100, lr = 0.001
I0622 21:33:54.181543 13672 solver.cpp:243] Iteration 3110, loss = 4.89732
I0622 21:33:54.181543 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.02453 (* 1 = 4.02453 loss)
I0622 21:33:54.181543 13672 sgd_solver.cpp:138] Iteration 3110, lr = 0.001
I0622 21:36:56.748349 13672 solver.cpp:243] Iteration 3120, loss = 5.89487
I0622 21:36:56.764003 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.96689 (* 1 = 3.96689 loss)
I0622 21:36:56.764003 13672 sgd_solver.cpp:138] Iteration 3120, lr = 0.001
I0622 21:40:01.314693 13672 solver.cpp:243] Iteration 3130, loss = 4.66993
I0622 21:40:01.314693 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.90138 (* 1 = 4.90138 loss)
I0622 21:40:01.314693 13672 sgd_solver.cpp:138] Iteration 3130, lr = 0.001
I0622 21:43:14.863349 13672 solver.cpp:243] Iteration 3140, loss = 5.72577
I0622 21:43:14.863349 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.77128 (* 1 = 4.77128 loss)
I0622 21:43:14.863349 13672 sgd_solver.cpp:138] Iteration 3140, lr = 0.001
I0622 21:46:24.647218 13672 solver.cpp:243] Iteration 3150, loss = 6.24436
I0622 21:46:24.647218 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.24166 (* 1 = 5.24166 loss)
I0622 21:46:24.647218 13672 sgd_solver.cpp:138] Iteration 3150, lr = 0.001
I0622 21:49:28.198179 13672 solver.cpp:243] Iteration 3160, loss = 7.23836
I0622 21:49:28.198179 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.7885 (* 1 = 17.7885 loss)
I0622 21:49:28.198179 13672 sgd_solver.cpp:138] Iteration 3160, lr = 0.001
I0622 21:52:33.248744 13672 solver.cpp:243] Iteration 3170, loss = 7.05685
I0622 21:52:33.248744 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.5828 (* 1 = 10.5828 loss)
I0622 21:52:33.248744 13672 sgd_solver.cpp:138] Iteration 3170, lr = 0.001
I0622 21:55:49.531105 13672 solver.cpp:243] Iteration 3180, loss = 6.28284
I0622 21:55:49.531105 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.0946 (* 1 = 17.0946 loss)
I0622 21:55:49.531105 13672 sgd_solver.cpp:138] Iteration 3180, lr = 0.001
I0622 21:58:50.551438 13672 solver.cpp:243] Iteration 3190, loss = 5.68836
I0622 21:58:50.551438 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.73227 (* 1 = 1.73227 loss)
I0622 21:58:50.551438 13672 sgd_solver.cpp:138] Iteration 3190, lr = 0.001
I0622 22:02:17.690600 13672 solver.cpp:243] Iteration 3200, loss = 5.70817
I0622 22:02:17.690600 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.4995 (* 1 = 4.4995 loss)
I0622 22:02:17.690600 13672 sgd_solver.cpp:138] Iteration 3200, lr = 0.001
I0622 22:05:27.740078 13672 solver.cpp:243] Iteration 3210, loss = 6.02203
I0622 22:05:27.740078 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.84381 (* 1 = 4.84381 loss)
I0622 22:05:27.740078 13672 sgd_solver.cpp:138] Iteration 3210, lr = 0.001
I0622 22:08:45.896991 13672 solver.cpp:243] Iteration 3220, loss = 5.15234
I0622 22:08:45.896991 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.2434 (* 1 = 3.2434 loss)
I0622 22:08:45.896991 13672 sgd_solver.cpp:138] Iteration 3220, lr = 0.001
I0622 22:11:55.602762 13672 solver.cpp:243] Iteration 3230, loss = 5.56325
I0622 22:11:55.602762 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.8647 (* 1 = 1.8647 loss)
I0622 22:11:55.602762 13672 sgd_solver.cpp:138] Iteration 3230, lr = 0.001
I0622 22:15:07.261276 13672 solver.cpp:243] Iteration 3240, loss = 4.86126
I0622 22:15:07.276854 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.48362 (* 1 = 4.48362 loss)
I0622 22:15:07.276854 13672 sgd_solver.cpp:138] Iteration 3240, lr = 0.001
I0622 22:18:20.919203 13672 solver.cpp:243] Iteration 3250, loss = 5.50219
I0622 22:18:20.919203 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.87564 (* 1 = 2.87564 loss)
I0622 22:18:20.919203 13672 sgd_solver.cpp:138] Iteration 3250, lr = 0.001
I0622 22:21:45.918342 13672 solver.cpp:243] Iteration 3260, loss = 5.98304
I0622 22:21:45.918342 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.3471 (* 1 = 4.3471 loss)
I0622 22:21:45.918342 13672 sgd_solver.cpp:138] Iteration 3260, lr = 0.001
I0622 22:25:27.398505 13672 solver.cpp:243] Iteration 3270, loss = 5.20609
I0622 22:25:27.445370 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.90245 (* 1 = 2.90245 loss)
I0622 22:25:27.476617 13672 sgd_solver.cpp:138] Iteration 3270, lr = 0.001
I0622 22:28:32.339339 13672 solver.cpp:243] Iteration 3280, loss = 4.57601
I0622 22:28:32.339339 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.81051 (* 1 = 1.81051 loss)
I0622 22:28:32.339339 13672 sgd_solver.cpp:138] Iteration 3280, lr = 0.001
I0622 22:31:43.122988 13672 solver.cpp:243] Iteration 3290, loss = 5.51656
I0622 22:31:43.138576 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.9805 (* 1 = 10.9805 loss)
I0622 22:31:43.138576 13672 sgd_solver.cpp:138] Iteration 3290, lr = 0.001
I0622 22:34:52.875633 13672 solver.cpp:243] Iteration 3300, loss = 4.77526
I0622 22:34:52.875633 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.11182 (* 1 = 5.11182 loss)
I0622 22:34:52.875633 13672 sgd_solver.cpp:138] Iteration 3300, lr = 0.001
I0622 22:38:12.739368 13672 solver.cpp:243] Iteration 3310, loss = 4.82214
I0622 22:38:12.739368 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.46457 (* 1 = 5.46457 loss)
I0622 22:38:12.739368 13672 sgd_solver.cpp:138] Iteration 3310, lr = 0.001
I0622 22:41:33.708132 13672 solver.cpp:243] Iteration 3320, loss = 5.3191
I0622 22:41:33.708132 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.40718 (* 1 = 4.40718 loss)
I0622 22:41:33.708132 13672 sgd_solver.cpp:138] Iteration 3320, lr = 0.001
I0622 22:44:50.021733 13672 solver.cpp:243] Iteration 3330, loss = 5.66398
I0622 22:44:50.021733 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.79111 (* 1 = 2.79111 loss)
I0622 22:44:50.021733 13672 sgd_solver.cpp:138] Iteration 3330, lr = 0.001
I0622 22:48:00.274250 13672 solver.cpp:243] Iteration 3340, loss = 5.63882
I0622 22:48:00.274250 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.08675 (* 1 = 5.08675 loss)
I0622 22:48:00.274250 13672 sgd_solver.cpp:138] Iteration 3340, lr = 0.001
I0622 22:51:16.009821 13672 solver.cpp:243] Iteration 3350, loss = 4.45796
I0622 22:51:16.009821 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.68383 (* 1 = 1.68383 loss)
I0622 22:51:16.009821 13672 sgd_solver.cpp:138] Iteration 3350, lr = 0.001
I0622 22:54:27.230861 13672 solver.cpp:243] Iteration 3360, loss = 5.1142
I0622 22:54:27.230861 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.57843 (* 1 = 3.57843 loss)
I0622 22:54:27.230861 13672 sgd_solver.cpp:138] Iteration 3360, lr = 0.001
I0622 22:57:54.338822 13672 solver.cpp:243] Iteration 3370, loss = 5.1403
I0622 22:57:54.370172 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.87023 (* 1 = 4.87023 loss)
I0622 22:57:54.370172 13672 sgd_solver.cpp:138] Iteration 3370, lr = 0.001
I0622 23:01:07.184585 13672 solver.cpp:243] Iteration 3380, loss = 4.83156
I0622 23:01:07.184585 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.64439 (* 1 = 8.64439 loss)
I0622 23:01:07.184585 13672 sgd_solver.cpp:138] Iteration 3380, lr = 0.001
I0622 23:04:23.201414 13672 solver.cpp:243] Iteration 3390, loss = 4.73025
I0622 23:04:23.201414 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.06096 (* 1 = 6.06096 loss)
I0622 23:04:23.201414 13672 sgd_solver.cpp:138] Iteration 3390, lr = 0.001
I0622 23:07:35.484751 13672 solver.cpp:243] Iteration 3400, loss = 5.31842
I0622 23:07:35.484751 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.10633 (* 1 = 4.10633 loss)
I0622 23:07:35.484751 13672 sgd_solver.cpp:138] Iteration 3400, lr = 0.001
I0622 23:10:45.924762 13672 solver.cpp:243] Iteration 3410, loss = 4.68428
I0622 23:10:45.924762 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.02489 (* 1 = 4.02489 loss)
I0622 23:10:45.924762 13672 sgd_solver.cpp:138] Iteration 3410, lr = 0.001
I0622 23:14:02.363334 13672 solver.cpp:243] Iteration 3420, loss = 5.0831
I0622 23:14:02.363334 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.65036 (* 1 = 9.65036 loss)
I0622 23:14:02.363334 13672 sgd_solver.cpp:138] Iteration 3420, lr = 0.001
I0622 23:16:49.652417 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0622 23:17:18.833149 13672 solver.cpp:243] Iteration 3430, loss = 5.0243
I0622 23:17:18.833149 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.72286 (* 1 = 5.72286 loss)
I0622 23:17:18.833149 13672 sgd_solver.cpp:138] Iteration 3430, lr = 0.001
I0622 23:20:24.427150 13672 solver.cpp:243] Iteration 3440, loss = 4.71097
I0622 23:20:24.427150 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.69835 (* 1 = 4.69835 loss)
I0622 23:20:24.427150 13672 sgd_solver.cpp:138] Iteration 3440, lr = 0.001
I0622 23:23:50.738421 13672 solver.cpp:243] Iteration 3450, loss = 5.0534
I0622 23:23:50.738421 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.98231 (* 1 = 3.98231 loss)
I0622 23:23:50.738421 13672 sgd_solver.cpp:138] Iteration 3450, lr = 0.001
I0622 23:27:07.005156 13672 solver.cpp:243] Iteration 3460, loss = 4.99061
I0622 23:27:07.005156 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.06215 (* 1 = 2.06215 loss)
I0622 23:27:07.005156 13672 sgd_solver.cpp:138] Iteration 3460, lr = 0.001
I0622 23:30:19.397801 13672 solver.cpp:243] Iteration 3470, loss = 4.95156
I0622 23:30:19.397801 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.53409 (* 1 = 3.53409 loss)
I0622 23:30:19.397801 13672 sgd_solver.cpp:138] Iteration 3470, lr = 0.001
I0622 23:33:50.114293 13672 solver.cpp:243] Iteration 3480, loss = 5.79673
I0622 23:33:50.114293 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.75875 (* 1 = 1.75875 loss)
I0622 23:33:50.114293 13672 sgd_solver.cpp:138] Iteration 3480, lr = 0.001
I0622 23:37:06.021699 13672 solver.cpp:243] Iteration 3490, loss = 5.16182
I0622 23:37:06.037322 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.16044 (* 1 = 1.16044 loss)
I0622 23:37:06.037322 13672 sgd_solver.cpp:138] Iteration 3490, lr = 0.001
I0622 23:40:20.163976 13672 solver.cpp:243] Iteration 3500, loss = 4.99092
I0622 23:40:20.163976 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.36952 (* 1 = 2.36952 loss)
I0622 23:40:20.163976 13672 sgd_solver.cpp:138] Iteration 3500, lr = 0.001
I0622 23:43:41.351404 13672 solver.cpp:243] Iteration 3510, loss = 6.35753
I0622 23:43:41.351404 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.57337 (* 1 = 7.57337 loss)
I0622 23:43:41.351404 13672 sgd_solver.cpp:138] Iteration 3510, lr = 0.001
I0622 23:47:07.226142 13672 solver.cpp:243] Iteration 3520, loss = 6.07861
I0622 23:47:07.257457 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.00628 (* 1 = 2.00628 loss)
I0622 23:47:07.257457 13672 sgd_solver.cpp:138] Iteration 3520, lr = 0.001
I0622 23:50:13.792099 13672 solver.cpp:243] Iteration 3530, loss = 4.99951
I0622 23:50:13.792099 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.50775 (* 1 = 1.50775 loss)
I0622 23:50:13.792099 13672 sgd_solver.cpp:138] Iteration 3530, lr = 0.001
I0622 23:53:41.666070 13672 solver.cpp:243] Iteration 3540, loss = 4.99337
I0622 23:53:41.728953 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.6221 (* 1 = 10.6221 loss)
I0622 23:53:41.728953 13672 sgd_solver.cpp:138] Iteration 3540, lr = 0.001
I0622 23:56:52.902693 13672 solver.cpp:243] Iteration 3550, loss = 5.29465
I0622 23:56:52.902693 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.3864 (* 1 = 10.3864 loss)
I0622 23:56:52.902693 13672 sgd_solver.cpp:138] Iteration 3550, lr = 0.001
I0623 00:00:03.327050 13672 solver.cpp:243] Iteration 3560, loss = 5.74386
I0623 00:00:03.327050 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.71818 (* 1 = 4.71818 loss)
I0623 00:00:03.327050 13672 sgd_solver.cpp:138] Iteration 3560, lr = 0.001
I0623 00:03:35.043272 13672 solver.cpp:243] Iteration 3570, loss = 5.55399
I0623 00:03:35.043272 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.02484 (* 1 = 5.02484 loss)
I0623 00:03:35.043272 13672 sgd_solver.cpp:138] Iteration 3570, lr = 0.001
I0623 00:06:54.340596 13672 solver.cpp:243] Iteration 3580, loss = 5.25682
I0623 00:06:54.340596 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.57875 (* 1 = 3.57875 loss)
I0623 00:06:54.340596 13672 sgd_solver.cpp:138] Iteration 3580, lr = 0.001
I0623 00:10:16.137300 13672 solver.cpp:243] Iteration 3590, loss = 4.91985
I0623 00:10:16.137300 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.90111 (* 1 = 4.90111 loss)
I0623 00:10:16.137300 13672 sgd_solver.cpp:138] Iteration 3590, lr = 0.001
I0623 00:15:59.285759 13672 solver.cpp:243] Iteration 3600, loss = 6.23248
I0623 00:15:59.285759 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.25614 (* 1 = 3.25614 loss)
I0623 00:15:59.285759 13672 sgd_solver.cpp:138] Iteration 3600, lr = 0.001
I0623 00:19:19.796908 13672 solver.cpp:243] Iteration 3610, loss = 7.41124
I0623 00:19:19.796908 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.71692 (* 1 = 1.71692 loss)
I0623 00:19:19.796908 13672 sgd_solver.cpp:138] Iteration 3610, lr = 0.001
I0623 00:22:44.328374 13672 solver.cpp:243] Iteration 3620, loss = 7.15892
I0623 00:22:44.328374 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.59591 (* 1 = 3.59591 loss)
I0623 00:22:44.328374 13672 sgd_solver.cpp:138] Iteration 3620, lr = 0.001
I0623 00:26:02.940039 13672 solver.cpp:243] Iteration 3630, loss = 5.46456
I0623 00:26:02.940039 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.08751 (* 1 = 4.08751 loss)
I0623 00:26:02.940039 13672 sgd_solver.cpp:138] Iteration 3630, lr = 0.001
I0623 00:29:23.924535 13672 solver.cpp:243] Iteration 3640, loss = 5.34079
I0623 00:29:23.924535 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.62441 (* 1 = 9.62441 loss)
I0623 00:29:23.924535 13672 sgd_solver.cpp:138] Iteration 3640, lr = 0.001
I0623 00:32:30.475931 13672 solver.cpp:243] Iteration 3650, loss = 4.78868
I0623 00:32:30.475931 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.72235 (* 1 = 4.72235 loss)
I0623 00:32:30.475931 13672 sgd_solver.cpp:138] Iteration 3650, lr = 0.001
I0623 00:35:37.435926 13672 solver.cpp:243] Iteration 3660, loss = 5.18948
I0623 00:35:37.435926 13672 solver.cpp:259]     Train net output #0: mbox_loss = 14.7606 (* 1 = 14.7606 loss)
I0623 00:35:37.435926 13672 sgd_solver.cpp:138] Iteration 3660, lr = 0.001
I0623 00:38:58.545586 13672 solver.cpp:243] Iteration 3670, loss = 5.21123
I0623 00:38:58.623694 13672 solver.cpp:259]     Train net output #0: mbox_loss = 14.5151 (* 1 = 14.5151 loss)
I0623 00:38:58.623694 13672 sgd_solver.cpp:138] Iteration 3670, lr = 0.001
I0623 00:42:22.294950 13672 solver.cpp:243] Iteration 3680, loss = 4.78857
I0623 00:42:22.294950 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.40166 (* 1 = 6.40166 loss)
I0623 00:42:22.294950 13672 sgd_solver.cpp:138] Iteration 3680, lr = 0.001
I0623 00:45:32.203796 13672 solver.cpp:243] Iteration 3690, loss = 4.7497
I0623 00:45:32.203796 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.44594 (* 1 = 4.44594 loss)
I0623 00:45:32.203796 13672 sgd_solver.cpp:138] Iteration 3690, lr = 0.001
I0623 00:49:06.372617 13672 solver.cpp:243] Iteration 3700, loss = 4.95322
I0623 00:49:06.372617 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.05313 (* 1 = 4.05313 loss)
I0623 00:49:06.372617 13672 sgd_solver.cpp:138] Iteration 3700, lr = 0.001
I0623 00:52:20.999116 13672 solver.cpp:243] Iteration 3710, loss = 4.81624
I0623 00:52:20.999116 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.59875 (* 1 = 3.59875 loss)
I0623 00:52:20.999116 13672 sgd_solver.cpp:138] Iteration 3710, lr = 0.001
I0623 00:55:33.688513 13672 solver.cpp:243] Iteration 3720, loss = 5.10677
I0623 00:55:33.688513 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.14751 (* 1 = 3.14751 loss)
I0623 00:55:33.688513 13672 sgd_solver.cpp:138] Iteration 3720, lr = 0.001
I0623 00:58:44.315943 13672 solver.cpp:243] Iteration 3730, loss = 4.69963
I0623 00:58:44.315943 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.08166 (* 1 = 2.08166 loss)
I0623 00:58:44.315943 13672 sgd_solver.cpp:138] Iteration 3730, lr = 0.001
I0623 01:02:01.223191 13672 solver.cpp:243] Iteration 3740, loss = 4.79586
I0623 01:02:01.223191 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.05555 (* 1 = 2.05555 loss)
I0623 01:02:01.223191 13672 sgd_solver.cpp:138] Iteration 3740, lr = 0.001
I0623 01:05:15.131114 13672 solver.cpp:243] Iteration 3750, loss = 4.63793
I0623 01:05:15.131114 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.82022 (* 1 = 1.82022 loss)
I0623 01:05:15.131114 13672 sgd_solver.cpp:138] Iteration 3750, lr = 0.001
I0623 01:08:35.256280 13672 solver.cpp:243] Iteration 3760, loss = 4.33731
I0623 01:08:35.256280 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.72457 (* 1 = 4.72457 loss)
I0623 01:08:35.256280 13672 sgd_solver.cpp:138] Iteration 3760, lr = 0.001
I0623 01:11:50.679576 13672 solver.cpp:243] Iteration 3770, loss = 4.50432
I0623 01:11:50.679576 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.82032 (* 1 = 2.82032 loss)
I0623 01:11:50.679576 13672 sgd_solver.cpp:138] Iteration 3770, lr = 0.001
I0623 01:15:09.023988 13672 solver.cpp:243] Iteration 3780, loss = 4.47954
I0623 01:15:09.023988 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.2128 (* 1 = 2.2128 loss)
I0623 01:15:09.023988 13672 sgd_solver.cpp:138] Iteration 3780, lr = 0.001
I0623 01:18:34.975934 13672 solver.cpp:243] Iteration 3790, loss = 5.10228
I0623 01:18:34.975934 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0623 01:18:34.975934 13672 sgd_solver.cpp:138] Iteration 3790, lr = 0.001
I0623 01:21:45.572221 13672 solver.cpp:243] Iteration 3800, loss = 5.01794
I0623 01:21:45.572221 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.9884 (* 1 = 10.9884 loss)
I0623 01:21:45.572221 13672 sgd_solver.cpp:138] Iteration 3800, lr = 0.001
I0623 01:24:58.355474 13672 solver.cpp:243] Iteration 3810, loss = 5.30561
I0623 01:24:58.355474 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.29934 (* 1 = 4.29934 loss)
I0623 01:24:58.355474 13672 sgd_solver.cpp:138] Iteration 3810, lr = 0.001
I0623 01:31:30.872237 13672 solver.cpp:243] Iteration 3820, loss = 4.90114
I0623 01:31:30.872237 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.9322 (* 1 = 4.9322 loss)
I0623 01:31:30.872237 13672 sgd_solver.cpp:138] Iteration 3820, lr = 0.001
I0623 01:35:07.735298 13672 solver.cpp:243] Iteration 3830, loss = 4.89948
I0623 01:35:07.735298 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.27564 (* 1 = 5.27564 loss)
I0623 01:35:07.735298 13672 sgd_solver.cpp:138] Iteration 3830, lr = 0.001
I0623 01:38:27.532465 13672 solver.cpp:243] Iteration 3840, loss = 5.47214
I0623 01:38:27.532465 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.4308 (* 1 = 3.4308 loss)
I0623 01:38:27.532465 13672 sgd_solver.cpp:138] Iteration 3840, lr = 0.001
I0623 01:41:46.564244 13672 solver.cpp:243] Iteration 3850, loss = 4.71808
I0623 01:41:46.564244 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.68287 (* 1 = 3.68287 loss)
I0623 01:41:46.564244 13672 sgd_solver.cpp:138] Iteration 3850, lr = 0.001
I0623 01:44:52.808308 13672 solver.cpp:243] Iteration 3860, loss = 4.5385
I0623 01:44:52.808308 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.372 (* 1 = 2.372 loss)
I0623 01:44:52.808308 13672 sgd_solver.cpp:138] Iteration 3860, lr = 0.001
I0623 01:48:14.308241 13672 solver.cpp:243] Iteration 3870, loss = 5.12219
I0623 01:48:14.308241 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.18807 (* 1 = 4.18807 loss)
I0623 01:48:14.308241 13672 sgd_solver.cpp:138] Iteration 3870, lr = 0.001
I0623 01:51:26.841485 13672 solver.cpp:243] Iteration 3880, loss = 4.96765
I0623 01:51:26.841485 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.34597 (* 1 = 5.34597 loss)
I0623 01:51:26.841485 13672 sgd_solver.cpp:138] Iteration 3880, lr = 0.001
I0623 01:54:43.904907 13672 solver.cpp:243] Iteration 3890, loss = 4.83404
I0623 01:54:43.904907 13672 solver.cpp:259]     Train net output #0: mbox_loss = 12.2209 (* 1 = 12.2209 loss)
I0623 01:54:43.904907 13672 sgd_solver.cpp:138] Iteration 3890, lr = 0.001
I0623 01:58:16.683408 13672 solver.cpp:243] Iteration 3900, loss = 4.22288
I0623 01:58:16.730278 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.97769 (* 1 = 2.97769 loss)
I0623 01:58:16.761519 13672 sgd_solver.cpp:138] Iteration 3900, lr = 0.001
I0623 02:01:27.139009 13672 solver.cpp:243] Iteration 3910, loss = 4.65302
I0623 02:01:27.139009 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.11803 (* 1 = 4.11803 loss)
I0623 02:01:27.139009 13672 sgd_solver.cpp:138] Iteration 3910, lr = 0.001
I0623 02:04:43.062075 13672 solver.cpp:243] Iteration 3920, loss = 4.61883
I0623 02:04:43.062075 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.17739 (* 1 = 7.17739 loss)
I0623 02:04:43.062075 13672 sgd_solver.cpp:138] Iteration 3920, lr = 0.001
I0623 02:07:59.675617 13672 solver.cpp:243] Iteration 3930, loss = 4.83275
I0623 02:07:59.675617 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.94416 (* 1 = 3.94416 loss)
I0623 02:07:59.675617 13672 sgd_solver.cpp:138] Iteration 3930, lr = 0.001
I0623 02:11:10.271819 13672 solver.cpp:243] Iteration 3940, loss = 4.29976
I0623 02:11:10.271819 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.71788 (* 1 = 6.71788 loss)
I0623 02:11:10.271819 13672 sgd_solver.cpp:138] Iteration 3940, lr = 0.001
I0623 02:14:27.296545 13672 solver.cpp:243] Iteration 3950, loss = 5.32354
I0623 02:14:27.296545 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.28573 (* 1 = 5.28573 loss)
I0623 02:14:27.296545 13672 sgd_solver.cpp:138] Iteration 3950, lr = 0.001
I0623 02:17:33.331240 13672 solver.cpp:243] Iteration 3960, loss = 5.02216
I0623 02:17:33.331240 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.85397 (* 1 = 7.85397 loss)
I0623 02:17:33.331240 13672 sgd_solver.cpp:138] Iteration 3960, lr = 0.001
I0623 02:20:47.629721 13672 solver.cpp:243] Iteration 3970, loss = 5.67898
I0623 02:20:47.629721 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.85939 (* 1 = 2.85939 loss)
I0623 02:20:47.629721 13672 sgd_solver.cpp:138] Iteration 3970, lr = 0.001
I0623 02:24:08.989025 13672 solver.cpp:243] Iteration 3980, loss = 5.04088
I0623 02:24:08.989025 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.49708 (* 1 = 3.49708 loss)
I0623 02:24:08.989025 13672 sgd_solver.cpp:138] Iteration 3980, lr = 0.001
I0623 02:27:28.317509 13672 solver.cpp:243] Iteration 3990, loss = 4.96922
I0623 02:27:28.317509 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.10609 (* 1 = 2.10609 loss)
I0623 02:27:28.317509 13672 sgd_solver.cpp:138] Iteration 3990, lr = 0.001
I0623 02:30:45.193521 13672 solver.cpp:243] Iteration 4000, loss = 4.80737
I0623 02:30:45.193521 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.06804 (* 1 = 1.06804 loss)
I0623 02:30:45.193521 13672 sgd_solver.cpp:138] Iteration 4000, lr = 0.001
I0623 02:33:55.508481 13672 solver.cpp:243] Iteration 4010, loss = 4.97653
I0623 02:33:55.508481 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.94614 (* 1 = 1.94614 loss)
I0623 02:33:55.508481 13672 sgd_solver.cpp:138] Iteration 4010, lr = 0.001
I0623 02:37:20.413869 13672 solver.cpp:243] Iteration 4020, loss = 4.8635
I0623 02:37:20.461285 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.73186 (* 1 = 1.73186 loss)
I0623 02:37:20.476881 13672 sgd_solver.cpp:138] Iteration 4020, lr = 0.001
I0623 02:40:26.308079 13672 solver.cpp:243] Iteration 4030, loss = 4.44076
I0623 02:40:26.308079 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.96098 (* 1 = 1.96098 loss)
I0623 02:40:26.308079 13672 sgd_solver.cpp:138] Iteration 4030, lr = 0.001
I0623 02:43:34.279837 13672 solver.cpp:243] Iteration 4040, loss = 4.90005
I0623 02:43:34.279837 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.84035 (* 1 = 6.84035 loss)
I0623 02:43:34.279837 13672 sgd_solver.cpp:138] Iteration 4040, lr = 0.001
I0623 02:46:48.605099 13672 solver.cpp:243] Iteration 4050, loss = 4.62715
I0623 02:46:48.605099 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.57227 (* 1 = 6.57227 loss)
I0623 02:46:48.605099 13672 sgd_solver.cpp:138] Iteration 4050, lr = 0.001
I0623 02:50:07.699270 13672 solver.cpp:243] Iteration 4060, loss = 4.52259
I0623 02:50:07.699270 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.83979 (* 1 = 5.83979 loss)
I0623 02:50:07.699270 13672 sgd_solver.cpp:138] Iteration 4060, lr = 0.001
I0623 02:53:24.528376 13672 solver.cpp:243] Iteration 4070, loss = 4.41054
I0623 02:53:24.528376 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.21675 (* 1 = 1.21675 loss)
I0623 02:53:24.528376 13672 sgd_solver.cpp:138] Iteration 4070, lr = 0.001
I0623 02:56:29.329037 13672 solver.cpp:243] Iteration 4080, loss = 4.31128
I0623 02:56:29.329037 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.569 (* 1 = 2.569 loss)
I0623 02:56:29.329037 13672 sgd_solver.cpp:138] Iteration 4080, lr = 0.001
I0623 02:59:52.125504 13672 solver.cpp:243] Iteration 4090, loss = 4.55919
I0623 02:59:52.125504 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.75264 (* 1 = 4.75264 loss)
I0623 02:59:52.125504 13672 sgd_solver.cpp:138] Iteration 4090, lr = 0.001
I0623 03:03:01.465199 13672 solver.cpp:243] Iteration 4100, loss = 4.66329
I0623 03:03:01.465199 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.09935 (* 1 = 4.09935 loss)
I0623 03:03:01.465199 13672 sgd_solver.cpp:138] Iteration 4100, lr = 0.001
I0623 03:06:18.943439 13672 solver.cpp:243] Iteration 4110, loss = 5.29751
I0623 03:06:18.943439 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.93845 (* 1 = 2.93845 loss)
I0623 03:06:18.943439 13672 sgd_solver.cpp:138] Iteration 4110, lr = 0.001
I0623 03:09:31.211148 13672 solver.cpp:243] Iteration 4120, loss = 5.24785
I0623 03:09:31.211148 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.87335 (* 1 = 2.87335 loss)
I0623 03:09:31.211148 13672 sgd_solver.cpp:138] Iteration 4120, lr = 0.001
I0623 03:12:50.258638 13672 solver.cpp:243] Iteration 4130, loss = 4.74206
I0623 03:12:50.258638 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.53273 (* 1 = 6.53273 loss)
I0623 03:12:50.258638 13672 sgd_solver.cpp:138] Iteration 4130, lr = 0.001
I0623 03:14:27.985850 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0623 03:16:01.198482 13672 solver.cpp:243] Iteration 4140, loss = 5.46278
I0623 03:16:01.198482 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.73032 (* 1 = 8.73032 loss)
I0623 03:16:01.198482 13672 sgd_solver.cpp:138] Iteration 4140, lr = 0.001
I0623 03:19:14.528373 13672 solver.cpp:243] Iteration 4150, loss = 4.82289
I0623 03:19:14.528373 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.88169 (* 1 = 2.88169 loss)
I0623 03:19:14.528373 13672 sgd_solver.cpp:138] Iteration 4150, lr = 0.001
I0623 03:22:31.513725 13672 solver.cpp:243] Iteration 4160, loss = 4.53786
I0623 03:22:31.513725 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.2493 (* 1 = 6.2493 loss)
I0623 03:22:31.513725 13672 sgd_solver.cpp:138] Iteration 4160, lr = 0.001
I0623 03:25:56.997131 13672 solver.cpp:243] Iteration 4170, loss = 4.24991
I0623 03:25:56.997131 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.21259 (* 1 = 7.21259 loss)
I0623 03:25:56.997131 13672 sgd_solver.cpp:138] Iteration 4170, lr = 0.001
I0623 03:29:25.546838 13672 solver.cpp:243] Iteration 4180, loss = 4.26508
I0623 03:29:25.546838 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.30947 (* 1 = 4.30947 loss)
I0623 03:29:25.546838 13672 sgd_solver.cpp:138] Iteration 4180, lr = 0.001
I0623 03:32:42.922262 13672 solver.cpp:243] Iteration 4190, loss = 4.18327
I0623 03:32:42.922262 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.3502 (* 1 = 4.3502 loss)
I0623 03:32:42.922262 13672 sgd_solver.cpp:138] Iteration 4190, lr = 0.001
I0623 03:36:27.992307 13672 solver.cpp:243] Iteration 4200, loss = 4.19854
I0623 03:36:27.992307 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.17967 (* 1 = 3.17967 loss)
I0623 03:36:27.992307 13672 sgd_solver.cpp:138] Iteration 4200, lr = 0.001
I0623 03:39:33.360224 13672 solver.cpp:243] Iteration 4210, loss = 3.99612
I0623 03:39:33.360224 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.87178 (* 1 = 2.87178 loss)
I0623 03:39:33.360224 13672 sgd_solver.cpp:138] Iteration 4210, lr = 0.001
I0623 03:42:46.653306 13672 solver.cpp:243] Iteration 4220, loss = 4.11878
I0623 03:42:46.653306 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.21563 (* 1 = 4.21563 loss)
I0623 03:42:46.653306 13672 sgd_solver.cpp:138] Iteration 4220, lr = 0.001
I0623 03:47:28.052358 13672 solver.cpp:243] Iteration 4230, loss = 4.33566
I0623 03:47:28.052358 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.950444 (* 1 = 0.950444 loss)
I0623 03:47:28.052358 13672 sgd_solver.cpp:138] Iteration 4230, lr = 0.001
I0623 03:52:22.281390 13672 solver.cpp:243] Iteration 4240, loss = 4.38927
I0623 03:52:22.284955 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.963889 (* 1 = 0.963889 loss)
I0623 03:52:22.311071 13672 sgd_solver.cpp:138] Iteration 4240, lr = 0.001
I0623 03:56:31.877056 13672 solver.cpp:243] Iteration 4250, loss = 4.6147
I0623 03:56:31.878049 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.14525 (* 1 = 1.14525 loss)
I0623 03:56:31.878049 13672 sgd_solver.cpp:138] Iteration 4250, lr = 0.001
I0623 04:00:35.507032 13672 solver.cpp:243] Iteration 4260, loss = 4.88084
I0623 04:00:35.507032 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.65037 (* 1 = 4.65037 loss)
I0623 04:00:35.508033 13672 sgd_solver.cpp:138] Iteration 4260, lr = 0.001
I0623 04:04:49.882267 13672 solver.cpp:243] Iteration 4270, loss = 4.5773
I0623 04:04:49.916616 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.8581 (* 1 = 1.8581 loss)
I0623 04:04:49.916616 13672 sgd_solver.cpp:138] Iteration 4270, lr = 0.001
I0623 04:09:03.172755 13672 solver.cpp:243] Iteration 4280, loss = 4.80724
I0623 04:09:03.172755 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.02278 (* 1 = 2.02278 loss)
I0623 04:09:03.172755 13672 sgd_solver.cpp:138] Iteration 4280, lr = 0.001
I0623 04:12:55.398972 13672 solver.cpp:243] Iteration 4290, loss = 4.50637
I0623 04:12:55.398972 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.953 (* 1 = 4.953 loss)
I0623 04:12:55.398972 13672 sgd_solver.cpp:138] Iteration 4290, lr = 0.001
I0623 04:16:09.869772 13672 solver.cpp:243] Iteration 4300, loss = 4.32388
I0623 04:16:09.869772 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.41706 (* 1 = 5.41706 loss)
I0623 04:16:09.869772 13672 sgd_solver.cpp:138] Iteration 4300, lr = 0.001
I0623 04:19:29.432734 13672 solver.cpp:243] Iteration 4310, loss = 3.92597
I0623 04:19:29.432734 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.61217 (* 1 = 3.61217 loss)
I0623 04:19:29.432734 13672 sgd_solver.cpp:138] Iteration 4310, lr = 0.001
I0623 04:23:03.320366 13672 solver.cpp:243] Iteration 4320, loss = 4.24394
I0623 04:23:03.320366 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.75337 (* 1 = 1.75337 loss)
I0623 04:23:03.320366 13672 sgd_solver.cpp:138] Iteration 4320, lr = 0.001
I0623 04:26:27.522753 13672 solver.cpp:243] Iteration 4330, loss = 4.24736
I0623 04:26:27.522753 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.53431 (* 1 = 6.53431 loss)
I0623 04:26:27.522753 13672 sgd_solver.cpp:138] Iteration 4330, lr = 0.001
I0623 04:29:50.147512 13672 solver.cpp:243] Iteration 4340, loss = 4.73041
I0623 04:29:50.147512 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.92057 (* 1 = 2.92057 loss)
I0623 04:29:50.147512 13672 sgd_solver.cpp:138] Iteration 4340, lr = 0.001
I0623 04:33:00.025072 13672 solver.cpp:243] Iteration 4350, loss = 5.08906
I0623 04:33:00.025072 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.73541 (* 1 = 1.73541 loss)
I0623 04:33:00.025072 13672 sgd_solver.cpp:138] Iteration 4350, lr = 0.001
I0623 04:36:27.258049 13672 solver.cpp:243] Iteration 4360, loss = 4.55463
I0623 04:36:27.258049 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.07716 (* 1 = 2.07716 loss)
I0623 04:36:27.258049 13672 sgd_solver.cpp:138] Iteration 4360, lr = 0.001
I0623 04:39:41.259685 13672 solver.cpp:243] Iteration 4370, loss = 4.36964
I0623 04:39:41.259685 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.13196 (* 1 = 2.13196 loss)
I0623 04:39:41.259685 13672 sgd_solver.cpp:138] Iteration 4370, lr = 0.001
I0623 04:42:47.981772 13672 solver.cpp:243] Iteration 4380, loss = 4.38489
I0623 04:42:47.981772 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.57831 (* 1 = 3.57831 loss)
I0623 04:42:47.981772 13672 sgd_solver.cpp:138] Iteration 4380, lr = 0.001
I0623 04:46:08.678613 13672 solver.cpp:243] Iteration 4390, loss = 4.26609
I0623 04:46:08.678613 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.03792 (* 1 = 5.03792 loss)
I0623 04:46:08.678613 13672 sgd_solver.cpp:138] Iteration 4390, lr = 0.001
I0623 04:49:18.946694 13672 solver.cpp:243] Iteration 4400, loss = 4.51922
I0623 04:49:18.946694 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.30165 (* 1 = 4.30165 loss)
I0623 04:49:18.946694 13672 sgd_solver.cpp:138] Iteration 4400, lr = 0.001
I0623 04:52:36.994307 13672 solver.cpp:243] Iteration 4410, loss = 4.44445
I0623 04:52:36.994307 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.93895 (* 1 = 5.93895 loss)
I0623 04:52:36.994307 13672 sgd_solver.cpp:138] Iteration 4410, lr = 0.001
I0623 04:55:57.275928 13672 solver.cpp:243] Iteration 4420, loss = 5.06779
I0623 04:55:57.275928 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.38578 (* 1 = 9.38578 loss)
I0623 04:55:57.275928 13672 sgd_solver.cpp:138] Iteration 4420, lr = 0.001
I0623 04:59:06.408783 13672 solver.cpp:243] Iteration 4430, loss = 4.66038
I0623 04:59:06.408783 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.13008 (* 1 = 4.13008 loss)
I0623 04:59:06.408783 13672 sgd_solver.cpp:138] Iteration 4430, lr = 0.001
I0623 05:02:18.689281 13672 solver.cpp:243] Iteration 4440, loss = 4.08778
I0623 05:02:18.689281 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.25531 (* 1 = 4.25531 loss)
I0623 05:02:18.689281 13672 sgd_solver.cpp:138] Iteration 4440, lr = 0.001
I0623 05:07:03.537107 13672 solver.cpp:243] Iteration 4450, loss = 4.34233
I0623 05:07:03.537107 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.16147 (* 1 = 5.16147 loss)
I0623 05:07:03.537107 13672 sgd_solver.cpp:138] Iteration 4450, lr = 0.001
I0623 05:11:18.232898 13672 solver.cpp:243] Iteration 4460, loss = 4.35246
I0623 05:11:18.232898 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.17589 (* 1 = 3.17589 loss)
I0623 05:11:18.232898 13672 sgd_solver.cpp:138] Iteration 4460, lr = 0.001
I0623 05:15:14.238523 13672 solver.cpp:243] Iteration 4470, loss = 3.98892
I0623 05:15:14.238523 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.61911 (* 1 = 4.61911 loss)
I0623 05:15:14.238523 13672 sgd_solver.cpp:138] Iteration 4470, lr = 0.001
I0623 05:19:46.769564 13672 solver.cpp:243] Iteration 4480, loss = 4.25145
I0623 05:19:46.798221 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.02366 (* 1 = 2.02366 loss)
I0623 05:19:46.798221 13672 sgd_solver.cpp:138] Iteration 4480, lr = 0.001
I0623 05:24:20.792245 13672 solver.cpp:243] Iteration 4490, loss = 4.20122
I0623 05:24:20.792245 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.01248 (* 1 = 1.01248 loss)
I0623 05:24:20.792245 13672 sgd_solver.cpp:138] Iteration 4490, lr = 0.001
I0623 05:28:00.224648 13672 solver.cpp:243] Iteration 4500, loss = 3.89584
I0623 05:28:00.224648 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.9415 (* 1 = 3.9415 loss)
I0623 05:28:00.224648 13672 sgd_solver.cpp:138] Iteration 4500, lr = 0.001
I0623 05:31:08.321434 13672 solver.cpp:243] Iteration 4510, loss = 4.28321
I0623 05:31:08.321434 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.70984 (* 1 = 5.70984 loss)
I0623 05:31:08.321434 13672 sgd_solver.cpp:138] Iteration 4510, lr = 0.001
I0623 05:34:42.459069 13672 solver.cpp:243] Iteration 4520, loss = 4.22528
I0623 05:34:42.521939 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.92206 (* 1 = 1.92206 loss)
I0623 05:34:42.553180 13672 sgd_solver.cpp:138] Iteration 4520, lr = 0.001
I0623 05:37:53.773810 13672 solver.cpp:243] Iteration 4530, loss = 3.92945
I0623 05:37:53.773810 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.84667 (* 1 = 1.84667 loss)
I0623 05:37:53.773810 13672 sgd_solver.cpp:138] Iteration 4530, lr = 0.001
I0623 05:41:11.352866 13672 solver.cpp:243] Iteration 4540, loss = 4.61585
I0623 05:41:11.352866 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.37348 (* 1 = 5.37348 loss)
I0623 05:41:11.352866 13672 sgd_solver.cpp:138] Iteration 4540, lr = 0.001
I0623 05:44:21.693809 13672 solver.cpp:243] Iteration 4550, loss = 4.25105
I0623 05:44:21.693809 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.79323 (* 1 = 5.79323 loss)
I0623 05:44:21.693809 13672 sgd_solver.cpp:138] Iteration 4550, lr = 0.001
I0623 05:47:33.024410 13672 solver.cpp:243] Iteration 4560, loss = 4.31894
I0623 05:47:33.024410 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.17225 (* 1 = 1.17225 loss)
I0623 05:47:33.024410 13672 sgd_solver.cpp:138] Iteration 4560, lr = 0.001
I0623 05:50:54.321224 13672 solver.cpp:243] Iteration 4570, loss = 4.6632
I0623 05:50:54.321224 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.93526 (* 1 = 4.93526 loss)
I0623 05:50:54.321224 13672 sgd_solver.cpp:138] Iteration 4570, lr = 0.001
I0623 05:54:15.602490 13672 solver.cpp:243] Iteration 4580, loss = 4.78981
I0623 05:54:15.602490 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.03357 (* 1 = 4.03357 loss)
I0623 05:54:15.602490 13672 sgd_solver.cpp:138] Iteration 4580, lr = 0.001
I0623 05:57:39.476825 13672 solver.cpp:243] Iteration 4590, loss = 5.09975
I0623 05:57:39.476825 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.38139 (* 1 = 7.38139 loss)
I0623 05:57:39.476825 13672 sgd_solver.cpp:138] Iteration 4590, lr = 0.001
I0623 06:00:49.573127 13672 solver.cpp:243] Iteration 4600, loss = 4.8137
I0623 06:00:49.573127 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.7779 (* 1 = 3.7779 loss)
I0623 06:00:49.573127 13672 sgd_solver.cpp:138] Iteration 4600, lr = 0.001
I0623 06:04:00.122450 13672 solver.cpp:243] Iteration 4610, loss = 5.24822
I0623 06:04:00.122450 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.12823 (* 1 = 3.12823 loss)
I0623 06:04:00.122450 13672 sgd_solver.cpp:138] Iteration 4610, lr = 0.001
I0623 06:07:12.296473 13672 solver.cpp:243] Iteration 4620, loss = 4.41342
I0623 06:07:12.296473 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.16073 (* 1 = 3.16073 loss)
I0623 06:07:12.296473 13672 sgd_solver.cpp:138] Iteration 4620, lr = 0.001
I0623 06:10:29.266211 13672 solver.cpp:243] Iteration 4630, loss = 4.39478
I0623 06:10:29.266211 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.87553 (* 1 = 5.87553 loss)
I0623 06:10:29.266211 13672 sgd_solver.cpp:138] Iteration 4630, lr = 0.001
I0623 06:13:36.878720 13672 solver.cpp:243] Iteration 4640, loss = 4.38996
I0623 06:13:36.878720 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.90545 (* 1 = 5.90545 loss)
I0623 06:13:36.878720 13672 sgd_solver.cpp:138] Iteration 4640, lr = 0.001
I0623 06:16:44.585086 13672 solver.cpp:243] Iteration 4650, loss = 3.99682
I0623 06:16:44.585086 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.86725 (* 1 = 4.86725 loss)
I0623 06:16:44.585086 13672 sgd_solver.cpp:138] Iteration 4650, lr = 0.001
I0623 06:19:55.618746 13672 solver.cpp:243] Iteration 4660, loss = 4.40299
I0623 06:19:55.618746 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.66232 (* 1 = 3.66232 loss)
I0623 06:19:55.618746 13672 sgd_solver.cpp:138] Iteration 4660, lr = 0.001
I0623 06:23:12.963394 13672 solver.cpp:243] Iteration 4670, loss = 4.45069
I0623 06:23:12.963394 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.48051 (* 1 = 6.48051 loss)
I0623 06:23:12.963394 13672 sgd_solver.cpp:138] Iteration 4670, lr = 0.001
I0623 06:26:39.071591 13672 solver.cpp:243] Iteration 4680, loss = 3.91615
I0623 06:26:39.071591 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.69371 (* 1 = 2.69371 loss)
I0623 06:26:39.071591 13672 sgd_solver.cpp:138] Iteration 4680, lr = 0.001
I0623 06:28:49.541129 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0623 06:29:46.027961 13672 solver.cpp:243] Iteration 4690, loss = 3.67457
I0623 06:29:46.027961 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.58926 (* 1 = 1.58926 loss)
I0623 06:29:46.027961 13672 sgd_solver.cpp:138] Iteration 4690, lr = 0.001
I0623 06:33:21.712157 13672 solver.cpp:243] Iteration 4700, loss = 4.02822
I0623 06:33:21.712157 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.52618 (* 1 = 8.52618 loss)
I0623 06:33:21.712157 13672 sgd_solver.cpp:138] Iteration 4700, lr = 0.001
I0623 06:36:26.450307 13672 solver.cpp:243] Iteration 4710, loss = 4.24058
I0623 06:36:26.450307 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.71389 (* 1 = 4.71389 loss)
I0623 06:36:26.450307 13672 sgd_solver.cpp:138] Iteration 4710, lr = 0.001
I0623 06:39:33.641034 13672 solver.cpp:243] Iteration 4720, loss = 4.10126
I0623 06:39:33.641034 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.58692 (* 1 = 3.58692 loss)
I0623 06:39:33.641034 13672 sgd_solver.cpp:138] Iteration 4720, lr = 0.001
I0623 06:42:41.565966 13672 solver.cpp:243] Iteration 4730, loss = 4.26318
I0623 06:42:41.565966 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.63203 (* 1 = 1.63203 loss)
I0623 06:42:41.565966 13672 sgd_solver.cpp:138] Iteration 4730, lr = 0.001
I0623 06:45:50.928066 13672 solver.cpp:243] Iteration 4740, loss = 4.10563
I0623 06:45:50.928066 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.72441 (* 1 = 1.72441 loss)
I0623 06:45:50.928066 13672 sgd_solver.cpp:138] Iteration 4740, lr = 0.001
I0623 06:48:58.320792 13672 solver.cpp:243] Iteration 4750, loss = 4.11504
I0623 06:48:58.320792 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.01551 (* 1 = 4.01551 loss)
I0623 06:48:58.320792 13672 sgd_solver.cpp:138] Iteration 4750, lr = 0.001
I0623 06:52:21.289139 13672 solver.cpp:243] Iteration 4760, loss = 3.82838
I0623 06:52:21.289139 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.51756 (* 1 = 4.51756 loss)
I0623 06:52:21.289139 13672 sgd_solver.cpp:138] Iteration 4760, lr = 0.001
I0623 06:57:26.580406 13672 solver.cpp:243] Iteration 4770, loss = 3.93247
I0623 06:57:26.603624 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.01876 (* 1 = 2.01876 loss)
I0623 06:57:26.636451 13672 sgd_solver.cpp:138] Iteration 4770, lr = 0.001
I0623 07:01:55.582157 13672 solver.cpp:243] Iteration 4780, loss = 3.92886
I0623 07:01:55.582157 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.82392 (* 1 = 2.82392 loss)
I0623 07:01:55.582157 13672 sgd_solver.cpp:138] Iteration 4780, lr = 0.001
I0623 07:06:05.866267 13672 solver.cpp:243] Iteration 4790, loss = 4.08249
I0623 07:06:05.866267 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.85315 (* 1 = 6.85315 loss)
I0623 07:06:05.866267 13672 sgd_solver.cpp:138] Iteration 4790, lr = 0.001
I0623 07:10:08.841358 13672 solver.cpp:243] Iteration 4800, loss = 4.17269
I0623 07:10:08.841358 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.28535 (* 1 = 7.28535 loss)
I0623 07:10:08.841358 13672 sgd_solver.cpp:138] Iteration 4800, lr = 0.001
I0623 07:14:23.764814 13672 solver.cpp:243] Iteration 4810, loss = 3.86555
I0623 07:14:23.764814 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.34898 (* 1 = 5.34898 loss)
I0623 07:14:23.764814 13672 sgd_solver.cpp:138] Iteration 4810, lr = 0.001
I0623 07:18:54.687093 13672 solver.cpp:243] Iteration 4820, loss = 3.92222
I0623 07:18:54.687093 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.63219 (* 1 = 4.63219 loss)
I0623 07:18:54.687093 13672 sgd_solver.cpp:138] Iteration 4820, lr = 0.001
I0623 07:22:10.677397 13672 solver.cpp:243] Iteration 4830, loss = 3.99796
I0623 07:22:10.677397 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.1059 (* 1 = 3.1059 loss)
I0623 07:22:10.677397 13672 sgd_solver.cpp:138] Iteration 4830, lr = 0.001
I0623 07:25:28.037714 13672 solver.cpp:243] Iteration 4840, loss = 3.91418
I0623 07:25:28.037714 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.78037 (* 1 = 4.78037 loss)
I0623 07:25:28.037714 13672 sgd_solver.cpp:138] Iteration 4840, lr = 0.001
I0623 07:28:35.806514 13672 solver.cpp:243] Iteration 4850, loss = 3.87016
I0623 07:28:35.806514 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.16655 (* 1 = 1.16655 loss)
I0623 07:28:35.806514 13672 sgd_solver.cpp:138] Iteration 4850, lr = 0.001
I0623 07:31:49.698942 13672 solver.cpp:243] Iteration 4860, loss = 4.13391
I0623 07:31:49.698942 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.55627 (* 1 = 4.55627 loss)
I0623 07:31:49.698942 13672 sgd_solver.cpp:138] Iteration 4860, lr = 0.001
I0623 07:35:02.997622 13672 solver.cpp:243] Iteration 4870, loss = 4.06904
I0623 07:35:02.997622 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.92777 (* 1 = 2.92777 loss)
I0623 07:35:02.997622 13672 sgd_solver.cpp:138] Iteration 4870, lr = 0.001
I0623 07:38:09.735370 13672 solver.cpp:243] Iteration 4880, loss = 3.75864
I0623 07:38:09.735370 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.22895 (* 1 = 4.22895 loss)
I0623 07:38:09.735370 13672 sgd_solver.cpp:138] Iteration 4880, lr = 0.001
I0623 07:41:17.527524 13672 solver.cpp:243] Iteration 4890, loss = 3.90772
I0623 07:41:17.527524 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.41288 (* 1 = 6.41288 loss)
I0623 07:41:17.527524 13672 sgd_solver.cpp:138] Iteration 4890, lr = 0.001
I0623 07:44:27.641237 13672 solver.cpp:243] Iteration 4900, loss = 3.90102
I0623 07:44:27.656858 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.38703 (* 1 = 4.38703 loss)
I0623 07:44:27.656858 13672 sgd_solver.cpp:138] Iteration 4900, lr = 0.001
I0623 07:47:40.857640 13672 solver.cpp:243] Iteration 4910, loss = 4.02375
I0623 07:47:40.857640 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.63543 (* 1 = 4.63543 loss)
I0623 07:47:40.857640 13672 sgd_solver.cpp:138] Iteration 4910, lr = 0.001
I0623 07:50:53.672057 13672 solver.cpp:243] Iteration 4920, loss = 3.8571
I0623 07:50:53.672057 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.80211 (* 1 = 5.80211 loss)
I0623 07:50:53.672057 13672 sgd_solver.cpp:138] Iteration 4920, lr = 0.001
I0623 07:54:15.281406 13672 solver.cpp:243] Iteration 4930, loss = 3.92824
I0623 07:54:15.281406 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.25308 (* 1 = 3.25308 loss)
I0623 07:54:15.281406 13672 sgd_solver.cpp:138] Iteration 4930, lr = 0.001
I0623 07:57:29.142457 13672 solver.cpp:243] Iteration 4940, loss = 3.85381
I0623 07:57:29.142457 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.39499 (* 1 = 4.39499 loss)
I0623 07:57:29.142457 13672 sgd_solver.cpp:138] Iteration 4940, lr = 0.001
I0623 08:01:00.609114 13672 solver.cpp:243] Iteration 4950, loss = 4.11556
I0623 08:01:00.609114 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.1197 (* 1 = 3.1197 loss)
I0623 08:01:00.609114 13672 sgd_solver.cpp:138] Iteration 4950, lr = 0.001
I0623 08:04:09.627517 13672 solver.cpp:243] Iteration 4960, loss = 3.85141
I0623 08:04:09.627517 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.86366 (* 1 = 3.86366 loss)
I0623 08:04:09.627517 13672 sgd_solver.cpp:138] Iteration 4960, lr = 0.001
I0623 08:07:23.176100 13672 solver.cpp:243] Iteration 4970, loss = 3.97077
I0623 08:07:23.176100 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.43115 (* 1 = 2.43115 loss)
I0623 08:07:23.176100 13672 sgd_solver.cpp:138] Iteration 4970, lr = 0.001
I0623 08:10:39.568118 13672 solver.cpp:243] Iteration 4980, loss = 3.99605
I0623 08:10:39.568118 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.21652 (* 1 = 2.21652 loss)
I0623 08:10:39.568118 13672 sgd_solver.cpp:138] Iteration 4980, lr = 0.001
I0623 08:14:03.801709 13672 solver.cpp:243] Iteration 4990, loss = 3.79789
I0623 08:14:03.801709 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.54792 (* 1 = 2.54792 loss)
I0623 08:14:03.801709 13672 sgd_solver.cpp:138] Iteration 4990, lr = 0.001
I0623 08:17:18.718209 13672 solver.cpp:243] Iteration 5000, loss = 3.92833
I0623 08:17:18.718209 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.41148 (* 1 = 2.41148 loss)
I0623 08:17:18.718209 13672 sgd_solver.cpp:138] Iteration 5000, lr = 0.001
I0623 08:20:28.439558 13672 solver.cpp:243] Iteration 5010, loss = 4.25623
I0623 08:20:28.439558 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.43531 (* 1 = 6.43531 loss)
I0623 08:20:28.439558 13672 sgd_solver.cpp:138] Iteration 5010, lr = 0.001
I0623 08:23:52.954419 13672 solver.cpp:243] Iteration 5020, loss = 4.39581
I0623 08:23:52.954419 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.00428 (* 1 = 2.00428 loss)
I0623 08:23:52.954419 13672 sgd_solver.cpp:138] Iteration 5020, lr = 0.001
I0623 08:26:57.442657 13672 solver.cpp:243] Iteration 5030, loss = 4.07209
I0623 08:26:57.442657 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.39061 (* 1 = 1.39061 loss)
I0623 08:26:57.442657 13672 sgd_solver.cpp:138] Iteration 5030, lr = 0.001
I0623 08:30:15.193410 13672 solver.cpp:243] Iteration 5040, loss = 4.66424
I0623 08:30:15.193410 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.91436 (* 1 = 7.91436 loss)
I0623 08:30:15.193410 13672 sgd_solver.cpp:138] Iteration 5040, lr = 0.001
I0623 08:33:26.789327 13672 solver.cpp:243] Iteration 5050, loss = 4.06265
I0623 08:33:26.789327 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.3924 (* 1 = 4.3924 loss)
I0623 08:33:26.789327 13672 sgd_solver.cpp:138] Iteration 5050, lr = 0.001
I0623 08:36:34.698724 13672 solver.cpp:243] Iteration 5060, loss = 3.85101
I0623 08:36:34.698724 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.04484 (* 1 = 4.04484 loss)
I0623 08:36:34.698724 13672 sgd_solver.cpp:138] Iteration 5060, lr = 0.001
I0623 08:39:58.822965 13672 solver.cpp:243] Iteration 5070, loss = 3.97996
I0623 08:39:58.822965 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.77531 (* 1 = 2.77531 loss)
I0623 08:39:58.822965 13672 sgd_solver.cpp:138] Iteration 5070, lr = 0.001
I0623 08:43:17.011132 13672 solver.cpp:243] Iteration 5080, loss = 3.91563
I0623 08:43:17.011132 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.69591 (* 1 = 3.69591 loss)
I0623 08:43:17.011132 13672 sgd_solver.cpp:138] Iteration 5080, lr = 0.001
I0623 08:46:31.950999 13672 solver.cpp:243] Iteration 5090, loss = 3.73302
I0623 08:46:31.950999 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.982308 (* 1 = 0.982308 loss)
I0623 08:46:31.950999 13672 sgd_solver.cpp:138] Iteration 5090, lr = 0.001
I0623 08:49:46.811810 13672 solver.cpp:243] Iteration 5100, loss = 3.82212
I0623 08:49:46.811810 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.23529 (* 1 = 2.23529 loss)
I0623 08:49:46.811810 13672 sgd_solver.cpp:138] Iteration 5100, lr = 0.001
I0623 08:53:13.388633 13672 solver.cpp:243] Iteration 5110, loss = 3.82737
I0623 08:53:13.388633 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.03987 (* 1 = 2.03987 loss)
I0623 08:53:13.388633 13672 sgd_solver.cpp:138] Iteration 5110, lr = 0.001
I0623 08:56:26.624832 13672 solver.cpp:243] Iteration 5120, loss = 4.11827
I0623 08:56:26.624832 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.24418 (* 1 = 2.24418 loss)
I0623 08:56:26.624832 13672 sgd_solver.cpp:138] Iteration 5120, lr = 0.001
I0623 08:59:42.532356 13672 solver.cpp:243] Iteration 5130, loss = 3.87046
I0623 08:59:42.532356 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.25145 (* 1 = 4.25145 loss)
I0623 08:59:42.532356 13672 sgd_solver.cpp:138] Iteration 5130, lr = 0.001
I0623 09:03:00.767506 13672 solver.cpp:243] Iteration 5140, loss = 3.86966
I0623 09:03:00.767506 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.48996 (* 1 = 5.48996 loss)
I0623 09:03:00.767506 13672 sgd_solver.cpp:138] Iteration 5140, lr = 0.001
I0623 09:06:17.659093 13672 solver.cpp:243] Iteration 5150, loss = 3.69017
I0623 09:06:17.659093 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.95202 (* 1 = 3.95202 loss)
I0623 09:06:17.659093 13672 sgd_solver.cpp:138] Iteration 5150, lr = 0.001
I0623 09:09:24.471550 13672 solver.cpp:243] Iteration 5160, loss = 3.84154
I0623 09:09:24.471550 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.12768 (* 1 = 5.12768 loss)
I0623 09:09:24.471550 13672 sgd_solver.cpp:138] Iteration 5160, lr = 0.001
I0623 09:12:45.580920 13672 solver.cpp:243] Iteration 5170, loss = 4.05998
I0623 09:12:45.580920 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.0762 (* 1 = 11.0762 loss)
I0623 09:12:45.580920 13672 sgd_solver.cpp:138] Iteration 5170, lr = 0.001
I0623 09:16:01.519623 13672 solver.cpp:243] Iteration 5180, loss = 4.07229
I0623 09:16:01.519623 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.95645 (* 1 = 4.95645 loss)
I0623 09:16:01.519623 13672 sgd_solver.cpp:138] Iteration 5180, lr = 0.001
I0623 09:19:12.584450 13672 solver.cpp:243] Iteration 5190, loss = 3.93797
I0623 09:19:12.584450 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.74544 (* 1 = 4.74544 loss)
I0623 09:19:12.584450 13672 sgd_solver.cpp:138] Iteration 5190, lr = 0.001
I0623 09:22:44.972466 13672 solver.cpp:243] Iteration 5200, loss = 3.99999
I0623 09:22:44.972466 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.94253 (* 1 = 1.94253 loss)
I0623 09:22:44.972466 13672 sgd_solver.cpp:138] Iteration 5200, lr = 0.001
I0623 09:25:53.881547 13672 solver.cpp:243] Iteration 5210, loss = 4.05872
I0623 09:25:53.881547 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.82092 (* 1 = 3.82092 loss)
I0623 09:25:53.881547 13672 sgd_solver.cpp:138] Iteration 5210, lr = 0.001
I0623 09:29:03.649761 13672 solver.cpp:243] Iteration 5220, loss = 4.1829
I0623 09:29:03.649761 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.91192 (* 1 = 1.91192 loss)
I0623 09:29:03.649761 13672 sgd_solver.cpp:138] Iteration 5220, lr = 0.001
I0623 09:32:27.039839 13672 solver.cpp:243] Iteration 5230, loss = 4.17333
I0623 09:32:27.039839 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.87233 (* 1 = 3.87233 loss)
I0623 09:32:27.039839 13672 sgd_solver.cpp:138] Iteration 5230, lr = 0.001
I0623 09:35:41.432013 13672 solver.cpp:243] Iteration 5240, loss = 4.0396
I0623 09:35:41.432013 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.1456 (* 1 = 2.1456 loss)
I0623 09:35:41.432013 13672 sgd_solver.cpp:138] Iteration 5240, lr = 0.001
I0623 09:38:47.919785 13672 solver.cpp:243] Iteration 5250, loss = 3.88133
I0623 09:38:47.919785 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.74995 (* 1 = 2.74995 loss)
I0623 09:38:47.919785 13672 sgd_solver.cpp:138] Iteration 5250, lr = 0.001
I0623 09:42:05.858039 13672 solver.cpp:243] Iteration 5260, loss = 3.79454
I0623 09:42:05.858039 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.20932 (* 1 = 5.20932 loss)
I0623 09:42:05.858039 13672 sgd_solver.cpp:138] Iteration 5260, lr = 0.001
I0623 09:45:53.664412 13672 solver.cpp:243] Iteration 5270, loss = 3.8941
I0623 09:45:53.742669 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.26313 (* 1 = 2.26313 loss)
I0623 09:45:53.773614 13672 sgd_solver.cpp:138] Iteration 5270, lr = 0.001
I0623 09:49:03.807430 13672 solver.cpp:243] Iteration 5280, loss = 3.63072
I0623 09:49:03.807430 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.85354 (* 1 = 1.85354 loss)
I0623 09:49:03.807430 13672 sgd_solver.cpp:138] Iteration 5280, lr = 0.001
I0623 09:52:11.637338 13672 solver.cpp:243] Iteration 5290, loss = 4.17759
I0623 09:52:11.637338 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.54929 (* 1 = 7.54929 loss)
I0623 09:52:11.637338 13672 sgd_solver.cpp:138] Iteration 5290, lr = 0.001
I0623 09:55:28.357100 13672 solver.cpp:243] Iteration 5300, loss = 3.96853
I0623 09:55:28.357100 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.56195 (* 1 = 7.56195 loss)
I0623 09:55:28.357100 13672 sgd_solver.cpp:138] Iteration 5300, lr = 0.001
I0623 09:58:34.411370 13672 solver.cpp:243] Iteration 5310, loss = 4.21177
I0623 09:58:34.411370 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.47465 (* 1 = 4.47465 loss)
I0623 09:58:34.411370 13672 sgd_solver.cpp:138] Iteration 5310, lr = 0.001
I0623 10:01:56.098718 13672 solver.cpp:243] Iteration 5320, loss = 4.18995
I0623 10:01:56.098718 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.07065 (* 1 = 5.07065 loss)
I0623 10:01:56.098718 13672 sgd_solver.cpp:138] Iteration 5320, lr = 0.001
I0623 10:05:21.566399 13672 solver.cpp:243] Iteration 5330, loss = 4.50436
I0623 10:05:21.566399 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.42796 (* 1 = 5.42796 loss)
I0623 10:05:21.566399 13672 sgd_solver.cpp:138] Iteration 5330, lr = 0.001
I0623 10:08:29.100931 13672 solver.cpp:243] Iteration 5340, loss = 4.39223
I0623 10:08:29.100931 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0623 10:08:29.100931 13672 sgd_solver.cpp:138] Iteration 5340, lr = 0.001
I0623 10:09:29.649319 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0623 10:11:51.741187 13672 solver.cpp:243] Iteration 5350, loss = 4.48745
I0623 10:11:51.741187 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.98245 (* 1 = 2.98245 loss)
I0623 10:11:51.756942 13672 sgd_solver.cpp:138] Iteration 5350, lr = 0.001
I0623 10:15:09.205835 13672 solver.cpp:243] Iteration 5360, loss = 4.77077
I0623 10:15:09.205835 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.21491 (* 1 = 3.21491 loss)
I0623 10:15:09.205835 13672 sgd_solver.cpp:138] Iteration 5360, lr = 0.001
I0623 10:18:23.691740 13672 solver.cpp:243] Iteration 5370, loss = 4.38455
I0623 10:18:23.691740 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.63943 (* 1 = 1.63943 loss)
I0623 10:18:23.691740 13672 sgd_solver.cpp:138] Iteration 5370, lr = 0.001
I0623 10:21:40.090521 13672 solver.cpp:243] Iteration 5380, loss = 4.28246
I0623 10:21:40.090521 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.68905 (* 1 = 4.68905 loss)
I0623 10:21:40.090521 13672 sgd_solver.cpp:138] Iteration 5380, lr = 0.001
I0623 10:25:04.183565 13672 solver.cpp:243] Iteration 5390, loss = 4.42742
I0623 10:25:04.183565 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.1559 (* 1 = 10.1559 loss)
I0623 10:25:04.183565 13672 sgd_solver.cpp:138] Iteration 5390, lr = 0.001
I0623 10:28:27.417428 13672 solver.cpp:243] Iteration 5400, loss = 4.29321
I0623 10:28:27.433050 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.00949 (* 1 = 5.00949 loss)
I0623 10:28:27.448709 13672 sgd_solver.cpp:138] Iteration 5400, lr = 0.001
I0623 10:31:39.732002 13672 solver.cpp:243] Iteration 5410, loss = 4.00373
I0623 10:31:39.732002 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.23991 (* 1 = 4.23991 loss)
I0623 10:31:39.732002 13672 sgd_solver.cpp:138] Iteration 5410, lr = 0.001
I0623 10:35:08.527240 13672 solver.cpp:243] Iteration 5420, loss = 4.75984
I0623 10:35:08.542858 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.40659 (* 1 = 8.40659 loss)
I0623 10:35:08.542858 13672 sgd_solver.cpp:138] Iteration 5420, lr = 0.001
I0623 10:38:25.887264 13672 solver.cpp:243] Iteration 5430, loss = 4.3118
I0623 10:38:25.887264 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.56072 (* 1 = 6.56072 loss)
I0623 10:38:25.887264 13672 sgd_solver.cpp:138] Iteration 5430, lr = 0.001
I0623 10:41:40.435653 13672 solver.cpp:243] Iteration 5440, loss = 4.27573
I0623 10:41:40.435653 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.82168 (* 1 = 9.82168 loss)
I0623 10:41:40.435653 13672 sgd_solver.cpp:138] Iteration 5440, lr = 0.001
I0623 10:45:00.560897 13672 solver.cpp:243] Iteration 5450, loss = 4.71893
I0623 10:45:00.560897 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.9287 (* 1 = 1.9287 loss)
I0623 10:45:00.560897 13672 sgd_solver.cpp:138] Iteration 5450, lr = 0.001
I0623 10:48:14.062623 13672 solver.cpp:243] Iteration 5460, loss = 4.17893
I0623 10:48:14.062623 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.0935 (* 1 = 17.0935 loss)
I0623 10:48:14.062623 13672 sgd_solver.cpp:138] Iteration 5460, lr = 0.001
I0623 10:51:23.346652 13672 solver.cpp:243] Iteration 5470, loss = 4.00973
I0623 10:51:23.346652 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.42638 (* 1 = 2.42638 loss)
I0623 10:51:23.346652 13672 sgd_solver.cpp:138] Iteration 5470, lr = 0.001
I0623 10:54:38.176189 13672 solver.cpp:243] Iteration 5480, loss = 3.99227
I0623 10:54:38.176189 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.69419 (* 1 = 2.69419 loss)
I0623 10:54:38.176189 13672 sgd_solver.cpp:138] Iteration 5480, lr = 0.001
I0623 10:57:50.709424 13672 solver.cpp:243] Iteration 5490, loss = 3.9791
I0623 10:57:50.709424 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.50794 (* 1 = 1.50794 loss)
I0623 10:57:50.709424 13672 sgd_solver.cpp:138] Iteration 5490, lr = 0.001
I0623 11:01:09.569533 13672 solver.cpp:243] Iteration 5500, loss = 4.08996
I0623 11:01:09.569533 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.70454 (* 1 = 2.70454 loss)
I0623 11:01:09.569533 13672 sgd_solver.cpp:138] Iteration 5500, lr = 0.001
I0623 11:04:15.385582 13672 solver.cpp:243] Iteration 5510, loss = 3.99695
I0623 11:04:15.385582 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.35302 (* 1 = 3.35302 loss)
I0623 11:04:15.385582 13672 sgd_solver.cpp:138] Iteration 5510, lr = 0.001
I0623 11:07:27.840744 13672 solver.cpp:243] Iteration 5520, loss = 3.96835
I0623 11:07:27.840744 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.1329 (* 1 = 1.1329 loss)
I0623 11:07:27.840744 13672 sgd_solver.cpp:138] Iteration 5520, lr = 0.001
I0623 11:10:38.671306 13672 solver.cpp:243] Iteration 5530, loss = 3.62585
I0623 11:10:38.671306 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.4695 (* 1 = 2.4695 loss)
I0623 11:10:38.671306 13672 sgd_solver.cpp:138] Iteration 5530, lr = 0.001
I0623 11:28:38.677913 13672 solver.cpp:243] Iteration 5540, loss = 3.87872
I0623 11:28:38.677913 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.70763 (* 1 = 5.70763 loss)
I0623 11:28:38.677913 13672 sgd_solver.cpp:138] Iteration 5540, lr = 0.001
I0623 11:31:44.650172 13672 solver.cpp:243] Iteration 5550, loss = 3.84297
I0623 11:31:44.650172 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.11291 (* 1 = 6.11291 loss)
I0623 11:31:44.650172 13672 sgd_solver.cpp:138] Iteration 5550, lr = 0.001
I0623 11:35:04.440237 13672 solver.cpp:243] Iteration 5560, loss = 3.95655
I0623 11:35:04.440237 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.27369 (* 1 = 3.27369 loss)
I0623 11:35:04.440237 13672 sgd_solver.cpp:138] Iteration 5560, lr = 0.001
I0623 11:38:17.379613 13672 solver.cpp:243] Iteration 5570, loss = 4.01864
I0623 11:38:17.379613 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.78091 (* 1 = 3.78091 loss)
I0623 11:38:17.379613 13672 sgd_solver.cpp:138] Iteration 5570, lr = 0.001
I0623 11:41:31.084452 13672 solver.cpp:243] Iteration 5580, loss = 4.07228
I0623 11:41:31.084452 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.60036 (* 1 = 4.60036 loss)
I0623 11:41:31.084452 13672 sgd_solver.cpp:138] Iteration 5580, lr = 0.001
I0623 11:44:50.912865 13672 solver.cpp:243] Iteration 5590, loss = 3.86237
I0623 11:44:50.912865 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.05021 (* 1 = 5.05021 loss)
I0623 11:44:50.912865 13672 sgd_solver.cpp:138] Iteration 5590, lr = 0.001
I0623 11:48:09.148970 13672 solver.cpp:243] Iteration 5600, loss = 3.8388
I0623 11:48:09.148970 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.15063 (* 1 = 2.15063 loss)
I0623 11:48:09.148970 13672 sgd_solver.cpp:138] Iteration 5600, lr = 0.001
I0623 11:51:22.494518 13672 solver.cpp:243] Iteration 5610, loss = 3.79267
I0623 11:51:22.494518 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.7502 (* 1 = 1.7502 loss)
I0623 11:51:22.494518 13672 sgd_solver.cpp:138] Iteration 5610, lr = 0.001
I0623 11:54:37.089723 13672 solver.cpp:243] Iteration 5620, loss = 3.788
I0623 11:54:37.089723 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.71669 (* 1 = 2.71669 loss)
I0623 11:54:37.089723 13672 sgd_solver.cpp:138] Iteration 5620, lr = 0.001
I0623 11:57:44.952222 13672 solver.cpp:243] Iteration 5630, loss = 3.85035
I0623 11:57:44.952222 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.81058 (* 1 = 5.81058 loss)
I0623 11:57:44.952222 13672 sgd_solver.cpp:138] Iteration 5630, lr = 0.001
I0623 12:01:02.281229 13672 solver.cpp:243] Iteration 5640, loss = 3.62381
I0623 12:01:02.281229 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.29407 (* 1 = 7.29407 loss)
I0623 12:01:02.281229 13672 sgd_solver.cpp:138] Iteration 5640, lr = 0.001
I0623 12:04:10.268582 13672 solver.cpp:243] Iteration 5650, loss = 3.61296
I0623 12:04:10.268582 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.96247 (* 1 = 2.96247 loss)
I0623 12:04:10.268582 13672 sgd_solver.cpp:138] Iteration 5650, lr = 0.001
I0623 12:07:30.456306 13672 solver.cpp:243] Iteration 5660, loss = 3.65848
I0623 12:07:30.456306 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.59116 (* 1 = 5.59116 loss)
I0623 12:07:30.456306 13672 sgd_solver.cpp:138] Iteration 5660, lr = 0.001
I0623 12:10:51.206348 13672 solver.cpp:243] Iteration 5670, loss = 4.02645
I0623 12:10:51.206348 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.48941 (* 1 = 4.48941 loss)
I0623 12:10:51.206348 13672 sgd_solver.cpp:138] Iteration 5670, lr = 0.001
I0623 12:14:10.108455 13672 solver.cpp:243] Iteration 5680, loss = 3.76734
I0623 12:14:10.108455 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.5216 (* 1 = 4.5216 loss)
I0623 12:14:10.108455 13672 sgd_solver.cpp:138] Iteration 5680, lr = 0.001
I0623 12:17:20.876485 13672 solver.cpp:243] Iteration 5690, loss = 3.74106
I0623 12:17:20.876485 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.95913 (* 1 = 2.95913 loss)
I0623 12:17:20.876485 13672 sgd_solver.cpp:138] Iteration 5690, lr = 0.001
I0623 12:20:47.094204 13672 solver.cpp:243] Iteration 5700, loss = 3.84046
I0623 12:20:47.094204 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.29625 (* 1 = 2.29625 loss)
I0623 12:20:47.094204 13672 sgd_solver.cpp:138] Iteration 5700, lr = 0.001
I0623 12:24:10.037824 13672 solver.cpp:243] Iteration 5710, loss = 3.89287
I0623 12:24:10.037824 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.65965 (* 1 = 3.65965 loss)
I0623 12:24:10.037824 13672 sgd_solver.cpp:138] Iteration 5710, lr = 0.001
I0623 12:27:30.694165 13672 solver.cpp:243] Iteration 5720, loss = 4.10133
I0623 12:27:30.694165 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.32519 (* 1 = 3.32519 loss)
I0623 12:27:30.694165 13672 sgd_solver.cpp:138] Iteration 5720, lr = 0.001
I0623 12:30:54.453007 13672 solver.cpp:243] Iteration 5730, loss = 3.76954
I0623 12:30:54.453007 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.12923 (* 1 = 3.12923 loss)
I0623 12:30:54.453007 13672 sgd_solver.cpp:138] Iteration 5730, lr = 0.001
I0623 12:35:11.317198 13672 solver.cpp:243] Iteration 5740, loss = 3.755
I0623 12:35:11.317198 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0623 12:35:11.317198 13672 sgd_solver.cpp:138] Iteration 5740, lr = 0.001
I0623 12:39:03.522460 13672 solver.cpp:243] Iteration 5750, loss = 3.8571
I0623 12:39:03.522460 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.00194 (* 1 = 1.00194 loss)
I0623 12:39:03.522460 13672 sgd_solver.cpp:138] Iteration 5750, lr = 0.001
I0623 12:43:18.768307 13672 solver.cpp:243] Iteration 5760, loss = 3.70999
I0623 12:43:18.768307 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.87361 (* 1 = 6.87361 loss)
I0623 12:43:18.768307 13672 sgd_solver.cpp:138] Iteration 5760, lr = 0.001
I0623 12:48:34.588680 13672 solver.cpp:243] Iteration 5770, loss = 3.7419
I0623 12:48:34.597787 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.65209 (* 1 = 2.65209 loss)
I0623 12:48:34.603055 13672 sgd_solver.cpp:138] Iteration 5770, lr = 0.001
I0623 12:52:32.100780 13672 solver.cpp:243] Iteration 5780, loss = 3.45086
I0623 12:52:32.100780 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.36555 (* 1 = 1.36555 loss)
I0623 12:52:32.100780 13672 sgd_solver.cpp:138] Iteration 5780, lr = 0.001
I0623 12:57:01.430030 13672 solver.cpp:243] Iteration 5790, loss = 3.80122
I0623 12:57:01.430030 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.44848 (* 1 = 6.44848 loss)
I0623 12:57:01.430030 13672 sgd_solver.cpp:138] Iteration 5790, lr = 0.001
I0623 13:00:11.749989 13672 solver.cpp:243] Iteration 5800, loss = 3.37045
I0623 13:00:11.749989 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.12898 (* 1 = 5.12898 loss)
I0623 13:00:11.749989 13672 sgd_solver.cpp:138] Iteration 5800, lr = 0.001
I0623 13:03:24.251983 13672 solver.cpp:243] Iteration 5810, loss = 3.53747
I0623 13:03:24.251983 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.88336 (* 1 = 4.88336 loss)
I0623 13:03:24.251983 13672 sgd_solver.cpp:138] Iteration 5810, lr = 0.001
I0623 13:06:47.751406 13672 solver.cpp:243] Iteration 5820, loss = 3.67892
I0623 13:06:47.751406 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.48637 (* 1 = 2.48637 loss)
I0623 13:06:47.751406 13672 sgd_solver.cpp:138] Iteration 5820, lr = 0.001
I0623 13:10:04.971045 13672 solver.cpp:243] Iteration 5830, loss = 4.00719
I0623 13:10:04.971045 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.8113 (* 1 = 3.8113 loss)
I0623 13:10:04.971045 13672 sgd_solver.cpp:138] Iteration 5830, lr = 0.001
I0623 13:13:17.348079 13672 solver.cpp:243] Iteration 5840, loss = 3.61088
I0623 13:13:17.348079 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.19754 (* 1 = 2.19754 loss)
I0623 13:13:17.348079 13672 sgd_solver.cpp:138] Iteration 5840, lr = 0.001
I0623 13:16:26.272768 13672 solver.cpp:243] Iteration 5850, loss = 3.68708
I0623 13:16:26.272768 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.3099 (* 1 = 4.3099 loss)
I0623 13:16:26.272768 13672 sgd_solver.cpp:138] Iteration 5850, lr = 0.001
I0623 13:19:51.303084 13672 solver.cpp:243] Iteration 5860, loss = 3.59665
I0623 13:19:51.303084 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.51201 (* 1 = 3.51201 loss)
I0623 13:19:51.303084 13672 sgd_solver.cpp:138] Iteration 5860, lr = 0.001
I0623 13:23:00.212168 13672 solver.cpp:243] Iteration 5870, loss = 3.7726
I0623 13:23:00.212168 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.86061 (* 1 = 3.86061 loss)
I0623 13:23:00.212168 13672 sgd_solver.cpp:138] Iteration 5870, lr = 0.001
I0623 13:26:18.822126 13672 solver.cpp:243] Iteration 5880, loss = 3.95391
I0623 13:26:18.915838 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.86924 (* 1 = 4.86924 loss)
I0623 13:26:18.915838 13672 sgd_solver.cpp:138] Iteration 5880, lr = 0.001
I0623 13:29:32.839385 13672 solver.cpp:243] Iteration 5890, loss = 3.6472
I0623 13:29:32.839385 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.27898 (* 1 = 4.27898 loss)
I0623 13:29:32.839385 13672 sgd_solver.cpp:138] Iteration 5890, lr = 0.001
I0623 13:33:22.035897 13672 solver.cpp:243] Iteration 5900, loss = 3.60744
I0623 13:33:22.051517 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.06096 (* 1 = 4.06096 loss)
I0623 13:33:22.067142 13672 sgd_solver.cpp:138] Iteration 5900, lr = 0.001
I0623 13:36:28.742360 13672 solver.cpp:243] Iteration 5910, loss = 3.80045
I0623 13:36:28.742360 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.28547 (* 1 = 6.28547 loss)
I0623 13:36:28.742360 13672 sgd_solver.cpp:138] Iteration 5910, lr = 0.001
I0623 13:39:43.884405 13672 solver.cpp:243] Iteration 5920, loss = 4.06421
I0623 13:39:43.884405 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.71582 (* 1 = 6.71582 loss)
I0623 13:39:43.884405 13672 sgd_solver.cpp:138] Iteration 5920, lr = 0.001
I0623 13:43:01.322700 13672 solver.cpp:243] Iteration 5930, loss = 3.82907
I0623 13:43:01.322700 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.01898 (* 1 = 5.01898 loss)
I0623 13:43:01.322700 13672 sgd_solver.cpp:138] Iteration 5930, lr = 0.001
I0623 13:46:06.028206 13672 solver.cpp:243] Iteration 5940, loss = 3.42062
I0623 13:46:06.028206 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.16854 (* 1 = 4.16854 loss)
I0623 13:46:06.028206 13672 sgd_solver.cpp:138] Iteration 5940, lr = 0.001
I0623 13:49:35.821269 13672 solver.cpp:243] Iteration 5950, loss = 3.75831
I0623 13:49:35.821269 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.2045 (* 1 = 1.2045 loss)
I0623 13:49:35.821269 13672 sgd_solver.cpp:138] Iteration 5950, lr = 0.001
I0623 13:52:53.263005 13672 solver.cpp:243] Iteration 5960, loss = 3.58822
I0623 13:52:53.263005 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.78312 (* 1 = 3.78312 loss)
I0623 13:52:53.263005 13672 sgd_solver.cpp:138] Iteration 5960, lr = 0.001
I0623 13:56:04.818210 13672 solver.cpp:243] Iteration 5970, loss = 3.88804
I0623 13:56:04.818210 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.88952 (* 1 = 3.88952 loss)
I0623 13:56:04.818210 13672 sgd_solver.cpp:138] Iteration 5970, lr = 0.001
I0623 13:59:25.802671 13672 solver.cpp:243] Iteration 5980, loss = 3.68279
I0623 13:59:25.802671 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.76107 (* 1 = 2.76107 loss)
I0623 13:59:25.802671 13672 sgd_solver.cpp:138] Iteration 5980, lr = 0.001
I0623 14:02:49.958122 13672 solver.cpp:243] Iteration 5990, loss = 3.65802
I0623 14:02:49.958122 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.73596 (* 1 = 1.73596 loss)
I0623 14:02:49.958122 13672 sgd_solver.cpp:138] Iteration 5990, lr = 0.001
I0623 14:06:03.991355 13672 solver.cpp:243] Iteration 6000, loss = 3.76735
I0623 14:06:03.991355 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.18236 (* 1 = 2.18236 loss)
I0623 14:06:03.991355 13672 sgd_solver.cpp:138] Iteration 6000, lr = 0.001
I0623 14:07:44.483551 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0623 14:09:16.961949 13672 solver.cpp:243] Iteration 6010, loss = 3.70022
I0623 14:09:16.961949 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.70174 (* 1 = 6.70174 loss)
I0623 14:09:16.961949 13672 sgd_solver.cpp:138] Iteration 6010, lr = 0.001
I0623 14:12:41.584766 13672 solver.cpp:243] Iteration 6020, loss = 3.79695
I0623 14:12:41.584766 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.74234 (* 1 = 2.74234 loss)
I0623 14:12:41.584766 13672 sgd_solver.cpp:138] Iteration 6020, lr = 0.001
I0623 14:15:56.123694 13672 solver.cpp:243] Iteration 6030, loss = 3.55962
I0623 14:15:56.123694 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.90975 (* 1 = 1.90975 loss)
I0623 14:15:56.123694 13672 sgd_solver.cpp:138] Iteration 6030, lr = 0.001
I0623 14:19:14.608705 13672 solver.cpp:243] Iteration 6040, loss = 3.74445
I0623 14:19:14.608705 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.7978 (* 1 = 4.7978 loss)
I0623 14:19:14.608705 13672 sgd_solver.cpp:138] Iteration 6040, lr = 0.001
I0623 14:22:32.343811 13672 solver.cpp:243] Iteration 6050, loss = 3.69239
I0623 14:22:32.343811 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.06591 (* 1 = 5.06591 loss)
I0623 14:22:32.343811 13672 sgd_solver.cpp:138] Iteration 6050, lr = 0.001
I0623 14:25:49.829015 13672 solver.cpp:243] Iteration 6060, loss = 3.39391
I0623 14:25:49.829015 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.64349 (* 1 = 4.64349 loss)
I0623 14:25:49.829015 13672 sgd_solver.cpp:138] Iteration 6060, lr = 0.001
I0623 14:29:14.078269 13672 solver.cpp:243] Iteration 6070, loss = 3.80709
I0623 14:29:14.078269 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.96816 (* 1 = 4.96816 loss)
I0623 14:29:14.078269 13672 sgd_solver.cpp:138] Iteration 6070, lr = 0.001
I0623 14:32:34.797092 13672 solver.cpp:243] Iteration 6080, loss = 3.85848
I0623 14:32:34.797092 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.57955 (* 1 = 4.57955 loss)
I0623 14:32:34.797092 13672 sgd_solver.cpp:138] Iteration 6080, lr = 0.001
I0623 14:35:50.189075 13672 solver.cpp:243] Iteration 6090, loss = 3.76305
I0623 14:35:50.189075 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.09035 (* 1 = 4.09035 loss)
I0623 14:35:50.189075 13672 sgd_solver.cpp:138] Iteration 6090, lr = 0.001
I0623 14:39:22.452044 13672 solver.cpp:243] Iteration 6100, loss = 3.68066
I0623 14:39:22.452044 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.26203 (* 1 = 2.26203 loss)
I0623 14:39:22.452044 13672 sgd_solver.cpp:138] Iteration 6100, lr = 0.001
I0623 14:42:38.687538 13672 solver.cpp:243] Iteration 6110, loss = 3.63794
I0623 14:42:38.687538 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.96785 (* 1 = 1.96785 loss)
I0623 14:42:38.687538 13672 sgd_solver.cpp:138] Iteration 6110, lr = 0.001
I0623 14:45:47.393582 13672 solver.cpp:243] Iteration 6120, loss = 3.84631
I0623 14:45:47.393582 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.35493 (* 1 = 2.35493 loss)
I0623 14:45:47.393582 13672 sgd_solver.cpp:138] Iteration 6120, lr = 0.001
I0623 14:49:00.208052 13672 solver.cpp:243] Iteration 6130, loss = 3.51392
I0623 14:49:00.208052 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.9973 (* 1 = 4.9973 loss)
I0623 14:49:00.208052 13672 sgd_solver.cpp:138] Iteration 6130, lr = 0.001
I0623 14:52:25.287225 13672 solver.cpp:243] Iteration 6140, loss = 3.81563
I0623 14:52:25.287225 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.12508 (* 1 = 5.12508 loss)
I0623 14:52:25.287225 13672 sgd_solver.cpp:138] Iteration 6140, lr = 0.001
I0623 14:55:36.992249 13672 solver.cpp:243] Iteration 6150, loss = 3.84957
I0623 14:55:36.992249 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.64212 (* 1 = 3.64212 loss)
I0623 14:55:36.992249 13672 sgd_solver.cpp:138] Iteration 6150, lr = 0.001
I0623 14:59:00.007475 13672 solver.cpp:243] Iteration 6160, loss = 3.83222
I0623 14:59:00.007475 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.28371 (* 1 = 6.28371 loss)
I0623 14:59:00.007475 13672 sgd_solver.cpp:138] Iteration 6160, lr = 0.001
I0623 15:02:13.118687 13672 solver.cpp:243] Iteration 6170, loss = 3.97672
I0623 15:02:13.118687 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.0437 (* 1 = 11.0437 loss)
I0623 15:02:13.118687 13672 sgd_solver.cpp:138] Iteration 6170, lr = 0.001
I0623 15:05:42.179355 13672 solver.cpp:243] Iteration 6180, loss = 4.01527
I0623 15:05:42.179355 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.51271 (* 1 = 9.51271 loss)
I0623 15:05:42.179355 13672 sgd_solver.cpp:138] Iteration 6180, lr = 0.001
I0623 15:08:55.399951 13672 solver.cpp:243] Iteration 6190, loss = 4.28013
I0623 15:08:55.399951 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.81483 (* 1 = 4.81483 loss)
I0623 15:08:55.399951 13672 sgd_solver.cpp:138] Iteration 6190, lr = 0.001
I0623 15:12:24.082451 13672 solver.cpp:243] Iteration 6200, loss = 3.93769
I0623 15:12:24.082451 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.5632 (* 1 = 3.5632 loss)
I0623 15:12:24.082451 13672 sgd_solver.cpp:138] Iteration 6200, lr = 0.001
I0623 15:15:36.287585 13672 solver.cpp:243] Iteration 6210, loss = 3.7074
I0623 15:15:36.287585 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.33463 (* 1 = 3.33463 loss)
I0623 15:15:36.287585 13672 sgd_solver.cpp:138] Iteration 6210, lr = 0.001
I0623 15:18:49.617507 13672 solver.cpp:243] Iteration 6220, loss = 3.69443
I0623 15:18:49.617507 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.95497 (* 1 = 2.95497 loss)
I0623 15:18:49.617507 13672 sgd_solver.cpp:138] Iteration 6220, lr = 0.001
I0623 15:22:05.431267 13672 solver.cpp:243] Iteration 6230, loss = 3.60902
I0623 15:22:05.431267 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.03977 (* 1 = 2.03977 loss)
I0623 15:22:05.431267 13672 sgd_solver.cpp:138] Iteration 6230, lr = 0.001
I0623 15:25:14.543424 13672 solver.cpp:243] Iteration 6240, loss = 3.542
I0623 15:25:14.543424 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.10006 (* 1 = 1.10006 loss)
I0623 15:25:14.543424 13672 sgd_solver.cpp:138] Iteration 6240, lr = 0.001
I0623 15:28:23.360579 13672 solver.cpp:243] Iteration 6250, loss = 3.4897
I0623 15:28:23.360579 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.473201 (* 1 = 0.473201 loss)
I0623 15:28:23.360579 13672 sgd_solver.cpp:138] Iteration 6250, lr = 0.001
I0623 15:31:31.738483 13672 solver.cpp:243] Iteration 6260, loss = 3.49696
I0623 15:31:31.738483 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.4008 (* 1 = 5.4008 loss)
I0623 15:31:31.738483 13672 sgd_solver.cpp:138] Iteration 6260, lr = 0.001
I0623 15:34:59.568776 13672 solver.cpp:243] Iteration 6270, loss = 3.38831
I0623 15:34:59.693950 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.77445 (* 1 = 1.77445 loss)
I0623 15:34:59.724754 13672 sgd_solver.cpp:138] Iteration 6270, lr = 0.001
I0623 15:38:07.717296 13672 solver.cpp:243] Iteration 6280, loss = 3.49877
I0623 15:38:07.717296 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.961282 (* 1 = 0.961282 loss)
I0623 15:38:07.717296 13672 sgd_solver.cpp:138] Iteration 6280, lr = 0.001
I0623 15:41:28.946182 13672 solver.cpp:243] Iteration 6290, loss = 3.67419
I0623 15:41:28.946182 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.47162 (* 1 = 7.47162 loss)
I0623 15:41:28.946182 13672 sgd_solver.cpp:138] Iteration 6290, lr = 0.001
I0623 15:44:53.117331 13672 solver.cpp:243] Iteration 6300, loss = 3.58418
I0623 15:44:53.117331 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.97829 (* 1 = 3.97829 loss)
I0623 15:44:53.117331 13672 sgd_solver.cpp:138] Iteration 6300, lr = 0.001
I0623 15:48:03.791707 13672 solver.cpp:243] Iteration 6310, loss = 3.45
I0623 15:48:03.791707 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.46513 (* 1 = 3.46513 loss)
I0623 15:48:03.807318 13672 sgd_solver.cpp:138] Iteration 6310, lr = 0.001
I0623 15:51:25.822686 13672 solver.cpp:243] Iteration 6320, loss = 3.51554
I0623 15:51:25.838308 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.54307 (* 1 = 4.54307 loss)
I0623 15:51:25.838308 13672 sgd_solver.cpp:138] Iteration 6320, lr = 0.001
I0623 15:54:46.275952 13672 solver.cpp:243] Iteration 6330, loss = 3.51573
I0623 15:54:46.275952 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.47312 (* 1 = 4.47312 loss)
I0623 15:54:46.275952 13672 sgd_solver.cpp:138] Iteration 6330, lr = 0.001
I0623 15:58:10.353407 13672 solver.cpp:243] Iteration 6340, loss = 3.64304
I0623 15:58:10.447127 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.34161 (* 1 = 3.34161 loss)
I0623 15:58:10.447127 13672 sgd_solver.cpp:138] Iteration 6340, lr = 0.001
I0623 16:01:33.806020 13672 solver.cpp:243] Iteration 6350, loss = 3.54529
I0623 16:01:33.806020 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.39459 (* 1 = 3.39459 loss)
I0623 16:01:33.806020 13672 sgd_solver.cpp:138] Iteration 6350, lr = 0.001
I0623 16:04:54.290570 13672 solver.cpp:243] Iteration 6360, loss = 3.4486
I0623 16:04:54.306145 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.00915 (* 1 = 2.00915 loss)
I0623 16:04:54.321805 13672 sgd_solver.cpp:138] Iteration 6360, lr = 0.001
I0623 16:08:04.824302 13672 solver.cpp:243] Iteration 6370, loss = 3.4996
I0623 16:08:04.824302 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.81355 (* 1 = 2.81355 loss)
I0623 16:08:04.824302 13672 sgd_solver.cpp:138] Iteration 6370, lr = 0.001
I0623 16:11:09.967844 13672 solver.cpp:243] Iteration 6380, loss = 3.66313
I0623 16:11:09.967844 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.69269 (* 1 = 5.69269 loss)
I0623 16:11:09.967844 13672 sgd_solver.cpp:138] Iteration 6380, lr = 0.001
I0623 16:14:37.715407 13672 solver.cpp:243] Iteration 6390, loss = 3.68282
I0623 16:14:37.715407 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.38931 (* 1 = 5.38931 loss)
I0623 16:14:37.715407 13672 sgd_solver.cpp:138] Iteration 6390, lr = 0.001
I0623 16:17:58.715376 13672 solver.cpp:243] Iteration 6400, loss = 3.83185
I0623 16:17:58.809154 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.94542 (* 1 = 3.94542 loss)
I0623 16:17:58.856009 13672 sgd_solver.cpp:138] Iteration 6400, lr = 0.001
I0623 16:21:15.044658 13672 solver.cpp:243] Iteration 6410, loss = 3.58084
I0623 16:21:15.044658 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.38297 (* 1 = 5.38297 loss)
I0623 16:21:15.044658 13672 sgd_solver.cpp:138] Iteration 6410, lr = 0.001
I0623 16:24:30.233523 13672 solver.cpp:243] Iteration 6420, loss = 3.62586
I0623 16:24:30.233523 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.34126 (* 1 = 6.34126 loss)
I0623 16:24:30.233523 13672 sgd_solver.cpp:138] Iteration 6420, lr = 0.001
I0623 16:27:45.497534 13672 solver.cpp:243] Iteration 6430, loss = 3.56905
I0623 16:27:45.497534 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.38406 (* 1 = 3.38406 loss)
I0623 16:27:45.497534 13672 sgd_solver.cpp:138] Iteration 6430, lr = 0.001
I0623 16:30:52.297693 13672 solver.cpp:243] Iteration 6440, loss = 3.33004
I0623 16:30:52.297693 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.58667 (* 1 = 3.58667 loss)
I0623 16:30:52.297693 13672 sgd_solver.cpp:138] Iteration 6440, lr = 0.001
I0623 16:34:14.641139 13672 solver.cpp:243] Iteration 6450, loss = 3.59962
I0623 16:34:14.641139 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.20165 (* 1 = 3.20165 loss)
I0623 16:34:14.641139 13672 sgd_solver.cpp:138] Iteration 6450, lr = 0.001
I0623 16:37:23.722054 13672 solver.cpp:243] Iteration 6460, loss = 3.52259
I0623 16:37:23.722054 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.62195 (* 1 = 2.62195 loss)
I0623 16:37:23.722054 13672 sgd_solver.cpp:138] Iteration 6460, lr = 0.001
I0623 16:40:34.376513 13672 solver.cpp:243] Iteration 6470, loss = 3.61225
I0623 16:40:34.376513 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.01311 (* 1 = 3.01311 loss)
I0623 16:40:34.376513 13672 sgd_solver.cpp:138] Iteration 6470, lr = 0.001
I0623 16:43:53.611308 13672 solver.cpp:243] Iteration 6480, loss = 3.55395
I0623 16:43:53.611308 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.16456 (* 1 = 2.16456 loss)
I0623 16:43:53.611308 13672 sgd_solver.cpp:138] Iteration 6480, lr = 0.001
I0623 16:47:01.771276 13672 solver.cpp:243] Iteration 6490, loss = 3.70306
I0623 16:47:01.771276 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.828542 (* 1 = 0.828542 loss)
I0623 16:47:01.771276 13672 sgd_solver.cpp:138] Iteration 6490, lr = 0.001
I0623 16:50:15.486883 13672 solver.cpp:243] Iteration 6500, loss = 3.52661
I0623 16:50:15.486883 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.85946 (* 1 = 1.85946 loss)
I0623 16:50:15.486883 13672 sgd_solver.cpp:138] Iteration 6500, lr = 0.001
I0623 16:53:29.764895 13672 solver.cpp:243] Iteration 6510, loss = 3.74592
I0623 16:53:29.764895 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.87254 (* 1 = 4.87254 loss)
I0623 16:53:29.764895 13672 sgd_solver.cpp:138] Iteration 6510, lr = 0.001
I0623 16:56:54.104785 13672 solver.cpp:243] Iteration 6520, loss = 3.63272
I0623 16:56:54.104785 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.56873 (* 1 = 1.56873 loss)
I0623 16:56:54.104785 13672 sgd_solver.cpp:138] Iteration 6520, lr = 0.001
I0623 17:00:09.401914 13672 solver.cpp:243] Iteration 6530, loss = 3.61208
I0623 17:00:09.401914 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.74745 (* 1 = 2.74745 loss)
I0623 17:00:09.401914 13672 sgd_solver.cpp:138] Iteration 6530, lr = 0.001
I0623 17:03:27.706538 13672 solver.cpp:243] Iteration 6540, loss = 3.91766
I0623 17:03:27.706538 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.02346 (* 1 = 6.02346 loss)
I0623 17:03:27.706538 13672 sgd_solver.cpp:138] Iteration 6540, lr = 0.001
I0623 17:06:38.142344 13672 solver.cpp:243] Iteration 6550, loss = 3.80692
I0623 17:06:38.142344 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.5017 (* 1 = 6.5017 loss)
I0623 17:06:38.142344 13672 sgd_solver.cpp:138] Iteration 6550, lr = 0.001
I0623 17:10:05.175915 13672 solver.cpp:243] Iteration 6560, loss = 3.40313
I0623 17:10:05.175915 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.18579 (* 1 = 5.18579 loss)
I0623 17:10:05.175915 13672 sgd_solver.cpp:138] Iteration 6560, lr = 0.001
I0623 17:13:37.569902 13672 solver.cpp:243] Iteration 6570, loss = 3.53479
I0623 17:13:37.569902 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.93073 (* 1 = 3.93073 loss)
I0623 17:13:37.569902 13672 sgd_solver.cpp:138] Iteration 6570, lr = 0.001
I0623 17:17:06.599290 13672 solver.cpp:243] Iteration 6580, loss = 3.47416
I0623 17:17:06.599290 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.61524 (* 1 = 3.61524 loss)
I0623 17:17:06.599290 13672 sgd_solver.cpp:138] Iteration 6580, lr = 0.001
I0623 17:20:19.273166 13672 solver.cpp:243] Iteration 6590, loss = 3.43661
I0623 17:20:19.273166 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.03315 (* 1 = 4.03315 loss)
I0623 17:20:19.273166 13672 sgd_solver.cpp:138] Iteration 6590, lr = 0.001
I0623 17:23:27.588583 13672 solver.cpp:243] Iteration 6600, loss = 3.45411
I0623 17:23:27.588583 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.53626 (* 1 = 5.53626 loss)
I0623 17:23:27.588583 13672 sgd_solver.cpp:138] Iteration 6600, lr = 0.001
I0623 17:26:43.964670 13672 solver.cpp:243] Iteration 6610, loss = 3.46469
I0623 17:26:43.964670 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.75472 (* 1 = 1.75472 loss)
I0623 17:26:43.964670 13672 sgd_solver.cpp:138] Iteration 6610, lr = 0.001
I0623 17:30:01.824800 13672 solver.cpp:243] Iteration 6620, loss = 3.65122
I0623 17:30:01.824800 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.04482 (* 1 = 3.04482 loss)
I0623 17:30:01.824800 13672 sgd_solver.cpp:138] Iteration 6620, lr = 0.001
I0623 17:33:09.312367 13672 solver.cpp:243] Iteration 6630, loss = 3.4181
I0623 17:33:09.312367 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.82719 (* 1 = 4.82719 loss)
I0623 17:33:09.312367 13672 sgd_solver.cpp:138] Iteration 6630, lr = 0.001
I0623 17:36:35.654932 13672 solver.cpp:243] Iteration 6640, loss = 3.51207
I0623 17:36:35.670459 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.6699 (* 1 = 1.6699 loss)
I0623 17:36:35.686089 13672 sgd_solver.cpp:138] Iteration 6640, lr = 0.001
I0623 17:40:01.232062 13672 solver.cpp:243] Iteration 6650, loss = 3.54663
I0623 17:40:01.294390 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.4235 (* 1 = 3.4235 loss)
I0623 17:40:01.310021 13672 sgd_solver.cpp:138] Iteration 6650, lr = 0.001
I0623 17:43:18.373440 13672 solver.cpp:243] Iteration 6660, loss = 3.3336
I0623 17:43:18.373440 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.51537 (* 1 = 4.51537 loss)
I0623 17:43:18.373440 13672 sgd_solver.cpp:138] Iteration 6660, lr = 0.001
I0623 17:46:58.603338 13672 solver.cpp:243] Iteration 6670, loss = 3.59451
I0623 17:46:58.634582 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.35204 (* 1 = 5.35204 loss)
I0623 17:46:58.650204 13672 sgd_solver.cpp:138] Iteration 6670, lr = 0.001
I0623 17:50:22.727622 13672 solver.cpp:243] Iteration 6680, loss = 3.39563
I0623 17:50:22.727622 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.83049 (* 1 = 1.83049 loss)
I0623 17:50:22.727622 13672 sgd_solver.cpp:138] Iteration 6680, lr = 0.001
I0623 17:52:03.407272 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0623 17:53:37.338495 13672 solver.cpp:243] Iteration 6690, loss = 3.35114
I0623 17:53:37.338495 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.17205 (* 1 = 3.17205 loss)
I0623 17:53:37.338495 13672 sgd_solver.cpp:138] Iteration 6690, lr = 0.001
I0623 17:57:16.068801 13672 solver.cpp:243] Iteration 6700, loss = 3.36171
I0623 17:57:16.068801 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.3884 (* 1 = 3.3884 loss)
I0623 17:57:16.068801 13672 sgd_solver.cpp:138] Iteration 6700, lr = 0.001
I0623 18:00:24.243731 13672 solver.cpp:243] Iteration 6710, loss = 3.41443
I0623 18:00:24.243731 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.97225 (* 1 = 3.97225 loss)
I0623 18:00:24.243731 13672 sgd_solver.cpp:138] Iteration 6710, lr = 0.001
I0623 18:03:41.338948 13672 solver.cpp:243] Iteration 6720, loss = 3.43369
I0623 18:03:41.338948 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.57013 (* 1 = 2.57013 loss)
I0623 18:03:41.338948 13672 sgd_solver.cpp:138] Iteration 6720, lr = 0.001
I0623 18:07:07.447193 13672 solver.cpp:243] Iteration 6730, loss = 3.41371
I0623 18:07:07.447193 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.905484 (* 1 = 0.905484 loss)
I0623 18:07:07.447193 13672 sgd_solver.cpp:138] Iteration 6730, lr = 0.001
I0623 18:10:30.024952 13672 solver.cpp:243] Iteration 6740, loss = 3.54765
I0623 18:10:30.024952 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.844013 (* 1 = 0.844013 loss)
I0623 18:10:30.024952 13672 sgd_solver.cpp:138] Iteration 6740, lr = 0.001
I0623 18:13:47.385185 13672 solver.cpp:243] Iteration 6750, loss = 3.34848
I0623 18:13:47.385185 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.37527 (* 1 = 2.37527 loss)
I0623 18:13:47.385185 13672 sgd_solver.cpp:138] Iteration 6750, lr = 0.001
I0623 18:17:09.556797 13672 solver.cpp:243] Iteration 6760, loss = 3.60848
I0623 18:17:09.556797 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.84588 (* 1 = 4.84588 loss)
I0623 18:17:09.556797 13672 sgd_solver.cpp:138] Iteration 6760, lr = 0.001
I0623 18:20:35.649847 13672 solver.cpp:243] Iteration 6770, loss = 3.37483
I0623 18:20:35.681114 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.99355 (* 1 = 1.99355 loss)
I0623 18:20:35.696760 13672 sgd_solver.cpp:138] Iteration 6770, lr = 0.001
I0623 18:23:40.762889 13672 solver.cpp:243] Iteration 6780, loss = 3.44471
I0623 18:23:40.762889 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.63483 (* 1 = 2.63483 loss)
I0623 18:23:40.762889 13672 sgd_solver.cpp:138] Iteration 6780, lr = 0.001
I0623 18:26:56.029862 13672 solver.cpp:243] Iteration 6790, loss = 3.80009
I0623 18:26:56.029862 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.01011 (* 1 = 5.01011 loss)
I0623 18:26:56.029862 13672 sgd_solver.cpp:138] Iteration 6790, lr = 0.001
I0623 18:30:15.639616 13672 solver.cpp:243] Iteration 6800, loss = 3.68474
I0623 18:30:15.639616 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.18392 (* 1 = 6.18392 loss)
I0623 18:30:15.639616 13672 sgd_solver.cpp:138] Iteration 6800, lr = 0.001
I0623 18:33:33.952744 13672 solver.cpp:243] Iteration 6810, loss = 3.38606
I0623 18:33:33.952744 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.74643 (* 1 = 4.74643 loss)
I0623 18:33:33.952744 13672 sgd_solver.cpp:138] Iteration 6810, lr = 0.001
I0623 18:37:03.810122 13672 solver.cpp:243] Iteration 6820, loss = 3.55419
I0623 18:37:03.825743 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.39841 (* 1 = 3.39841 loss)
I0623 18:37:03.825743 13672 sgd_solver.cpp:138] Iteration 6820, lr = 0.001
I0623 18:40:25.559957 13672 solver.cpp:243] Iteration 6830, loss = 3.63869
I0623 18:40:25.559957 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.80032 (* 1 = 2.80032 loss)
I0623 18:40:25.559957 13672 sgd_solver.cpp:138] Iteration 6830, lr = 0.001
I0623 18:43:52.324301 13672 solver.cpp:243] Iteration 6840, loss = 3.62132
I0623 18:43:52.324301 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.48526 (* 1 = 2.48526 loss)
I0623 18:43:52.324301 13672 sgd_solver.cpp:138] Iteration 6840, lr = 0.001
I0623 18:46:59.077739 13672 solver.cpp:243] Iteration 6850, loss = 3.62121
I0623 18:46:59.077739 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.24657 (* 1 = 2.24657 loss)
I0623 18:46:59.077739 13672 sgd_solver.cpp:138] Iteration 6850, lr = 0.001
I0623 18:50:22.290027 13672 solver.cpp:243] Iteration 6860, loss = 3.4861
I0623 18:50:22.290027 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.64645 (* 1 = 1.64645 loss)
I0623 18:50:22.290027 13672 sgd_solver.cpp:138] Iteration 6860, lr = 0.001
I0623 18:53:39.119125 13672 solver.cpp:243] Iteration 6870, loss = 3.39479
I0623 18:53:39.119125 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.30118 (* 1 = 2.30118 loss)
I0623 18:53:39.119125 13672 sgd_solver.cpp:138] Iteration 6870, lr = 0.001
I0623 18:56:55.870175 13672 solver.cpp:243] Iteration 6880, loss = 3.4575
I0623 18:56:55.870175 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.20297 (* 1 = 4.20297 loss)
I0623 18:56:55.870175 13672 sgd_solver.cpp:138] Iteration 6880, lr = 0.001
I0623 19:00:10.730958 13672 solver.cpp:243] Iteration 6890, loss = 3.47867
I0623 19:00:10.730958 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.06119 (* 1 = 4.06119 loss)
I0623 19:00:10.730958 13672 sgd_solver.cpp:138] Iteration 6890, lr = 0.001
I0623 19:03:19.624456 13672 solver.cpp:243] Iteration 6900, loss = 3.27502
I0623 19:03:19.624456 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.70731 (* 1 = 4.70731 loss)
I0623 19:03:19.624456 13672 sgd_solver.cpp:138] Iteration 6900, lr = 0.001
I0623 19:06:35.328826 13672 solver.cpp:243] Iteration 6910, loss = 3.29518
I0623 19:06:35.422510 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.29055 (* 1 = 8.29055 loss)
I0623 19:06:35.422510 13672 sgd_solver.cpp:138] Iteration 6910, lr = 0.001
I0623 19:09:47.783954 13672 solver.cpp:243] Iteration 6920, loss = 3.66012
I0623 19:09:47.783954 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.73924 (* 1 = 5.73924 loss)
I0623 19:09:47.783954 13672 sgd_solver.cpp:138] Iteration 6920, lr = 0.001
I0623 19:13:06.987501 13672 solver.cpp:243] Iteration 6930, loss = 3.53519
I0623 19:13:06.987501 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.78652 (* 1 = 3.78652 loss)
I0623 19:13:06.987501 13672 sgd_solver.cpp:138] Iteration 6930, lr = 0.001
I0623 19:16:16.427708 13672 solver.cpp:243] Iteration 6940, loss = 3.52711
I0623 19:16:16.427708 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.63918 (* 1 = 3.63918 loss)
I0623 19:16:16.427708 13672 sgd_solver.cpp:138] Iteration 6940, lr = 0.001
I0623 19:19:36.943454 13672 solver.cpp:243] Iteration 6950, loss = 3.48065
I0623 19:19:36.943454 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.15253 (* 1 = 2.15253 loss)
I0623 19:19:36.943454 13672 sgd_solver.cpp:138] Iteration 6950, lr = 0.001
I0623 19:22:58.427932 13672 solver.cpp:243] Iteration 6960, loss = 3.50383
I0623 19:22:58.427932 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.38469 (* 1 = 1.38469 loss)
I0623 19:22:58.427932 13672 sgd_solver.cpp:138] Iteration 6960, lr = 0.001
I0623 19:26:13.897943 13672 solver.cpp:243] Iteration 6970, loss = 3.64816
I0623 19:26:13.897943 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.23742 (* 1 = 4.23742 loss)
I0623 19:26:13.897943 13672 sgd_solver.cpp:138] Iteration 6970, lr = 0.001
I0623 19:29:38.100360 13672 solver.cpp:243] Iteration 6980, loss = 3.44023
I0623 19:29:38.100360 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.90883 (* 1 = 2.90883 loss)
I0623 19:29:38.100360 13672 sgd_solver.cpp:138] Iteration 6980, lr = 0.001
I0623 19:32:53.867224 13672 solver.cpp:243] Iteration 6990, loss = 3.45493
I0623 19:32:53.867224 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.995221 (* 1 = 0.995221 loss)
I0623 19:32:53.867224 13672 sgd_solver.cpp:138] Iteration 6990, lr = 0.001
I0623 19:36:07.165952 13672 solver.cpp:243] Iteration 7000, loss = 3.37803
I0623 19:36:07.165952 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.15922 (* 1 = 2.15922 loss)
I0623 19:36:07.165952 13672 sgd_solver.cpp:138] Iteration 7000, lr = 0.001
I0623 19:39:25.557149 13672 solver.cpp:243] Iteration 7010, loss = 3.62505
I0623 19:39:25.635290 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.57085 (* 1 = 5.57085 loss)
I0623 19:39:25.635290 13672 sgd_solver.cpp:138] Iteration 7010, lr = 0.001
I0623 19:42:40.871096 13672 solver.cpp:243] Iteration 7020, loss = 3.70981
I0623 19:42:40.871096 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.75728 (* 1 = 1.75728 loss)
I0623 19:42:40.871096 13672 sgd_solver.cpp:138] Iteration 7020, lr = 0.001
I0623 19:45:45.343710 13672 solver.cpp:243] Iteration 7030, loss = 3.47857
I0623 19:45:45.343710 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.68617 (* 1 = 1.68617 loss)
I0623 19:45:45.343710 13672 sgd_solver.cpp:138] Iteration 7030, lr = 0.001
I0623 19:48:59.081063 13672 solver.cpp:243] Iteration 7040, loss = 3.66502
I0623 19:48:59.081063 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.20121 (* 1 = 3.20121 loss)
I0623 19:48:59.081063 13672 sgd_solver.cpp:138] Iteration 7040, lr = 0.001
I0623 19:52:09.583474 13672 solver.cpp:243] Iteration 7050, loss = 3.56208
I0623 19:52:09.583474 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.00236 (* 1 = 5.00236 loss)
I0623 19:52:09.583474 13672 sgd_solver.cpp:138] Iteration 7050, lr = 0.001
I0623 19:55:22.788426 13672 solver.cpp:243] Iteration 7060, loss = 3.37612
I0623 19:55:22.788426 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.45512 (* 1 = 5.45512 loss)
I0623 19:55:22.788426 13672 sgd_solver.cpp:138] Iteration 7060, lr = 0.001
I0623 19:58:36.665098 13672 solver.cpp:243] Iteration 7070, loss = 3.62546
I0623 19:58:36.665098 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.26515 (* 1 = 1.26515 loss)
I0623 19:58:36.665098 13672 sgd_solver.cpp:138] Iteration 7070, lr = 0.001
I0623 20:01:49.620106 13672 solver.cpp:243] Iteration 7080, loss = 3.63983
I0623 20:01:49.620106 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.14699 (* 1 = 3.14699 loss)
I0623 20:01:49.620106 13672 sgd_solver.cpp:138] Iteration 7080, lr = 0.001
I0623 20:05:12.869591 13672 solver.cpp:243] Iteration 7090, loss = 3.95517
I0623 20:05:12.869591 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.11185 (* 1 = 3.11185 loss)
I0623 20:05:12.869591 13672 sgd_solver.cpp:138] Iteration 7090, lr = 0.001
I0623 20:08:27.917903 13672 solver.cpp:243] Iteration 7100, loss = 3.57358
I0623 20:08:27.917903 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.36129 (* 1 = 4.36129 loss)
I0623 20:08:27.917903 13672 sgd_solver.cpp:138] Iteration 7100, lr = 0.001
I0623 20:11:52.573271 13672 solver.cpp:243] Iteration 7110, loss = 3.33606
I0623 20:11:52.682621 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.84774 (* 1 = 1.84774 loss)
I0623 20:11:52.682621 13672 sgd_solver.cpp:138] Iteration 7110, lr = 0.001
I0623 20:15:05.871992 13672 solver.cpp:243] Iteration 7120, loss = 3.48101
I0623 20:15:05.871992 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.24903 (* 1 = 3.24903 loss)
I0623 20:15:05.871992 13672 sgd_solver.cpp:138] Iteration 7120, lr = 0.001
I0623 20:18:29.746321 13672 solver.cpp:243] Iteration 7130, loss = 3.44387
I0623 20:18:29.746321 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.75472 (* 1 = 4.75472 loss)
I0623 20:18:29.746321 13672 sgd_solver.cpp:138] Iteration 7130, lr = 0.001
I0623 20:21:49.199784 13672 solver.cpp:243] Iteration 7140, loss = 3.58159
I0623 20:21:49.199784 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.67394 (* 1 = 4.67394 loss)
I0623 20:21:49.199784 13672 sgd_solver.cpp:138] Iteration 7140, lr = 0.001
I0623 20:25:00.061537 13672 solver.cpp:243] Iteration 7150, loss = 3.38558
I0623 20:25:00.061537 13672 solver.cpp:259]     Train net output #0: mbox_loss = 8.87585 (* 1 = 8.87585 loss)
I0623 20:25:00.061537 13672 sgd_solver.cpp:138] Iteration 7150, lr = 0.001
I0623 20:28:15.234895 13672 solver.cpp:243] Iteration 7160, loss = 3.35575
I0623 20:28:15.234895 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.61857 (* 1 = 5.61857 loss)
I0623 20:28:15.234895 13672 sgd_solver.cpp:138] Iteration 7160, lr = 0.001
I0623 20:31:33.266808 13672 solver.cpp:243] Iteration 7170, loss = 3.76635
I0623 20:31:33.266808 13672 solver.cpp:259]     Train net output #0: mbox_loss = 11.8569 (* 1 = 11.8569 loss)
I0623 20:31:33.266808 13672 sgd_solver.cpp:138] Iteration 7170, lr = 0.001
I0623 20:35:00.827826 13672 solver.cpp:243] Iteration 7180, loss = 3.42204
I0623 20:35:00.827826 13672 solver.cpp:259]     Train net output #0: mbox_loss = 10.5399 (* 1 = 10.5399 loss)
I0623 20:35:00.827826 13672 sgd_solver.cpp:138] Iteration 7180, lr = 0.001
I0623 20:38:16.329121 13672 solver.cpp:243] Iteration 7190, loss = 3.38192
I0623 20:38:16.329121 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.89944 (* 1 = 2.89944 loss)
I0623 20:38:16.329121 13672 sgd_solver.cpp:138] Iteration 7190, lr = 0.001
I0623 20:41:37.735280 13672 solver.cpp:243] Iteration 7200, loss = 3.53742
I0623 20:41:37.735280 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.49589 (* 1 = 3.49589 loss)
I0623 20:41:37.735280 13672 sgd_solver.cpp:138] Iteration 7200, lr = 0.001
I0623 20:45:05.358709 13672 solver.cpp:243] Iteration 7210, loss = 3.61347
I0623 20:45:05.358709 13672 solver.cpp:259]     Train net output #0: mbox_loss = 17.4022 (* 1 = 17.4022 loss)
I0623 20:45:05.358709 13672 sgd_solver.cpp:138] Iteration 7210, lr = 0.001
I0623 20:48:24.859771 13672 solver.cpp:243] Iteration 7220, loss = 3.5174
I0623 20:48:24.859771 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.49037 (* 1 = 3.49037 loss)
I0623 20:48:24.859771 13672 sgd_solver.cpp:138] Iteration 7220, lr = 0.001
I0623 20:51:39.798732 13672 solver.cpp:243] Iteration 7230, loss = 3.26052
I0623 20:51:39.798732 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.50041 (* 1 = 1.50041 loss)
I0623 20:51:39.798732 13672 sgd_solver.cpp:138] Iteration 7230, lr = 0.001
I0623 20:54:57.440148 13672 solver.cpp:243] Iteration 7240, loss = 3.5
I0623 20:54:57.440148 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.75608 (* 1 = 1.75608 loss)
I0623 20:54:57.440148 13672 sgd_solver.cpp:138] Iteration 7240, lr = 0.001
I0623 20:58:09.660951 13672 solver.cpp:243] Iteration 7250, loss = 3.31782
I0623 20:58:09.660951 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.94003 (* 1 = 2.94003 loss)
I0623 20:58:09.660951 13672 sgd_solver.cpp:138] Iteration 7250, lr = 0.001
I0623 21:01:17.398392 13672 solver.cpp:243] Iteration 7260, loss = 3.75932
I0623 21:01:17.398392 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.93094 (* 1 = 4.93094 loss)
I0623 21:01:17.398392 13672 sgd_solver.cpp:138] Iteration 7260, lr = 0.001
I0623 21:04:34.664898 13672 solver.cpp:243] Iteration 7270, loss = 3.52583
I0623 21:04:34.664898 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.73568 (* 1 = 1.73568 loss)
I0623 21:04:34.664898 13672 sgd_solver.cpp:138] Iteration 7270, lr = 0.001
I0623 21:07:57.741869 13672 solver.cpp:243] Iteration 7280, loss = 3.21914
I0623 21:07:57.772658 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.17211 (* 1 = 1.17211 loss)
I0623 21:07:57.788734 13672 sgd_solver.cpp:138] Iteration 7280, lr = 0.001
I0623 21:11:22.592654 13672 solver.cpp:243] Iteration 7290, loss = 3.50647
I0623 21:11:22.592654 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.53877 (* 1 = 3.53877 loss)
I0623 21:11:22.592654 13672 sgd_solver.cpp:138] Iteration 7290, lr = 0.001
I0623 21:14:34.422894 13672 solver.cpp:243] Iteration 7300, loss = 3.39184
I0623 21:14:34.422894 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.1786 (* 1 = 4.1786 loss)
I0623 21:14:34.422894 13672 sgd_solver.cpp:138] Iteration 7300, lr = 0.001
I0623 21:17:44.003696 13672 solver.cpp:243] Iteration 7310, loss = 3.43977
I0623 21:17:44.003696 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.39291 (* 1 = 3.39291 loss)
I0623 21:17:44.003696 13672 sgd_solver.cpp:138] Iteration 7310, lr = 0.001
I0623 21:21:09.112079 13672 solver.cpp:243] Iteration 7320, loss = 3.36855
I0623 21:21:09.112079 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.91053 (* 1 = 1.91053 loss)
I0623 21:21:09.112079 13672 sgd_solver.cpp:138] Iteration 7320, lr = 0.001
I0623 21:24:26.159924 13672 solver.cpp:243] Iteration 7330, loss = 3.58699
I0623 21:24:26.159924 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.42916 (* 1 = 2.42916 loss)
I0623 21:24:26.159924 13672 sgd_solver.cpp:138] Iteration 7330, lr = 0.001
I0623 21:27:41.645598 13672 solver.cpp:243] Iteration 7340, loss = 3.46468
I0623 21:27:41.645598 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.26148 (* 1 = 4.26148 loss)
I0623 21:27:41.645598 13672 sgd_solver.cpp:138] Iteration 7340, lr = 0.001
I0623 21:31:01.130334 13672 solver.cpp:243] Iteration 7350, loss = 3.44754
I0623 21:31:01.130334 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.60358 (* 1 = 5.60358 loss)
I0623 21:31:01.130334 13672 sgd_solver.cpp:138] Iteration 7350, lr = 0.001
I0623 21:34:11.117245 13672 solver.cpp:243] Iteration 7360, loss = 3.37624
I0623 21:34:11.117245 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.66481 (* 1 = 3.66481 loss)
I0623 21:34:11.117245 13672 sgd_solver.cpp:138] Iteration 7360, lr = 0.001
I0623 21:37:32.289139 13672 solver.cpp:243] Iteration 7370, loss = 3.76746
I0623 21:37:32.289139 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.67912 (* 1 = 3.67912 loss)
I0623 21:37:32.289139 13672 sgd_solver.cpp:138] Iteration 7370, lr = 0.001
I0623 21:38:21.574513 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0623 21:40:45.790846 13672 solver.cpp:243] Iteration 7380, loss = 3.33648
I0623 21:40:45.790846 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.85975 (* 1 = 2.85975 loss)
I0623 21:40:45.790846 13672 sgd_solver.cpp:138] Iteration 7380, lr = 0.001
I0623 21:44:14.226668 13672 solver.cpp:243] Iteration 7390, loss = 3.70967
I0623 21:44:14.226668 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.52763 (* 1 = 4.52763 loss)
I0623 21:44:14.226668 13672 sgd_solver.cpp:138] Iteration 7390, lr = 0.001
I0623 21:47:29.524876 13672 solver.cpp:243] Iteration 7400, loss = 3.21292
I0623 21:47:29.524876 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.4117 (* 1 = 2.4117 loss)
I0623 21:47:29.524876 13672 sgd_solver.cpp:138] Iteration 7400, lr = 0.001
I0623 21:50:32.169790 13672 solver.cpp:243] Iteration 7410, loss = 3.34887
I0623 21:50:32.169790 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.94091 (* 1 = 2.94091 loss)
I0623 21:50:32.169790 13672 sgd_solver.cpp:138] Iteration 7410, lr = 0.001
I0623 21:53:39.079336 13672 solver.cpp:243] Iteration 7420, loss = 3.43928
I0623 21:53:39.079336 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.02157 (* 1 = 7.02157 loss)
I0623 21:53:39.079336 13672 sgd_solver.cpp:138] Iteration 7420, lr = 0.001
I0623 21:57:08.639808 13672 solver.cpp:243] Iteration 7430, loss = 3.48692
I0623 21:57:08.671054 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.18954 (* 1 = 4.18954 loss)
I0623 21:57:08.671054 13672 sgd_solver.cpp:138] Iteration 7430, lr = 0.001
I0623 22:00:16.533780 13672 solver.cpp:243] Iteration 7440, loss = 3.43441
I0623 22:00:16.533780 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.47547 (* 1 = 2.47547 loss)
I0623 22:00:16.533780 13672 sgd_solver.cpp:138] Iteration 7440, lr = 0.001
I0623 22:03:39.392693 13672 solver.cpp:243] Iteration 7450, loss = 3.37441
I0623 22:03:39.392693 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.68899 (* 1 = 3.68899 loss)
I0623 22:03:39.392693 13672 sgd_solver.cpp:138] Iteration 7450, lr = 0.001
I0623 22:06:57.003194 13672 solver.cpp:243] Iteration 7460, loss = 3.4962
I0623 22:06:57.003194 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.37427 (* 1 = 3.37427 loss)
I0623 22:06:57.003194 13672 sgd_solver.cpp:138] Iteration 7460, lr = 0.001
I0623 22:10:12.926256 13672 solver.cpp:243] Iteration 7470, loss = 3.65749
I0623 22:10:12.926256 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.16334 (* 1 = 2.16334 loss)
I0623 22:10:12.926256 13672 sgd_solver.cpp:138] Iteration 7470, lr = 0.001
I0623 22:13:29.927206 13672 solver.cpp:243] Iteration 7480, loss = 3.36243
I0623 22:13:29.927206 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.75726 (* 1 = 1.75726 loss)
I0623 22:13:29.927206 13672 sgd_solver.cpp:138] Iteration 7480, lr = 0.001
I0623 22:16:43.085292 13672 solver.cpp:243] Iteration 7490, loss = 3.49431
I0623 22:16:43.085292 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.4285 (* 1 = 2.4285 loss)
I0623 22:16:43.085292 13672 sgd_solver.cpp:138] Iteration 7490, lr = 0.001
I0623 22:19:50.416604 13672 solver.cpp:243] Iteration 7500, loss = 3.23657
I0623 22:19:50.416604 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.30077 (* 1 = 2.30077 loss)
I0623 22:19:50.416604 13672 sgd_solver.cpp:138] Iteration 7500, lr = 0.001
I0623 22:23:06.605239 13672 solver.cpp:243] Iteration 7510, loss = 3.41715
I0623 22:23:06.605239 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.52447 (* 1 = 3.52447 loss)
I0623 22:23:06.605239 13672 sgd_solver.cpp:138] Iteration 7510, lr = 0.001
I0623 22:26:26.761749 13672 solver.cpp:243] Iteration 7520, loss = 3.49014
I0623 22:26:26.761749 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.881637 (* 1 = 0.881637 loss)
I0623 22:26:26.761749 13672 sgd_solver.cpp:138] Iteration 7520, lr = 0.001
I0623 22:29:41.231979 13672 solver.cpp:243] Iteration 7530, loss = 3.10524
I0623 22:29:41.231979 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.385305 (* 1 = 0.385305 loss)
I0623 22:29:41.231979 13672 sgd_solver.cpp:138] Iteration 7530, lr = 0.001
I0623 22:32:59.701432 13672 solver.cpp:243] Iteration 7540, loss = 3.45828
I0623 22:32:59.701432 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.03552 (* 1 = 5.03552 loss)
I0623 22:32:59.701432 13672 sgd_solver.cpp:138] Iteration 7540, lr = 0.001
I0623 22:36:02.939957 13672 solver.cpp:243] Iteration 7550, loss = 3.27165
I0623 22:36:02.939957 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.80546 (* 1 = 5.80546 loss)
I0623 22:36:02.939957 13672 sgd_solver.cpp:138] Iteration 7550, lr = 0.001
I0623 22:39:12.067807 13672 solver.cpp:243] Iteration 7560, loss = 3.20274
I0623 22:39:12.067807 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.03544 (* 1 = 5.03544 loss)
I0623 22:39:12.067807 13672 sgd_solver.cpp:138] Iteration 7560, lr = 0.001
I0623 22:42:32.864742 13672 solver.cpp:243] Iteration 7570, loss = 3.39079
I0623 22:42:32.864742 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.0339 (* 1 = 5.0339 loss)
I0623 22:42:32.864742 13672 sgd_solver.cpp:138] Iteration 7570, lr = 0.001
I0623 22:45:48.834672 13672 solver.cpp:243] Iteration 7580, loss = 3.362
I0623 22:45:48.834672 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.50387 (* 1 = 1.50387 loss)
I0623 22:45:48.834672 13672 sgd_solver.cpp:138] Iteration 7580, lr = 0.001
I0623 22:49:06.585440 13672 solver.cpp:243] Iteration 7590, loss = 3.37917
I0623 22:49:06.585440 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.00025 (* 1 = 4.00025 loss)
I0623 22:49:06.585440 13672 sgd_solver.cpp:138] Iteration 7590, lr = 0.001
I0623 22:52:17.744035 13672 solver.cpp:243] Iteration 7600, loss = 3.43526
I0623 22:52:17.759647 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.21063 (* 1 = 2.21063 loss)
I0623 22:52:17.759647 13672 sgd_solver.cpp:138] Iteration 7600, lr = 0.001
I0623 22:55:30.980188 13672 solver.cpp:243] Iteration 7610, loss = 3.30046
I0623 22:55:30.980188 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.78382 (* 1 = 1.78382 loss)
I0623 22:55:30.980188 13672 sgd_solver.cpp:138] Iteration 7610, lr = 0.001
I0623 22:58:44.763131 13672 solver.cpp:243] Iteration 7620, loss = 3.43949
I0623 22:58:44.763131 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.38643 (* 1 = 3.38643 loss)
I0623 22:58:44.763131 13672 sgd_solver.cpp:138] Iteration 7620, lr = 0.001
I0623 23:01:54.031502 13672 solver.cpp:243] Iteration 7630, loss = 3.29046
I0623 23:01:54.031502 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.3125 (* 1 = 5.3125 loss)
I0623 23:01:54.031502 13672 sgd_solver.cpp:138] Iteration 7630, lr = 0.001
I0623 23:05:04.330883 13672 solver.cpp:243] Iteration 7640, loss = 3.3009
I0623 23:05:04.330883 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.84529 (* 1 = 4.84529 loss)
I0623 23:05:04.330883 13672 sgd_solver.cpp:138] Iteration 7640, lr = 0.001
I0623 23:08:15.942593 13672 solver.cpp:243] Iteration 7650, loss = 3.33688
I0623 23:08:15.942593 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.41043 (* 1 = 3.41043 loss)
I0623 23:08:15.942593 13672 sgd_solver.cpp:138] Iteration 7650, lr = 0.001
I0623 23:11:22.477190 13672 solver.cpp:243] Iteration 7660, loss = 3.44221
I0623 23:11:22.477190 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.62347 (* 1 = 4.62347 loss)
I0623 23:11:22.477190 13672 sgd_solver.cpp:138] Iteration 7660, lr = 0.001
I0623 23:14:49.397693 13672 solver.cpp:243] Iteration 7670, loss = 3.42459
I0623 23:14:49.397693 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.94246 (* 1 = 4.94246 loss)
I0623 23:14:49.397693 13672 sgd_solver.cpp:138] Iteration 7670, lr = 0.001
I0623 23:18:11.335022 13672 solver.cpp:243] Iteration 7680, loss = 3.19064
I0623 23:18:11.335022 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.46326 (* 1 = 2.46326 loss)
I0623 23:18:11.335022 13672 sgd_solver.cpp:138] Iteration 7680, lr = 0.001
I0623 23:21:17.385560 13672 solver.cpp:243] Iteration 7690, loss = 3.26049
I0623 23:21:17.385560 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.04021 (* 1 = 2.04021 loss)
I0623 23:21:17.385560 13672 sgd_solver.cpp:138] Iteration 7690, lr = 0.001
I0623 23:24:53.897639 13672 solver.cpp:243] Iteration 7700, loss = 3.61148
I0623 23:24:53.897639 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.97296 (* 1 = 0.97296 loss)
I0623 23:24:53.897639 13672 sgd_solver.cpp:138] Iteration 7700, lr = 0.001
I0623 23:28:02.775452 13672 solver.cpp:243] Iteration 7710, loss = 3.21583
I0623 23:28:02.775452 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.961371 (* 1 = 0.961371 loss)
I0623 23:28:02.775452 13672 sgd_solver.cpp:138] Iteration 7710, lr = 0.001
I0623 23:31:16.527112 13672 solver.cpp:243] Iteration 7720, loss = 3.42764
I0623 23:31:16.527112 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.88113 (* 1 = 1.88113 loss)
I0623 23:31:16.527112 13672 sgd_solver.cpp:138] Iteration 7720, lr = 0.001
I0623 23:34:27.591984 13672 solver.cpp:243] Iteration 7730, loss = 3.23135
I0623 23:34:27.591984 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.73736 (* 1 = 1.73736 loss)
I0623 23:34:27.591984 13672 sgd_solver.cpp:138] Iteration 7730, lr = 0.001
I0623 23:37:44.327354 13672 solver.cpp:243] Iteration 7740, loss = 3.53647
I0623 23:37:44.327354 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.880502 (* 1 = 0.880502 loss)
I0623 23:37:44.327354 13672 sgd_solver.cpp:138] Iteration 7740, lr = 0.001
I0623 23:40:48.659390 13672 solver.cpp:243] Iteration 7750, loss = 3.24274
I0623 23:40:48.659390 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.80077 (* 1 = 1.80077 loss)
I0623 23:40:48.659390 13672 sgd_solver.cpp:138] Iteration 7750, lr = 0.001
I0623 23:44:01.083222 13672 solver.cpp:243] Iteration 7760, loss = 3.32314
I0623 23:44:01.083222 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.84006 (* 1 = 3.84006 loss)
I0623 23:44:01.083222 13672 sgd_solver.cpp:138] Iteration 7760, lr = 0.001
I0623 23:47:13.241582 13672 solver.cpp:243] Iteration 7770, loss = 3.30215
I0623 23:47:13.241582 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.36796 (* 1 = 2.36796 loss)
I0623 23:47:13.241582 13672 sgd_solver.cpp:138] Iteration 7770, lr = 0.001
I0623 23:50:26.321574 13672 solver.cpp:243] Iteration 7780, loss = 3.16414
I0623 23:50:26.321574 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.63083 (* 1 = 1.63083 loss)
I0623 23:50:26.321574 13672 sgd_solver.cpp:138] Iteration 7780, lr = 0.001
I0623 23:53:43.463100 13672 solver.cpp:243] Iteration 7790, loss = 3.4536
I0623 23:53:43.463100 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.90366 (* 1 = 4.90366 loss)
I0623 23:53:43.463100 13672 sgd_solver.cpp:138] Iteration 7790, lr = 0.001
I0623 23:56:50.997496 13672 solver.cpp:243] Iteration 7800, loss = 3.44678
I0623 23:56:50.997496 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.15165 (* 1 = 4.15165 loss)
I0623 23:56:50.997496 13672 sgd_solver.cpp:138] Iteration 7800, lr = 0.001
I0624 00:00:10.497872 13672 solver.cpp:243] Iteration 7810, loss = 3.23852
I0624 00:00:10.497872 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.58064 (* 1 = 3.58064 loss)
I0624 00:00:10.497872 13672 sgd_solver.cpp:138] Iteration 7810, lr = 0.001
I0624 00:03:26.748970 13672 solver.cpp:243] Iteration 7820, loss = 3.25151
I0624 00:03:26.748970 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.86143 (* 1 = 3.86143 loss)
I0624 00:03:26.748970 13672 sgd_solver.cpp:138] Iteration 7820, lr = 0.001
I0624 00:06:50.685798 13672 solver.cpp:243] Iteration 7830, loss = 3.34651
I0624 00:06:50.685798 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.2907 (* 1 = 3.2907 loss)
I0624 00:06:50.685798 13672 sgd_solver.cpp:138] Iteration 7830, lr = 0.001
I0624 00:10:13.669797 13672 solver.cpp:243] Iteration 7840, loss = 3.25318
I0624 00:10:13.669797 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.28284 (* 1 = 4.28284 loss)
I0624 00:10:13.669797 13672 sgd_solver.cpp:138] Iteration 7840, lr = 0.001
I0624 00:13:35.560297 13672 solver.cpp:243] Iteration 7850, loss = 3.17823
I0624 00:13:35.560297 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.84552 (* 1 = 2.84552 loss)
I0624 00:13:35.575917 13672 sgd_solver.cpp:138] Iteration 7850, lr = 0.001
I0624 00:16:52.717381 13672 solver.cpp:243] Iteration 7860, loss = 3.30507
I0624 00:16:52.717381 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.58761 (* 1 = 1.58761 loss)
I0624 00:16:52.717381 13672 sgd_solver.cpp:138] Iteration 7860, lr = 0.001
I0624 00:19:58.189800 13672 solver.cpp:243] Iteration 7870, loss = 3.40661
I0624 00:19:58.189800 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.67496 (* 1 = 2.67496 loss)
I0624 00:19:58.189800 13672 sgd_solver.cpp:138] Iteration 7870, lr = 0.001
I0624 00:23:11.754035 13672 solver.cpp:243] Iteration 7880, loss = 3.20665
I0624 00:23:11.754035 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.95584 (* 1 = 3.95584 loss)
I0624 00:23:11.754035 13672 sgd_solver.cpp:138] Iteration 7880, lr = 0.001
I0624 00:26:23.303092 13672 solver.cpp:243] Iteration 7890, loss = 3.31262
I0624 00:26:23.303092 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.99748 (* 1 = 3.99748 loss)
I0624 00:26:23.303092 13672 sgd_solver.cpp:138] Iteration 7890, lr = 0.001
I0624 00:29:44.241037 13672 solver.cpp:243] Iteration 7900, loss = 3.28662
I0624 00:29:44.257028 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.2972 (* 1 = 3.2972 loss)
I0624 00:29:44.257028 13672 sgd_solver.cpp:138] Iteration 7900, lr = 0.001
I0624 00:33:01.413767 13672 solver.cpp:243] Iteration 7910, loss = 3.3773
I0624 00:33:01.413767 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.92683 (* 1 = 5.92683 loss)
I0624 00:33:01.413767 13672 sgd_solver.cpp:138] Iteration 7910, lr = 0.001
I0624 00:36:17.696190 13672 solver.cpp:243] Iteration 7920, loss = 3.41877
I0624 00:36:17.696190 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.51438 (* 1 = 6.51438 loss)
I0624 00:36:17.696190 13672 sgd_solver.cpp:138] Iteration 7920, lr = 0.001
I0624 00:39:53.052489 13672 solver.cpp:243] Iteration 7930, loss = 3.37371
I0624 00:39:53.161928 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.77338 (* 1 = 2.77338 loss)
I0624 00:39:53.161928 13672 sgd_solver.cpp:138] Iteration 7930, lr = 0.001
I0624 00:42:57.790403 13672 solver.cpp:243] Iteration 7940, loss = 3.38396
I0624 00:42:57.790403 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.27389 (* 1 = 3.27389 loss)
I0624 00:42:57.790403 13672 sgd_solver.cpp:138] Iteration 7940, lr = 0.001
I0624 00:46:35.364714 13672 solver.cpp:243] Iteration 7950, loss = 3.25572
I0624 00:46:35.364714 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.64106 (* 1 = 2.64106 loss)
I0624 00:46:35.364714 13672 sgd_solver.cpp:138] Iteration 7950, lr = 0.001
I0624 00:50:20.499720 13672 solver.cpp:243] Iteration 7960, loss = 3.27141
I0624 00:50:20.499720 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.43592 (* 1 = 3.43592 loss)
I0624 00:50:20.499720 13672 sgd_solver.cpp:138] Iteration 7960, lr = 0.001
I0624 00:53:45.155124 13672 solver.cpp:243] Iteration 7970, loss = 3.28168
I0624 00:53:45.186331 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.07085 (* 1 = 4.07085 loss)
I0624 00:53:45.217607 13672 sgd_solver.cpp:138] Iteration 7970, lr = 0.001
I0624 00:56:57.578976 13672 solver.cpp:243] Iteration 7980, loss = 3.4477
I0624 00:56:57.578976 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.84626 (* 1 = 1.84626 loss)
I0624 00:56:57.578976 13672 sgd_solver.cpp:138] Iteration 7980, lr = 0.001
I0624 01:00:03.832420 13672 solver.cpp:243] Iteration 7990, loss = 3.56505
I0624 01:00:03.832420 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.09338 (* 1 = 1.09338 loss)
I0624 01:00:03.832420 13672 sgd_solver.cpp:138] Iteration 7990, lr = 0.001
I0624 01:03:15.569020 13672 solver.cpp:243] Iteration 8000, loss = 3.27919
I0624 01:03:15.569020 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.7906 (* 1 = 1.7906 loss)
I0624 01:03:15.569020 13672 sgd_solver.cpp:138] Iteration 8000, lr = 0.001
I0624 01:06:40.646189 13672 solver.cpp:243] Iteration 8010, loss = 3.58365
I0624 01:06:40.661809 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.0587 (* 1 = 3.0587 loss)
I0624 01:06:40.661809 13672 sgd_solver.cpp:138] Iteration 8010, lr = 0.001
I0624 01:09:51.429790 13672 solver.cpp:243] Iteration 8020, loss = 3.30302
I0624 01:09:51.429790 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.14095 (* 1 = 1.14095 loss)
I0624 01:09:51.429790 13672 sgd_solver.cpp:138] Iteration 8020, lr = 0.001
I0624 01:13:04.021572 13672 solver.cpp:243] Iteration 8030, loss = 3.37353
I0624 01:13:04.021572 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.44682 (* 1 = 1.44682 loss)
I0624 01:13:04.021572 13672 sgd_solver.cpp:138] Iteration 8030, lr = 0.001
I0624 01:16:22.600317 13672 solver.cpp:243] Iteration 8040, loss = 3.47747
I0624 01:16:22.897078 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.29044 (* 1 = 5.29044 loss)
I0624 01:16:22.897078 13672 sgd_solver.cpp:138] Iteration 8040, lr = 0.001
I0624 01:19:29.959738 13672 solver.cpp:243] Iteration 8050, loss = 3.33131
I0624 01:19:29.975358 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.14467 (* 1 = 6.14467 loss)
I0624 01:19:29.975358 13672 sgd_solver.cpp:138] Iteration 8050, lr = 0.001
I0624 01:22:44.750917 13672 solver.cpp:243] Iteration 8060, loss = 3.37532
I0624 01:22:45.456596 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.6893 (* 1 = 4.6893 loss)
I0624 01:22:45.456596 13672 sgd_solver.cpp:138] Iteration 8060, lr = 0.001
I0624 01:27:10.281746 13672 solver.cpp:243] Iteration 8070, loss = 3.50266
I0624 01:27:10.281746 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.3789 (* 1 = 2.3789 loss)
I0624 01:27:10.281746 13672 sgd_solver.cpp:138] Iteration 8070, lr = 0.001
I0624 01:29:42.486723 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0624 01:31:31.183771 13672 solver.cpp:243] Iteration 8080, loss = 3.31501
I0624 01:31:31.184973 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.44894 (* 1 = 2.44894 loss)
I0624 01:31:31.184973 13672 sgd_solver.cpp:138] Iteration 8080, lr = 0.001
I0624 01:36:12.461819 13672 solver.cpp:243] Iteration 8090, loss = 3.26048
I0624 01:36:12.461819 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.39247 (* 1 = 4.39247 loss)
I0624 01:36:12.461819 13672 sgd_solver.cpp:138] Iteration 8090, lr = 0.001
I0624 01:40:39.520900 13672 solver.cpp:243] Iteration 8100, loss = 3.14055
I0624 01:40:39.533017 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.46823 (* 1 = 1.46823 loss)
I0624 01:40:39.535604 13672 sgd_solver.cpp:138] Iteration 8100, lr = 0.001
I0624 01:45:05.682020 13672 solver.cpp:243] Iteration 8110, loss = 3.2774
I0624 01:45:05.682020 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.24308 (* 1 = 7.24308 loss)
I0624 01:45:05.682020 13672 sgd_solver.cpp:138] Iteration 8110, lr = 0.001
I0624 01:49:40.004009 13672 solver.cpp:243] Iteration 8120, loss = 3.45589
I0624 01:49:40.004009 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.60302 (* 1 = 2.60302 loss)
I0624 01:49:40.004009 13672 sgd_solver.cpp:138] Iteration 8120, lr = 0.001
I0624 01:53:53.151098 13672 solver.cpp:243] Iteration 8130, loss = 3.2374
I0624 01:53:53.151098 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.72668 (* 1 = 4.72668 loss)
I0624 01:53:53.151098 13672 sgd_solver.cpp:138] Iteration 8130, lr = 0.001
I0624 01:57:18.191215 13672 solver.cpp:243] Iteration 8140, loss = 3.42231
I0624 01:57:18.191215 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.27433 (* 1 = 5.27433 loss)
I0624 01:57:18.191215 13672 sgd_solver.cpp:138] Iteration 8140, lr = 0.001
I0624 02:00:34.249303 13672 solver.cpp:243] Iteration 8150, loss = 2.96241
I0624 02:00:34.264925 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.97093 (* 1 = 3.97093 loss)
I0624 02:00:34.280545 13672 sgd_solver.cpp:138] Iteration 8150, lr = 0.001
I0624 02:03:49.016444 13672 solver.cpp:243] Iteration 8160, loss = 3.32098
I0624 02:03:49.016444 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.04002 (* 1 = 6.04002 loss)
I0624 02:03:49.016444 13672 sgd_solver.cpp:138] Iteration 8160, lr = 0.001
I0624 02:07:23.466501 13672 solver.cpp:243] Iteration 8170, loss = 3.60943
I0624 02:07:23.466501 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.40691 (* 1 = 4.40691 loss)
I0624 02:07:23.466501 13672 sgd_solver.cpp:138] Iteration 8170, lr = 0.001
I0624 02:10:42.498260 13672 solver.cpp:243] Iteration 8180, loss = 3.23802
I0624 02:10:42.498260 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.32604 (* 1 = 3.32604 loss)
I0624 02:10:42.498260 13672 sgd_solver.cpp:138] Iteration 8180, lr = 0.001
I0624 02:14:00.983188 13672 solver.cpp:243] Iteration 8190, loss = 3.23836
I0624 02:14:00.983188 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.4096 (* 1 = 3.4096 loss)
I0624 02:14:00.983188 13672 sgd_solver.cpp:138] Iteration 8190, lr = 0.001
I0624 02:17:28.669183 13672 solver.cpp:243] Iteration 8200, loss = 3.41288
I0624 02:17:28.669183 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.5478 (* 1 = 2.5478 loss)
I0624 02:17:28.669183 13672 sgd_solver.cpp:138] Iteration 8200, lr = 0.001
I0624 02:20:39.124837 13672 solver.cpp:243] Iteration 8210, loss = 3.18172
I0624 02:20:39.124837 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.86922 (* 1 = 3.86922 loss)
I0624 02:20:39.124837 13672 sgd_solver.cpp:138] Iteration 8210, lr = 0.001
I0624 02:23:45.018955 13672 solver.cpp:243] Iteration 8220, loss = 3.20885
I0624 02:23:45.018955 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.72222 (* 1 = 2.72222 loss)
I0624 02:23:45.018955 13672 sgd_solver.cpp:138] Iteration 8220, lr = 0.001
I0624 02:27:01.520054 13672 solver.cpp:243] Iteration 8230, loss = 3.24952
I0624 02:27:01.520054 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.66969 (* 1 = 1.66969 loss)
I0624 02:27:01.520054 13672 sgd_solver.cpp:138] Iteration 8230, lr = 0.001
I0624 02:30:16.334004 13672 solver.cpp:243] Iteration 8240, loss = 3.31567
I0624 02:30:16.334004 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.612481 (* 1 = 0.612481 loss)
I0624 02:30:16.334004 13672 sgd_solver.cpp:138] Iteration 8240, lr = 0.001
I0624 02:33:27.086407 13672 solver.cpp:243] Iteration 8250, loss = 3.36081
I0624 02:33:27.086407 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.18803 (* 1 = 1.18803 loss)
I0624 02:33:27.086407 13672 sgd_solver.cpp:138] Iteration 8250, lr = 0.001
I0624 02:36:35.667429 13672 solver.cpp:243] Iteration 8260, loss = 3.23231
I0624 02:36:35.667429 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.3662 (* 1 = 2.3662 loss)
I0624 02:36:35.667429 13672 sgd_solver.cpp:138] Iteration 8260, lr = 0.001
I0624 02:40:00.026036 13672 solver.cpp:243] Iteration 8270, loss = 3.4042
I0624 02:40:00.026036 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.48341 (* 1 = 2.48341 loss)
I0624 02:40:00.026036 13672 sgd_solver.cpp:138] Iteration 8270, lr = 0.001
I0624 02:43:18.854710 13672 solver.cpp:243] Iteration 8280, loss = 3.12137
I0624 02:43:18.870342 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.45374 (* 1 = 1.45374 loss)
I0624 02:43:18.870342 13672 sgd_solver.cpp:138] Iteration 8280, lr = 0.001
I0624 02:46:30.263132 13672 solver.cpp:243] Iteration 8290, loss = 3.37023
I0624 02:46:30.263132 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.44066 (* 1 = 4.44066 loss)
I0624 02:46:30.263132 13672 sgd_solver.cpp:138] Iteration 8290, lr = 0.001
I0624 02:49:38.750479 13672 solver.cpp:243] Iteration 8300, loss = 3.39246
I0624 02:49:38.750479 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.73081 (* 1 = 4.73081 loss)
I0624 02:49:38.750479 13672 sgd_solver.cpp:138] Iteration 8300, lr = 0.001
I0624 02:52:48.721767 13672 solver.cpp:243] Iteration 8310, loss = 3.03816
I0624 02:52:48.721767 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.46308 (* 1 = 4.46308 loss)
I0624 02:52:48.721767 13672 sgd_solver.cpp:138] Iteration 8310, lr = 0.001
I0624 02:55:56.084437 13672 solver.cpp:243] Iteration 8320, loss = 3.27103
I0624 02:55:56.084437 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.81369 (* 1 = 1.81369 loss)
I0624 02:55:56.084437 13672 sgd_solver.cpp:138] Iteration 8320, lr = 0.001
I0624 02:59:08.024060 13672 solver.cpp:243] Iteration 8330, loss = 3.42219
I0624 02:59:08.024060 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.44488 (* 1 = 2.44488 loss)
I0624 02:59:08.024060 13672 sgd_solver.cpp:138] Iteration 8330, lr = 0.001
I0624 03:02:24.228353 13672 solver.cpp:243] Iteration 8340, loss = 3.35556
I0624 03:02:24.228353 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.57928 (* 1 = 4.57928 loss)
I0624 03:02:24.228353 13672 sgd_solver.cpp:138] Iteration 8340, lr = 0.001
I0624 03:05:45.072386 13672 solver.cpp:243] Iteration 8350, loss = 3.27736
I0624 03:05:45.087906 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.39368 (* 1 = 3.39368 loss)
I0624 03:05:45.087906 13672 sgd_solver.cpp:138] Iteration 8350, lr = 0.001
I0624 03:08:53.715623 13672 solver.cpp:243] Iteration 8360, loss = 3.1763
I0624 03:08:53.715623 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.39778 (* 1 = 2.39778 loss)
I0624 03:08:53.715623 13672 sgd_solver.cpp:138] Iteration 8360, lr = 0.001
I0624 03:12:02.609129 13672 solver.cpp:243] Iteration 8370, loss = 3.27916
I0624 03:12:02.609129 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.56143 (* 1 = 2.56143 loss)
I0624 03:12:02.609129 13672 sgd_solver.cpp:138] Iteration 8370, lr = 0.001
I0624 03:15:08.393930 13672 solver.cpp:243] Iteration 8380, loss = 3.17316
I0624 03:15:08.393930 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.31049 (* 1 = 3.31049 loss)
I0624 03:15:08.393930 13672 sgd_solver.cpp:138] Iteration 8380, lr = 0.001
I0624 03:18:14.131872 13672 solver.cpp:243] Iteration 8390, loss = 3.36179
I0624 03:18:14.131872 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.21195 (* 1 = 4.21195 loss)
I0624 03:18:14.131872 13672 sgd_solver.cpp:138] Iteration 8390, lr = 0.001
I0624 03:21:18.057783 13672 solver.cpp:243] Iteration 8400, loss = 3.17838
I0624 03:21:18.057783 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.12057 (* 1 = 4.12057 loss)
I0624 03:21:18.057783 13672 sgd_solver.cpp:138] Iteration 8400, lr = 0.001
I0624 03:24:30.497321 13672 solver.cpp:243] Iteration 8410, loss = 3.24447
I0624 03:24:30.497321 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.0332 (* 1 = 5.0332 loss)
I0624 03:24:30.497321 13672 sgd_solver.cpp:138] Iteration 8410, lr = 0.001
I0624 03:27:53.106354 13672 solver.cpp:243] Iteration 8420, loss = 3.34961
I0624 03:27:53.153825 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.42776 (* 1 = 5.42776 loss)
I0624 03:27:53.169229 13672 sgd_solver.cpp:138] Iteration 8420, lr = 0.001
I0624 03:31:02.640342 13672 solver.cpp:243] Iteration 8430, loss = 3.11708
I0624 03:31:02.640342 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.40153 (* 1 = 3.40153 loss)
I0624 03:31:02.640342 13672 sgd_solver.cpp:138] Iteration 8430, lr = 0.001
I0624 03:34:05.238459 13672 solver.cpp:243] Iteration 8440, loss = 3.2116
I0624 03:34:05.238459 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.78784 (* 1 = 2.78784 loss)
I0624 03:34:05.238459 13672 sgd_solver.cpp:138] Iteration 8440, lr = 0.001
I0624 03:37:22.786270 13672 solver.cpp:243] Iteration 8450, loss = 3.31905
I0624 03:37:22.786270 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.28686 (* 1 = 4.28686 loss)
I0624 03:37:22.786270 13672 sgd_solver.cpp:138] Iteration 8450, lr = 0.001
I0624 03:40:23.587867 13672 solver.cpp:243] Iteration 8460, loss = 3.31759
I0624 03:40:23.587867 13672 solver.cpp:259]     Train net output #0: mbox_loss = 16.1316 (* 1 = 16.1316 loss)
I0624 03:40:23.587867 13672 sgd_solver.cpp:138] Iteration 8460, lr = 0.001
I0624 03:43:31.200333 13672 solver.cpp:243] Iteration 8470, loss = 3.34254
I0624 03:43:31.200333 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.27515 (* 1 = 4.27515 loss)
I0624 03:43:31.200333 13672 sgd_solver.cpp:138] Iteration 8470, lr = 0.001
I0624 03:46:39.906380 13672 solver.cpp:243] Iteration 8480, loss = 3.25903
I0624 03:46:39.906380 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.603504 (* 1 = 0.603504 loss)
I0624 03:46:39.906380 13672 sgd_solver.cpp:138] Iteration 8480, lr = 0.001
I0624 03:49:44.722707 13672 solver.cpp:243] Iteration 8490, loss = 3.38692
I0624 03:49:44.722707 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.02915 (* 1 = 1.02915 loss)
I0624 03:49:44.722707 13672 sgd_solver.cpp:138] Iteration 8490, lr = 0.001
I0624 03:52:47.570739 13672 solver.cpp:243] Iteration 8500, loss = 3.15013
I0624 03:52:47.570739 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.11421 (* 1 = 2.11421 loss)
I0624 03:52:47.570739 13672 sgd_solver.cpp:138] Iteration 8500, lr = 0.001
I0624 03:55:56.495400 13672 solver.cpp:243] Iteration 8510, loss = 3.45231
I0624 03:55:56.495400 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.52234 (* 1 = 4.52234 loss)
I0624 03:55:56.495400 13672 sgd_solver.cpp:138] Iteration 8510, lr = 0.001
I0624 03:59:20.213587 13672 solver.cpp:243] Iteration 8520, loss = 3.1929
I0624 03:59:20.213587 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.82653 (* 1 = 1.82653 loss)
I0624 03:59:20.213587 13672 sgd_solver.cpp:138] Iteration 8520, lr = 0.001
I0624 04:02:29.388206 13672 solver.cpp:243] Iteration 8530, loss = 3.24893
I0624 04:02:29.388206 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.3303 (* 1 = 1.3303 loss)
I0624 04:02:29.388206 13672 sgd_solver.cpp:138] Iteration 8530, lr = 0.001
I0624 04:05:35.454198 13672 solver.cpp:243] Iteration 8540, loss = 3.34549
I0624 04:05:35.454198 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.76319 (* 1 = 4.76319 loss)
I0624 04:05:35.454198 13672 sgd_solver.cpp:138] Iteration 8540, lr = 0.001
I0624 04:08:45.128684 13672 solver.cpp:243] Iteration 8550, loss = 3.35628
I0624 04:08:45.128684 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.28243 (* 1 = 7.28243 loss)
I0624 04:08:45.128684 13672 sgd_solver.cpp:138] Iteration 8550, lr = 0.001
I0624 04:11:58.849186 13672 solver.cpp:243] Iteration 8560, loss = 3.22209
I0624 04:11:58.849186 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.40531 (* 1 = 4.40531 loss)
I0624 04:11:58.849186 13672 sgd_solver.cpp:138] Iteration 8560, lr = 0.001
I0624 04:15:12.788337 13672 solver.cpp:243] Iteration 8570, loss = 3.33311
I0624 04:15:12.788337 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.77902 (* 1 = 2.77902 loss)
I0624 04:15:12.788337 13672 sgd_solver.cpp:138] Iteration 8570, lr = 0.001
I0624 04:18:27.414834 13672 solver.cpp:243] Iteration 8580, loss = 3.13837
I0624 04:18:27.414834 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.98886 (* 1 = 2.98886 loss)
I0624 04:18:27.414834 13672 sgd_solver.cpp:138] Iteration 8580, lr = 0.001
I0624 04:21:38.191653 13672 solver.cpp:243] Iteration 8590, loss = 3.18397
I0624 04:21:38.191653 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.50922 (* 1 = 3.50922 loss)
I0624 04:21:38.191653 13672 sgd_solver.cpp:138] Iteration 8590, lr = 0.001
I0624 04:25:00.816283 13672 solver.cpp:243] Iteration 8600, loss = 3.34739
I0624 04:25:00.816283 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.30824 (* 1 = 2.30824 loss)
I0624 04:25:00.816283 13672 sgd_solver.cpp:138] Iteration 8600, lr = 0.001
I0624 04:28:10.350174 13672 solver.cpp:243] Iteration 8610, loss = 3.07968
I0624 04:28:10.350174 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.937248 (* 1 = 0.937248 loss)
I0624 04:28:10.350174 13672 sgd_solver.cpp:138] Iteration 8610, lr = 0.001
I0624 04:31:19.509402 13672 solver.cpp:243] Iteration 8620, loss = 3.35428
I0624 04:31:19.509402 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.73527 (* 1 = 1.73527 loss)
I0624 04:31:19.509402 13672 sgd_solver.cpp:138] Iteration 8620, lr = 0.001
I0624 04:34:27.153115 13672 solver.cpp:243] Iteration 8630, loss = 3.26367
I0624 04:34:27.153115 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.94854 (* 1 = 3.94854 loss)
I0624 04:34:27.153115 13672 sgd_solver.cpp:138] Iteration 8630, lr = 0.001
I0624 04:37:38.093006 13672 solver.cpp:243] Iteration 8640, loss = 3.43118
I0624 04:37:38.093006 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.3457 (* 1 = 4.3457 loss)
I0624 04:37:38.093006 13672 sgd_solver.cpp:138] Iteration 8640, lr = 0.001
I0624 04:41:02.373463 13672 solver.cpp:243] Iteration 8650, loss = 3.0645
I0624 04:41:02.389122 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.11572 (* 1 = 3.11572 loss)
I0624 04:41:02.404747 13672 sgd_solver.cpp:138] Iteration 8650, lr = 0.001
I0624 04:44:18.817653 13672 solver.cpp:243] Iteration 8660, loss = 3.21875
I0624 04:44:18.817653 13672 solver.cpp:259]     Train net output #0: mbox_loss = 6.00604 (* 1 = 6.00604 loss)
I0624 04:44:18.817653 13672 sgd_solver.cpp:138] Iteration 8660, lr = 0.001
I0624 04:47:31.085326 13672 solver.cpp:243] Iteration 8670, loss = 3.47018
I0624 04:47:31.085326 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.43401 (* 1 = 5.43401 loss)
I0624 04:47:31.085326 13672 sgd_solver.cpp:138] Iteration 8670, lr = 0.001
I0624 04:50:43.853009 13672 solver.cpp:243] Iteration 8680, loss = 3.2811
I0624 04:50:43.853009 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.47576 (* 1 = 2.47576 loss)
I0624 04:50:43.853009 13672 sgd_solver.cpp:138] Iteration 8680, lr = 0.001
I0624 04:53:52.605984 13672 solver.cpp:243] Iteration 8690, loss = 3.12922
I0624 04:53:52.605984 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.51214 (* 1 = 4.51214 loss)
I0624 04:53:52.605984 13672 sgd_solver.cpp:138] Iteration 8690, lr = 0.001
I0624 04:57:21.838548 13672 solver.cpp:243] Iteration 8700, loss = 3.22221
I0624 04:57:21.838548 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.11585 (* 1 = 2.11585 loss)
I0624 04:57:21.838548 13672 sgd_solver.cpp:138] Iteration 8700, lr = 0.001
I0624 05:00:30.966328 13672 solver.cpp:243] Iteration 8710, loss = 3.02906
I0624 05:00:30.966328 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.83191 (* 1 = 2.83191 loss)
I0624 05:00:30.966328 13672 sgd_solver.cpp:138] Iteration 8710, lr = 0.001
I0624 05:04:02.975623 13672 solver.cpp:243] Iteration 8720, loss = 3.17914
I0624 05:04:03.006865 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.79787 (* 1 = 2.79787 loss)
I0624 05:04:03.022481 13672 sgd_solver.cpp:138] Iteration 8720, lr = 0.001
I0624 05:07:19.804730 13672 solver.cpp:243] Iteration 8730, loss = 3.10414
I0624 05:07:19.804730 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.26379 (* 1 = 1.26379 loss)
I0624 05:07:19.804730 13672 sgd_solver.cpp:138] Iteration 8730, lr = 0.001
I0624 05:10:30.893326 13672 solver.cpp:243] Iteration 8740, loss = 3.37163
I0624 05:10:30.893326 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.554671 (* 1 = 0.554671 loss)
I0624 05:10:30.893326 13672 sgd_solver.cpp:138] Iteration 8740, lr = 0.001
I0624 05:13:36.396908 13672 solver.cpp:243] Iteration 8750, loss = 3.40383
I0624 05:13:36.396908 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.622 (* 1 = 1.622 loss)
I0624 05:13:36.396908 13672 sgd_solver.cpp:138] Iteration 8750, lr = 0.001
I0624 05:16:49.617482 13672 solver.cpp:243] Iteration 8760, loss = 3.48152
I0624 05:16:49.617482 13672 solver.cpp:259]     Train net output #0: mbox_loss = 9.53012 (* 1 = 9.53012 loss)
I0624 05:16:49.617482 13672 sgd_solver.cpp:138] Iteration 8760, lr = 0.001
I0624 05:20:08.956957 13672 solver.cpp:243] Iteration 8770, loss = 3.2319
I0624 05:20:08.956957 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.08319 (* 1 = 1.08319 loss)
I0624 05:20:08.956957 13672 sgd_solver.cpp:138] Iteration 8770, lr = 0.001
I0624 05:23:23.983758 13672 solver.cpp:243] Iteration 8780, loss = 3.09795
I0624 05:23:23.983758 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.78655 (* 1 = 0.78655 loss)
I0624 05:23:23.983758 13672 sgd_solver.cpp:138] Iteration 8780, lr = 0.001
I0624 05:23:35.276897 13672 blocking_queue.cpp:51] Data layer prefetch queue empty
I0624 05:26:37.123711 13672 solver.cpp:243] Iteration 8790, loss = 3.28209
I0624 05:26:37.123711 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.16271 (* 1 = 4.16271 loss)
I0624 05:26:37.123711 13672 sgd_solver.cpp:138] Iteration 8790, lr = 0.001
I0624 05:29:59.176888 13672 solver.cpp:243] Iteration 8800, loss = 3.15237
I0624 05:29:59.176888 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.40462 (* 1 = 2.40462 loss)
I0624 05:29:59.176888 13672 sgd_solver.cpp:138] Iteration 8800, lr = 0.001
I0624 05:33:16.910187 13672 solver.cpp:243] Iteration 8810, loss = 3.24929
I0624 05:33:16.910187 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.26748 (* 1 = 3.26748 loss)
I0624 05:33:16.910187 13672 sgd_solver.cpp:138] Iteration 8810, lr = 0.001
I0624 05:36:37.323380 13672 solver.cpp:243] Iteration 8820, loss = 3.17583
I0624 05:36:37.385905 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.91569 (* 1 = 2.91569 loss)
I0624 05:36:37.385905 13672 sgd_solver.cpp:138] Iteration 8820, lr = 0.001
I0624 05:40:12.256683 13672 solver.cpp:243] Iteration 8830, loss = 3.23075
I0624 05:40:12.256683 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.053 (* 1 = 2.053 loss)
I0624 05:40:12.256683 13672 sgd_solver.cpp:138] Iteration 8830, lr = 0.001
I0624 05:43:27.398766 13672 solver.cpp:243] Iteration 8840, loss = 3.18642
I0624 05:43:27.398766 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.06142 (* 1 = 4.06142 loss)
I0624 05:43:27.398766 13672 sgd_solver.cpp:138] Iteration 8840, lr = 0.001
I0624 05:47:12.605159 13672 solver.cpp:243] Iteration 8850, loss = 3.08593
I0624 05:47:12.776926 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.75877 (* 1 = 3.75877 loss)
I0624 05:47:12.839725 13672 sgd_solver.cpp:138] Iteration 8850, lr = 0.001
I0624 05:50:34.137161 13672 solver.cpp:243] Iteration 8860, loss = 2.94171
I0624 05:50:34.137161 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.50611 (* 1 = 1.50611 loss)
I0624 05:50:34.137161 13672 sgd_solver.cpp:138] Iteration 8860, lr = 0.001
I0624 05:53:46.422958 13672 solver.cpp:243] Iteration 8870, loss = 3.23825
I0624 05:53:46.422958 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.35807 (* 1 = 2.35807 loss)
I0624 05:53:46.422958 13672 sgd_solver.cpp:138] Iteration 8870, lr = 0.001
I0624 05:57:07.166803 13672 solver.cpp:243] Iteration 8880, loss = 3.11929
I0624 05:57:07.166803 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.18519 (* 1 = 4.18519 loss)
I0624 05:57:07.166803 13672 sgd_solver.cpp:138] Iteration 8880, lr = 0.001
I0624 06:00:21.777746 13672 solver.cpp:243] Iteration 8890, loss = 2.99709
I0624 06:00:21.777746 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.33858 (* 1 = 5.33858 loss)
I0624 06:00:21.777746 13672 sgd_solver.cpp:138] Iteration 8890, lr = 0.001
I0624 06:03:39.387921 13672 solver.cpp:243] Iteration 8900, loss = 3.12289
I0624 06:03:39.387921 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.77167 (* 1 = 2.77167 loss)
I0624 06:03:39.387921 13672 sgd_solver.cpp:138] Iteration 8900, lr = 0.001
I0624 06:06:46.585865 13672 solver.cpp:243] Iteration 8910, loss = 3.0687
I0624 06:06:46.585865 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.82812 (* 1 = 3.82812 loss)
I0624 06:06:46.585865 13672 sgd_solver.cpp:138] Iteration 8910, lr = 0.001
I0624 06:09:55.493185 13672 solver.cpp:243] Iteration 8920, loss = 3.31966
I0624 06:09:55.493185 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.27218 (* 1 = 5.27218 loss)
I0624 06:09:55.493185 13672 sgd_solver.cpp:138] Iteration 8920, lr = 0.001
I0624 06:13:16.477533 13672 solver.cpp:243] Iteration 8930, loss = 3.14218
I0624 06:13:16.477533 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.87269 (* 1 = 2.87269 loss)
I0624 06:13:16.477533 13672 sgd_solver.cpp:138] Iteration 8930, lr = 0.001
I0624 06:16:24.855489 13672 solver.cpp:243] Iteration 8940, loss = 3.12406
I0624 06:16:24.855489 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.06129 (* 1 = 2.06129 loss)
I0624 06:16:24.855489 13672 sgd_solver.cpp:138] Iteration 8940, lr = 0.001
I0624 06:19:54.744086 13672 solver.cpp:243] Iteration 8950, loss = 3.12936
I0624 06:19:54.744086 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.12509 (* 1 = 4.12509 loss)
I0624 06:19:54.744086 13672 sgd_solver.cpp:138] Iteration 8950, lr = 0.001
I0624 06:23:07.433531 13672 solver.cpp:243] Iteration 8960, loss = 3.0443
I0624 06:23:07.433531 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.3156 (* 1 = 3.3156 loss)
I0624 06:23:07.433531 13672 sgd_solver.cpp:138] Iteration 8960, lr = 0.001
I0624 06:26:36.166116 13672 solver.cpp:243] Iteration 8970, loss = 3.24051
I0624 06:26:36.197358 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.45632 (* 1 = 2.45632 loss)
I0624 06:26:36.212978 13672 sgd_solver.cpp:138] Iteration 8970, lr = 0.001
I0624 06:29:50.074029 13672 solver.cpp:243] Iteration 8980, loss = 3.0517
I0624 06:29:50.074029 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.958969 (* 1 = 0.958969 loss)
I0624 06:29:50.074029 13672 sgd_solver.cpp:138] Iteration 8980, lr = 0.001
I0624 06:33:12.745523 13672 solver.cpp:243] Iteration 8990, loss = 3.08169
I0624 06:33:12.792395 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.35622 (* 1 = 1.35622 loss)
I0624 06:33:12.792395 13672 sgd_solver.cpp:138] Iteration 8990, lr = 0.001
I0624 06:36:26.262866 13672 solver.cpp:243] Iteration 9000, loss = 3.20859
I0624 06:36:26.262866 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.98402 (* 1 = 2.98402 loss)
I0624 06:36:26.262866 13672 sgd_solver.cpp:138] Iteration 9000, lr = 0.001
I0624 06:39:44.963102 13672 solver.cpp:243] Iteration 9010, loss = 3.40717
I0624 06:39:44.963102 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.4117 (* 1 = 5.4117 loss)
I0624 06:39:44.963102 13672 sgd_solver.cpp:138] Iteration 9010, lr = 0.001
I0624 06:42:57.558820 13672 solver.cpp:243] Iteration 9020, loss = 3.23448
I0624 06:42:57.558820 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.943216 (* 1 = 0.943216 loss)
I0624 06:42:57.558820 13672 sgd_solver.cpp:138] Iteration 9020, lr = 0.001
I0624 06:46:20.011615 13672 solver.cpp:243] Iteration 9030, loss = 3.0666
I0624 06:46:20.011615 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.74607 (* 1 = 1.74607 loss)
I0624 06:46:20.011615 13672 sgd_solver.cpp:138] Iteration 9030, lr = 0.001
I0624 06:49:59.288575 13672 solver.cpp:243] Iteration 9040, loss = 3.25881
I0624 06:49:59.335487 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.55962 (* 1 = 5.55962 loss)
I0624 06:49:59.351155 13672 sgd_solver.cpp:138] Iteration 9040, lr = 0.001
I0624 06:53:16.398907 13672 solver.cpp:243] Iteration 9050, loss = 3.20083
I0624 06:53:16.398907 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.74676 (* 1 = 5.74676 loss)
I0624 06:53:16.398907 13672 sgd_solver.cpp:138] Iteration 9050, lr = 0.001
I0624 06:56:58.320828 13672 solver.cpp:243] Iteration 9060, loss = 3.22379
I0624 06:56:58.320828 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.65843 (* 1 = 5.65843 loss)
I0624 06:56:58.323040 13672 sgd_solver.cpp:138] Iteration 9060, lr = 0.001
I0624 07:01:27.821888 13672 solver.cpp:243] Iteration 9070, loss = 3.25969
I0624 07:01:27.822885 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.89357 (* 1 = 3.89357 loss)
I0624 07:01:27.823547 13672 sgd_solver.cpp:138] Iteration 9070, lr = 0.001
I0624 07:05:48.954979 13672 solver.cpp:243] Iteration 9080, loss = 3.11751
I0624 07:05:48.954979 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.49912 (* 1 = 3.49912 loss)
I0624 07:05:48.954979 13672 sgd_solver.cpp:138] Iteration 9080, lr = 0.001
I0624 07:10:12.271064 13672 solver.cpp:243] Iteration 9090, loss = 3.14891
I0624 07:10:12.272266 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.72124 (* 1 = 3.72124 loss)
I0624 07:10:12.272266 13672 sgd_solver.cpp:138] Iteration 9090, lr = 0.001
I0624 07:14:13.731914 13672 solver.cpp:243] Iteration 9100, loss = 3.29226
I0624 07:14:13.731914 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.89715 (* 1 = 3.89715 loss)
I0624 07:14:13.731914 13672 sgd_solver.cpp:138] Iteration 9100, lr = 0.001
I0624 07:18:41.037469 13672 solver.cpp:243] Iteration 9110, loss = 2.97042
I0624 07:18:41.037469 13672 solver.cpp:259]     Train net output #0: mbox_loss = 0.988188 (* 1 = 0.988188 loss)
I0624 07:18:41.037469 13672 sgd_solver.cpp:138] Iteration 9110, lr = 0.001
I0624 07:23:20.979352 13672 solver.cpp:243] Iteration 9120, loss = 3.22095
I0624 07:23:20.979352 13672 solver.cpp:259]     Train net output #0: mbox_loss = 1.80697 (* 1 = 1.80697 loss)
I0624 07:23:20.979352 13672 sgd_solver.cpp:138] Iteration 9120, lr = 0.001
I0624 07:27:35.079574 13672 solver.cpp:243] Iteration 9130, loss = 3.04885
I0624 07:27:35.079574 13672 solver.cpp:259]     Train net output #0: mbox_loss = 4.83637 (* 1 = 4.83637 loss)
I0624 07:27:35.079574 13672 sgd_solver.cpp:138] Iteration 9130, lr = 0.001
I0624 07:30:43.516093 13672 solver.cpp:243] Iteration 9140, loss = 3.38922
I0624 07:30:43.516093 13672 solver.cpp:259]     Train net output #0: mbox_loss = 3.54295 (* 1 = 3.54295 loss)
I0624 07:30:43.516093 13672 sgd_solver.cpp:138] Iteration 9140, lr = 0.001
I0624 07:34:09.733644 13672 solver.cpp:243] Iteration 9150, loss = 3.02562
I0624 07:34:09.733644 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.7475 (* 1 = 2.7475 loss)
I0624 07:34:09.749264 13672 sgd_solver.cpp:138] Iteration 9150, lr = 0.001
I0624 07:37:26.249334 13672 solver.cpp:243] Iteration 9160, loss = 3.15988
I0624 07:37:26.249334 13672 solver.cpp:259]     Train net output #0: mbox_loss = 7.13692 (* 1 = 7.13692 loss)
I0624 07:37:26.249334 13672 sgd_solver.cpp:138] Iteration 9160, lr = 0.001
I0624 07:40:45.541208 13672 solver.cpp:243] Iteration 9170, loss = 3.25793
I0624 07:40:45.541208 13672 solver.cpp:259]     Train net output #0: mbox_loss = 5.44534 (* 1 = 5.44534 loss)
I0624 07:40:45.541208 13672 sgd_solver.cpp:138] Iteration 9170, lr = 0.001
I0624 07:44:07.636765 13672 solver.cpp:243] Iteration 9180, loss = 3.20774
I0624 07:44:07.652346 13672 solver.cpp:259]     Train net output #0: mbox_loss = 2.1819 (* 1 = 2.1819 loss)
I0624 07:44:07.652346 13672 sgd_solver.cpp:138] Iteration 9180, lr = 0.001
